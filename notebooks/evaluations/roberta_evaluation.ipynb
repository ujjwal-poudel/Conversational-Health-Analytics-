{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36635b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(Path.cwd().parents[1] / \"src\"))\n",
    "from preprocessing.preprocess_dataset import DistilBertPreprocessor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "CHECKPOINT_PATH = Path.cwd().parents[1] / \"models\" / \"roberta\"\n",
    "DATA_DIR = Path(\"/Volumes/MACBACKUP/final_datasets/\")\n",
    "TEST_DATA_PATH = DATA_DIR / \"final_test_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b78d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # LOAD SAVED MODEL AND TOKENIZER\n",
    "    print(f\"Loading model and tokenizer from {CHECKPOINT_PATH}...\")\n",
    "    if not CHECKPOINT_PATH.exists():\n",
    "        print(\"Error: Model checkpoint not found. Please train the model first.\")\n",
    "        return\n",
    "        \n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # LOADING AND PREPROCESSING TEST DATA\n",
    "    preprocessor = DistilBertPreprocessor()\n",
    "    \n",
    "    print(\"Loading and preprocessing test data...\")\n",
    "    # keep_id_column must be True to track participants\n",
    "    X_test_df, y_test_df = preprocessor.load_and_preprocess(TEST_DATA_PATH, keep_id_column=True)\n",
    "\n",
    "    # Chunking the test data just like the training data\n",
    "    X_test_chunked, y_test_chunked = preprocessor.chunk_dataframe(X_test_df, y_test_df)\n",
    "\n",
    "    # Getting PREDICTIONS FOR EACH CHUNK\n",
    "    chunk_predictions = []\n",
    "    print(\"Getting predictions for each text chunk...\")\n",
    "    with torch.no_grad():\n",
    "        for index, row in tqdm(X_test_chunked.iterrows(), total=len(X_test_chunked)):\n",
    "            text = row['text']\n",
    "            participant_id = row['participant_id']\n",
    "            \n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "            \n",
    "            chunk_predictions.append({\n",
    "                'participant_id': participant_id,\n",
    "                'chunk_prediction': prediction\n",
    "            })\n",
    "    \n",
    "    chunk_results_df = pd.DataFrame(chunk_predictions)\n",
    "\n",
    "    # AGGREGATING PREDICTIONS (MAJORITY VOTING)\n",
    "    print(\"Aggregating chunk predictions to participant level...\")\n",
    "    final_preds_series = chunk_results_df.groupby('participant_id')['chunk_prediction'].agg(lambda x: x.mode()[0])\n",
    "    final_preds_df = final_preds_series.reset_index().rename(columns={'chunk_prediction': 'final_prediction'})\n",
    "\n",
    "    # CALCULATING FINAL METRICS\n",
    "    print(\"Calculating final performance metrics...\")\n",
    "    \n",
    "    # Merge final predictions with the original true labels\n",
    "    # We use the original y_test_df which has one label per participant\n",
    "    true_labels_df = X_test_df.join(y_test_df)\n",
    "    \n",
    "    results_df = pd.merge(final_preds_df, true_labels_df, on='participant_id')\n",
    "\n",
    "    true_labels = results_df['label']\n",
    "    final_predictions = results_df['final_prediction']\n",
    "\n",
    "    # Generate and print the classification report\n",
    "    report = classification_report(true_labels, final_predictions, target_names=['Not Depressed (0)', 'Depressed (1)'])\n",
    "    accuracy = accuracy_score(true_labels, final_predictions)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL TEST SET PERFORMANCE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, final_predictions)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not Depressed (0)', 'Depressed (1)'],\n",
    "            yticklabels=['Not Depressed (0)', 'Depressed (1)'])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
