{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148f1418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants: 189\n",
      "Example folders: ['300_P', '301_P', '302_P', '303_P', '304_P']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Base folder with 300_P, 301_P, ...\n",
    "base_path = Path(r\"C:\\Users\\DELL\\Desktop\\Conversational-Health-Analytics-\\Dataset\\extracted_folders\")\n",
    "\n",
    "# Get participant folder names like ['300_P', '301_P', ...]\n",
    "participant_folders = sorted(\n",
    "    [f for f in base_path.iterdir() if f.is_dir() and f.name.endswith(\"_P\")]\n",
    ")\n",
    "\n",
    "print(\"Number of participants:\", len(participant_folders))\n",
    "print(\"Example folders:\", [f.name for f in participant_folders[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2e3889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in transcript file: ['start_time', 'stop_time', 'speaker', 'value']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.588</td>\n",
       "      <td>39.668</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>hi i'm ellie thanks for coming in today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.888</td>\n",
       "      <td>43.378</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>i was created to talk to people in a safe and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.728</td>\n",
       "      <td>48.498</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>think of me as a friend i don't judge i can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.188</td>\n",
       "      <td>52.388</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>i'm here to learn about people and would love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.658</td>\n",
       "      <td>58.958</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>i'll ask a few questions to get us started and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_time  stop_time speaker  \\\n",
       "0      36.588     39.668   Ellie   \n",
       "1      39.888     43.378   Ellie   \n",
       "2      43.728     48.498   Ellie   \n",
       "3      49.188     52.388   Ellie   \n",
       "4      52.658     58.958   Ellie   \n",
       "\n",
       "                                               value  \n",
       "0            hi i'm ellie thanks for coming in today  \n",
       "1  i was created to talk to people in a safe and ...  \n",
       "2  think of me as a friend i don't judge i can't ...  \n",
       "3  i'm here to learn about people and would love ...  \n",
       "4  i'll ask a few questions to get us started and...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "pid = 300\n",
    "folder = base_path / f\"{pid}_P\"\n",
    "transcript_path = folder / f\"{pid}_TRANSCRIPT.csv\"\n",
    "\n",
    "df_t = pd.read_csv(transcript_path, sep=\"\\t\")  # IMPORTANT\n",
    "print(\"Columns in transcript file:\", df_t.columns.tolist())\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2822d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_audio_and_clean(pid, sr_target=None):\n",
    "    \"\"\"\n",
    "    Loads original audio AND cleaned (no Ellie) audio.\n",
    "    Prints both durations.\n",
    "    Returns: y_full, y_clean, sr\n",
    "    \"\"\"\n",
    "    folder = base_path / f\"{pid}_P\"\n",
    "    audio_path = folder / f\"{pid}_AUDIO.wav\"\n",
    "    transcript_path = folder / f\"{pid}_TRANSCRIPT.csv\"\n",
    "\n",
    "    # Load original audio\n",
    "    y_full, sr = librosa.load(audio_path, sr=sr_target)\n",
    "    full_duration = len(y_full) / sr\n",
    "\n",
    "    # Load transcript (tab-separated)\n",
    "    df_t = pd.read_csv(transcript_path, sep=\"\\t\")\n",
    "    \n",
    "    # Ensure numeric times\n",
    "    df_t[\"start_time\"] = pd.to_numeric(df_t[\"start_time\"], errors=\"coerce\")\n",
    "    df_t[\"stop_time\"]  = pd.to_numeric(df_t[\"stop_time\"],  errors=\"coerce\")\n",
    "\n",
    "    keep_segments = []\n",
    "\n",
    "    for _, row in df_t.iterrows():\n",
    "        speaker = str(row[\"speaker\"]).lower()\n",
    "\n",
    "        # Keep only participant speech\n",
    "        if \"ellie\" in speaker:\n",
    "            continue\n",
    "\n",
    "        start_sec = float(row[\"start_time\"])\n",
    "        end_sec   = float(row[\"stop_time\"])\n",
    "        if np.isnan(start_sec) or np.isnan(end_sec):\n",
    "            continue\n",
    "\n",
    "        start_idx = int(start_sec * sr)\n",
    "        end_idx   = int(end_sec * sr)\n",
    "\n",
    "        # Clip to audio boundaries\n",
    "        start_idx = max(0, min(start_idx, len(y_full)))\n",
    "        end_idx   = max(0, min(end_idx, len(y_full)))\n",
    "\n",
    "        if end_idx > start_idx:\n",
    "            keep_segments.append(y_full[start_idx:end_idx])\n",
    "\n",
    "    # Concatenate kept segments\n",
    "    if keep_segments:\n",
    "        y_clean = np.concatenate(keep_segments)\n",
    "    else:\n",
    "        y_clean = y_full  # fallback\n",
    "\n",
    "    clean_duration = len(y_clean) / sr\n",
    "\n",
    "    # Print both lengths\n",
    "    print(f\"Participant {pid}:\")\n",
    "    print(f\" - Original audio length: {full_duration:.2f} seconds\")\n",
    "    print(f\" - Cleaned audio length (no Ellie): {clean_duration:.2f} seconds\")\n",
    "\n",
    "    return y_full, y_clean, sr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c13fe6",
   "metadata": {},
   "source": [
    "### Summarize Feature Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b51750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def summarize_feature_matrix(mat, prefix):\n",
    "    \"\"\"\n",
    "    mat: 2D numpy array (n_features x n_frames)\n",
    "    prefix: string for column names, e.g. 'mfcc', 'delta', 'delta2'\n",
    "    \n",
    "    Returns: pandas.Series with stats for each row:\n",
    "             {prefix}_{i}_mean, _std, _min, _max\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    n_features = mat.shape[0]\n",
    "    for i in range(n_features):\n",
    "        row = mat[i, :]\n",
    "        row = row[np.isfinite(row)]  # just in case\n",
    "\n",
    "        if row.size == 0:\n",
    "            mean = std = rmin = rmax = np.nan\n",
    "        else:\n",
    "            mean = row.mean()\n",
    "            std  = row.std()\n",
    "            rmin = row.min()\n",
    "            rmax = row.max()\n",
    "        \n",
    "        stats[f\"{prefix}_{i+1}_mean\"] = mean\n",
    "        stats[f\"{prefix}_{i+1}_std\"]  = std\n",
    "        stats[f\"{prefix}_{i+1}_min\"]  = rmin\n",
    "        stats[f\"{prefix}_{i+1}_max\"]  = rmax\n",
    "\n",
    "    return pd.Series(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7da4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LogMel Spectogram Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fca25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_logmel_family_features(y, sr, n_mels=64, prefix=\"logmel\"):\n",
    "    \"\"\"\n",
    "    Extract Log-Mel Spectrogram + Delta + Delta-Delta\n",
    "    Then summarize each into statistical features.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series (one row of features)\n",
    "    \"\"\"\n",
    "\n",
    "    feats = {}\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 1. Mel-Spectrogram (power)\n",
    "    # -------------------------------------------------\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0     # energy spectrogram\n",
    "    )\n",
    "\n",
    "    # Convert to log-mel\n",
    "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    mel_stats = summarize_feature_matrix(logmel, prefix=f\"{prefix}\")\n",
    "    feats.update(mel_stats.to_dict())\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 2. Delta (1st-order derivative)\n",
    "    # -------------------------------------------------\n",
    "    mel_delta = librosa.feature.delta(logmel)\n",
    "    mel_delta_stats = summarize_feature_matrix(mel_delta, prefix=f\"{prefix}_delta\")\n",
    "    feats.update(mel_delta_stats.to_dict())\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3. Delta-Delta (2nd-order derivative)\n",
    "    # -------------------------------------------------\n",
    "    mel_delta2 = librosa.feature.delta(logmel, order=2)\n",
    "    mel_delta2_stats = summarize_feature_matrix(mel_delta2, prefix=f\"{prefix}_delta2\")\n",
    "    feats.update(mel_delta2_stats.to_dict())\n",
    "\n",
    "    return pd.Series(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed4b26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant 300:\n",
      " - Original audio length: 648.50 seconds\n",
      " - Cleaned audio length (no Ellie): 155.76 seconds\n",
      "Log-Mel DF shape: (1, 769)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logmel_1_mean</th>\n",
       "      <th>logmel_1_std</th>\n",
       "      <th>logmel_1_min</th>\n",
       "      <th>logmel_1_max</th>\n",
       "      <th>logmel_2_mean</th>\n",
       "      <th>logmel_2_std</th>\n",
       "      <th>logmel_2_min</th>\n",
       "      <th>logmel_2_max</th>\n",
       "      <th>logmel_3_mean</th>\n",
       "      <th>logmel_3_std</th>\n",
       "      <th>...</th>\n",
       "      <th>logmel_delta2_62_max</th>\n",
       "      <th>logmel_delta2_63_mean</th>\n",
       "      <th>logmel_delta2_63_std</th>\n",
       "      <th>logmel_delta2_63_min</th>\n",
       "      <th>logmel_delta2_63_max</th>\n",
       "      <th>logmel_delta2_64_mean</th>\n",
       "      <th>logmel_delta2_64_std</th>\n",
       "      <th>logmel_delta2_64_min</th>\n",
       "      <th>logmel_delta2_64_max</th>\n",
       "      <th>Participant_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39.851742</td>\n",
       "      <td>5.740917</td>\n",
       "      <td>-50.290749</td>\n",
       "      <td>-10.951934</td>\n",
       "      <td>-36.666473</td>\n",
       "      <td>9.424625</td>\n",
       "      <td>-59.953186</td>\n",
       "      <td>-1.421984</td>\n",
       "      <td>-32.704754</td>\n",
       "      <td>10.618219</td>\n",
       "      <td>...</td>\n",
       "      <td>2.475754</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.306427</td>\n",
       "      <td>-2.576145</td>\n",
       "      <td>2.543875</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.286238</td>\n",
       "      <td>-2.665952</td>\n",
       "      <td>2.558672</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   logmel_1_mean  logmel_1_std  logmel_1_min  logmel_1_max  logmel_2_mean  \\\n",
       "0     -39.851742      5.740917    -50.290749    -10.951934     -36.666473   \n",
       "\n",
       "   logmel_2_std  logmel_2_min  logmel_2_max  logmel_3_mean  logmel_3_std  ...  \\\n",
       "0      9.424625    -59.953186     -1.421984     -32.704754     10.618219  ...   \n",
       "\n",
       "   logmel_delta2_62_max  logmel_delta2_63_mean  logmel_delta2_63_std  \\\n",
       "0              2.475754               0.000095              0.306427   \n",
       "\n",
       "   logmel_delta2_63_min  logmel_delta2_63_max  logmel_delta2_64_mean  \\\n",
       "0             -2.576145              2.543875               0.000019   \n",
       "\n",
       "   logmel_delta2_64_std  logmel_delta2_64_min  logmel_delta2_64_max  \\\n",
       "0              0.286238             -2.665952              2.558672   \n",
       "\n",
       "   Participant_ID  \n",
       "0           300.0  \n",
       "\n",
       "[1 rows x 769 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pid = 300\n",
    "y_full, y_clean, sr = load_audio_and_clean(pid)\n",
    "\n",
    "logmel_series = extract_logmel_family_features(y_clean, sr)\n",
    "logmel_series[\"Participant_ID\"] = pid\n",
    "\n",
    "df_logmel = logmel_series.to_frame().T\n",
    "\n",
    "print(\"Log-Mel DF shape:\", df_logmel.shape)\n",
    "display(df_logmel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a04cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total participants detected: 189\n",
      "First 10 participants: [300, 301, 302, 303, 304, 305, 306, 307, 308, 309]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ---- 1. Get all participant IDs ----\n",
    "participant_ids = sorted([\n",
    "    int(f.name.split(\"_\")[0])\n",
    "    for f in base_path.iterdir()\n",
    "    if f.is_dir() and f.name.endswith(\"_P\")\n",
    "])\n",
    "\n",
    "print(\"Total participants detected:\", len(participant_ids))\n",
    "print(\"First 10 participants:\", participant_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0be20962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Participant: 300\n",
      "Participant 300:\n",
      " - Original audio length: 648.50 seconds\n",
      " - Cleaned audio length (no Ellie): 155.76 seconds\n",
      "\n",
      "Processing Participant: 301\n",
      "Participant 301:\n",
      " - Original audio length: 823.90 seconds\n",
      " - Cleaned audio length (no Ellie): 475.44 seconds\n",
      "\n",
      "Processing Participant: 302\n",
      "Participant 302:\n",
      " - Original audio length: 758.80 seconds\n",
      " - Cleaned audio length (no Ellie): 208.93 seconds\n",
      "\n",
      "Processing Participant: 303\n",
      "Participant 303:\n",
      " - Original audio length: 985.30 seconds\n",
      " - Cleaned audio length (no Ellie): 642.93 seconds\n",
      "\n",
      "Processing Participant: 304\n",
      "Participant 304:\n",
      " - Original audio length: 792.60 seconds\n",
      " - Cleaned audio length (no Ellie): 362.60 seconds\n",
      "\n",
      "Processing Participant: 305\n",
      "Participant 305:\n",
      " - Original audio length: 1704.00 seconds\n",
      " - Cleaned audio length (no Ellie): 1118.49 seconds\n",
      "\n",
      "Processing Participant: 306\n",
      "Participant 306:\n",
      " - Original audio length: 858.10 seconds\n",
      " - Cleaned audio length (no Ellie): 509.37 seconds\n",
      "\n",
      "Processing Participant: 307\n",
      "Participant 307:\n",
      " - Original audio length: 1238.80 seconds\n",
      " - Cleaned audio length (no Ellie): 843.79 seconds\n",
      "\n",
      "Processing Participant: 308\n",
      "Participant 308:\n",
      " - Original audio length: 867.60 seconds\n",
      " - Cleaned audio length (no Ellie): 326.71 seconds\n",
      "\n",
      "Processing Participant: 309\n",
      "Participant 309:\n",
      " - Original audio length: 705.80 seconds\n",
      " - Cleaned audio length (no Ellie): 182.02 seconds\n",
      "\n",
      "Processing Participant: 310\n",
      "Participant 310:\n",
      " - Original audio length: 844.90 seconds\n",
      " - Cleaned audio length (no Ellie): 285.85 seconds\n",
      "\n",
      "Processing Participant: 311\n",
      "Participant 311:\n",
      " - Original audio length: 785.60 seconds\n",
      " - Cleaned audio length (no Ellie): 200.76 seconds\n",
      "\n",
      "Processing Participant: 312\n",
      "Participant 312:\n",
      " - Original audio length: 790.00 seconds\n",
      " - Cleaned audio length (no Ellie): 313.90 seconds\n",
      "\n",
      "Processing Participant: 313\n",
      "Participant 313:\n",
      " - Original audio length: 753.80 seconds\n",
      " - Cleaned audio length (no Ellie): 267.84 seconds\n",
      "\n",
      "Processing Participant: 314\n",
      "Participant 314:\n",
      " - Original audio length: 1546.70 seconds\n",
      " - Cleaned audio length (no Ellie): 1018.17 seconds\n",
      "\n",
      "Processing Participant: 315\n",
      "Participant 315:\n",
      " - Original audio length: 975.40 seconds\n",
      " - Cleaned audio length (no Ellie): 472.96 seconds\n",
      "\n",
      "Processing Participant: 316\n",
      "Participant 316:\n",
      " - Original audio length: 869.00 seconds\n",
      " - Cleaned audio length (no Ellie): 205.67 seconds\n",
      "\n",
      "Processing Participant: 317\n",
      "Participant 317:\n",
      " - Original audio length: 804.90 seconds\n",
      " - Cleaned audio length (no Ellie): 242.32 seconds\n",
      "\n",
      "Processing Participant: 318\n",
      "Participant 318:\n",
      " - Original audio length: 588.40 seconds\n",
      " - Cleaned audio length (no Ellie): 229.52 seconds\n",
      "\n",
      "Processing Participant: 319\n",
      "Participant 319:\n",
      " - Original audio length: 679.70 seconds\n",
      " - Cleaned audio length (no Ellie): 224.47 seconds\n",
      "\n",
      "Processing Participant: 320\n",
      "Participant 320:\n",
      " - Original audio length: 840.70 seconds\n",
      " - Cleaned audio length (no Ellie): 249.25 seconds\n",
      "\n",
      "Processing Participant: 321\n",
      "Participant 321:\n",
      " - Original audio length: 821.90 seconds\n",
      " - Cleaned audio length (no Ellie): 290.45 seconds\n",
      "\n",
      "Processing Participant: 322\n",
      "Participant 322:\n",
      " - Original audio length: 1047.10 seconds\n",
      " - Cleaned audio length (no Ellie): 477.13 seconds\n",
      "\n",
      "Processing Participant: 323\n",
      "Participant 323:\n",
      " - Original audio length: 837.00 seconds\n",
      " - Cleaned audio length (no Ellie): 385.07 seconds\n",
      "\n",
      "Processing Participant: 324\n",
      "Participant 324:\n",
      " - Original audio length: 721.30 seconds\n",
      " - Cleaned audio length (no Ellie): 274.90 seconds\n",
      "\n",
      "Processing Participant: 325\n",
      "Participant 325:\n",
      " - Original audio length: 875.00 seconds\n",
      " - Cleaned audio length (no Ellie): 514.75 seconds\n",
      "\n",
      "Processing Participant: 326\n",
      "Participant 326:\n",
      " - Original audio length: 699.20 seconds\n",
      " - Cleaned audio length (no Ellie): 168.51 seconds\n",
      "\n",
      "Processing Participant: 327\n",
      "Participant 327:\n",
      " - Original audio length: 680.80 seconds\n",
      " - Cleaned audio length (no Ellie): 266.57 seconds\n",
      "\n",
      "Processing Participant: 328\n",
      "Participant 328:\n",
      " - Original audio length: 1065.20 seconds\n",
      " - Cleaned audio length (no Ellie): 664.26 seconds\n",
      "\n",
      "Processing Participant: 329\n",
      "Participant 329:\n",
      " - Original audio length: 706.30 seconds\n",
      " - Cleaned audio length (no Ellie): 375.21 seconds\n",
      "\n",
      "Processing Participant: 330\n",
      "Participant 330:\n",
      " - Original audio length: 771.50 seconds\n",
      " - Cleaned audio length (no Ellie): 192.15 seconds\n",
      "\n",
      "Processing Participant: 331\n",
      "Participant 331:\n",
      " - Original audio length: 850.70 seconds\n",
      " - Cleaned audio length (no Ellie): 402.79 seconds\n",
      "\n",
      "Processing Participant: 332\n",
      "Participant 332:\n",
      " - Original audio length: 874.10 seconds\n",
      " - Cleaned audio length (no Ellie): 298.97 seconds\n",
      "\n",
      "Processing Participant: 333\n",
      "Participant 333:\n",
      " - Original audio length: 969.30 seconds\n",
      " - Cleaned audio length (no Ellie): 413.19 seconds\n",
      "\n",
      "Processing Participant: 334\n",
      "Participant 334:\n",
      " - Original audio length: 980.00 seconds\n",
      " - Cleaned audio length (no Ellie): 441.70 seconds\n",
      "\n",
      "Processing Participant: 335\n",
      "Participant 335:\n",
      " - Original audio length: 830.10 seconds\n",
      " - Cleaned audio length (no Ellie): 431.16 seconds\n",
      "\n",
      "Processing Participant: 336\n",
      "Participant 336:\n",
      " - Original audio length: 944.50 seconds\n",
      " - Cleaned audio length (no Ellie): 385.57 seconds\n",
      "\n",
      "Processing Participant: 337\n",
      "Participant 337:\n",
      " - Original audio length: 1871.20 seconds\n",
      " - Cleaned audio length (no Ellie): 1282.82 seconds\n",
      "\n",
      "Processing Participant: 338\n",
      "Participant 338:\n",
      " - Original audio length: 596.80 seconds\n",
      " - Cleaned audio length (no Ellie): 279.75 seconds\n",
      "\n",
      "Processing Participant: 339\n",
      "Participant 339:\n",
      " - Original audio length: 862.90 seconds\n",
      " - Cleaned audio length (no Ellie): 419.06 seconds\n",
      "\n",
      "Processing Participant: 340\n",
      "Participant 340:\n",
      " - Original audio length: 599.30 seconds\n",
      " - Cleaned audio length (no Ellie): 171.39 seconds\n",
      "\n",
      "Processing Participant: 341\n",
      "Participant 341:\n",
      " - Original audio length: 867.50 seconds\n",
      " - Cleaned audio length (no Ellie): 385.11 seconds\n",
      "\n",
      "Processing Participant: 343\n",
      "Participant 343:\n",
      " - Original audio length: 927.30 seconds\n",
      " - Cleaned audio length (no Ellie): 237.05 seconds\n",
      "\n",
      "Processing Participant: 344\n",
      "Participant 344:\n",
      " - Original audio length: 1090.50 seconds\n",
      " - Cleaned audio length (no Ellie): 604.25 seconds\n",
      "\n",
      "Processing Participant: 345\n",
      "Participant 345:\n",
      " - Original audio length: 793.90 seconds\n",
      " - Cleaned audio length (no Ellie): 481.39 seconds\n",
      "\n",
      "Processing Participant: 346\n",
      "Participant 346:\n",
      " - Original audio length: 1221.80 seconds\n",
      " - Cleaned audio length (no Ellie): 653.22 seconds\n",
      "\n",
      "Processing Participant: 347\n",
      "Participant 347:\n",
      " - Original audio length: 611.60 seconds\n",
      " - Cleaned audio length (no Ellie): 127.97 seconds\n",
      "\n",
      "Processing Participant: 348\n",
      "Participant 348:\n",
      " - Original audio length: 719.40 seconds\n",
      " - Cleaned audio length (no Ellie): 296.49 seconds\n",
      "\n",
      "Processing Participant: 349\n",
      "Participant 349:\n",
      " - Original audio length: 1216.00 seconds\n",
      " - Cleaned audio length (no Ellie): 515.82 seconds\n",
      "\n",
      "Processing Participant: 350\n",
      "Participant 350:\n",
      " - Original audio length: 881.80 seconds\n",
      " - Cleaned audio length (no Ellie): 458.73 seconds\n",
      "\n",
      "Processing Participant: 351\n",
      "Participant 351:\n",
      " - Original audio length: 769.60 seconds\n",
      " - Cleaned audio length (no Ellie): 406.88 seconds\n",
      "\n",
      "Processing Participant: 352\n",
      "Participant 352:\n",
      " - Original audio length: 760.10 seconds\n",
      " - Cleaned audio length (no Ellie): 499.50 seconds\n",
      "\n",
      "Processing Participant: 353\n",
      "Participant 353:\n",
      " - Original audio length: 786.00 seconds\n",
      " - Cleaned audio length (no Ellie): 415.40 seconds\n",
      "\n",
      "Processing Participant: 354\n",
      "Participant 354:\n",
      " - Original audio length: 576.80 seconds\n",
      " - Cleaned audio length (no Ellie): 146.38 seconds\n",
      "\n",
      "Processing Participant: 355\n",
      "Participant 355:\n",
      " - Original audio length: 674.70 seconds\n",
      " - Cleaned audio length (no Ellie): 332.36 seconds\n",
      "\n",
      "Processing Participant: 356\n",
      "Participant 356:\n",
      " - Original audio length: 954.00 seconds\n",
      " - Cleaned audio length (no Ellie): 527.73 seconds\n",
      "\n",
      "Processing Participant: 357\n",
      "Participant 357:\n",
      " - Original audio length: 414.80 seconds\n",
      " - Cleaned audio length (no Ellie): 133.94 seconds\n",
      "\n",
      "Processing Participant: 358\n",
      "Participant 358:\n",
      " - Original audio length: 647.90 seconds\n",
      " - Cleaned audio length (no Ellie): 238.33 seconds\n",
      "\n",
      "Processing Participant: 359\n",
      "Participant 359:\n",
      " - Original audio length: 1033.60 seconds\n",
      " - Cleaned audio length (no Ellie): 603.63 seconds\n",
      "\n",
      "Processing Participant: 360\n",
      "Participant 360:\n",
      " - Original audio length: 440.40 seconds\n",
      " - Cleaned audio length (no Ellie): 202.93 seconds\n",
      "\n",
      "Processing Participant: 361\n",
      "Participant 361:\n",
      " - Original audio length: 641.90 seconds\n",
      " - Cleaned audio length (no Ellie): 381.56 seconds\n",
      "\n",
      "Processing Participant: 362\n",
      "Participant 362:\n",
      " - Original audio length: 590.20 seconds\n",
      " - Cleaned audio length (no Ellie): 267.17 seconds\n",
      "\n",
      "Processing Participant: 363\n",
      "Participant 363:\n",
      " - Original audio length: 1227.10 seconds\n",
      " - Cleaned audio length (no Ellie): 709.33 seconds\n",
      "\n",
      "Processing Participant: 364\n",
      "Participant 364:\n",
      " - Original audio length: 1781.50 seconds\n",
      " - Cleaned audio length (no Ellie): 1174.94 seconds\n",
      "\n",
      "Processing Participant: 365\n",
      "Participant 365:\n",
      " - Original audio length: 1386.10 seconds\n",
      " - Cleaned audio length (no Ellie): 606.01 seconds\n",
      "\n",
      "Processing Participant: 366\n",
      "Participant 366:\n",
      " - Original audio length: 1312.70 seconds\n",
      " - Cleaned audio length (no Ellie): 781.62 seconds\n",
      "\n",
      "Processing Participant: 367\n",
      "Participant 367:\n",
      " - Original audio length: 1637.00 seconds\n",
      " - Cleaned audio length (no Ellie): 987.24 seconds\n",
      "\n",
      "Processing Participant: 368\n",
      "Participant 368:\n",
      " - Original audio length: 1354.80 seconds\n",
      " - Cleaned audio length (no Ellie): 911.29 seconds\n",
      "\n",
      "Processing Participant: 369\n",
      "Participant 369:\n",
      " - Original audio length: 1041.10 seconds\n",
      " - Cleaned audio length (no Ellie): 732.90 seconds\n",
      "\n",
      "Processing Participant: 370\n",
      "Participant 370:\n",
      " - Original audio length: 1208.60 seconds\n",
      " - Cleaned audio length (no Ellie): 790.01 seconds\n",
      "\n",
      "Processing Participant: 371\n",
      "Participant 371:\n",
      " - Original audio length: 911.70 seconds\n",
      " - Cleaned audio length (no Ellie): 253.26 seconds\n",
      "\n",
      "Processing Participant: 372\n",
      "Participant 372:\n",
      " - Original audio length: 1513.70 seconds\n",
      " - Cleaned audio length (no Ellie): 706.70 seconds\n",
      "\n",
      "Processing Participant: 373\n",
      "Participant 373:\n",
      " - Original audio length: 1265.10 seconds\n",
      " - Cleaned audio length (no Ellie): 846.84 seconds\n",
      "\n",
      "Processing Participant: 374\n",
      "Participant 374:\n",
      " - Original audio length: 1287.70 seconds\n",
      " - Cleaned audio length (no Ellie): 760.88 seconds\n",
      "\n",
      "Processing Participant: 375\n",
      "Participant 375:\n",
      " - Original audio length: 621.20 seconds\n",
      " - Cleaned audio length (no Ellie): 135.32 seconds\n",
      "\n",
      "Processing Participant: 376\n",
      "Participant 376:\n",
      " - Original audio length: 1025.70 seconds\n",
      " - Cleaned audio length (no Ellie): 530.27 seconds\n",
      "\n",
      "Processing Participant: 377\n",
      "Participant 377:\n",
      " - Original audio length: 1328.30 seconds\n",
      " - Cleaned audio length (no Ellie): 803.77 seconds\n",
      "\n",
      "Processing Participant: 378\n",
      "Participant 378:\n",
      " - Original audio length: 873.40 seconds\n",
      " - Cleaned audio length (no Ellie): 413.31 seconds\n",
      "\n",
      "Processing Participant: 379\n",
      "Participant 379:\n",
      " - Original audio length: 1002.10 seconds\n",
      " - Cleaned audio length (no Ellie): 611.96 seconds\n",
      "\n",
      "Processing Participant: 380\n",
      "Participant 380:\n",
      " - Original audio length: 1966.20 seconds\n",
      " - Cleaned audio length (no Ellie): 1214.89 seconds\n",
      "\n",
      "Processing Participant: 381\n",
      "Participant 381:\n",
      " - Original audio length: 1089.30 seconds\n",
      " - Cleaned audio length (no Ellie): 463.37 seconds\n",
      "\n",
      "Processing Participant: 382\n",
      "Participant 382:\n",
      " - Original audio length: 824.20 seconds\n",
      " - Cleaned audio length (no Ellie): 295.76 seconds\n",
      "\n",
      "Processing Participant: 383\n",
      "Participant 383:\n",
      " - Original audio length: 1369.10 seconds\n",
      " - Cleaned audio length (no Ellie): 891.93 seconds\n",
      "\n",
      "Processing Participant: 384\n",
      "Participant 384:\n",
      " - Original audio length: 1056.80 seconds\n",
      " - Cleaned audio length (no Ellie): 431.21 seconds\n",
      "\n",
      "Processing Participant: 385\n",
      "Participant 385:\n",
      " - Original audio length: 536.30 seconds\n",
      " - Cleaned audio length (no Ellie): 62.23 seconds\n",
      "\n",
      "Processing Participant: 386\n",
      "Participant 386:\n",
      " - Original audio length: 1039.40 seconds\n",
      " - Cleaned audio length (no Ellie): 650.62 seconds\n",
      "\n",
      "Processing Participant: 387\n",
      "Participant 387:\n",
      " - Original audio length: 602.80 seconds\n",
      " - Cleaned audio length (no Ellie): 168.27 seconds\n",
      "\n",
      "Processing Participant: 388\n",
      "Participant 388:\n",
      " - Original audio length: 831.20 seconds\n",
      " - Cleaned audio length (no Ellie): 154.96 seconds\n",
      "\n",
      "Processing Participant: 389\n",
      "Participant 389:\n",
      " - Original audio length: 953.20 seconds\n",
      " - Cleaned audio length (no Ellie): 225.15 seconds\n",
      "\n",
      "Processing Participant: 390\n",
      "Participant 390:\n",
      " - Original audio length: 1356.70 seconds\n",
      " - Cleaned audio length (no Ellie): 632.77 seconds\n",
      "\n",
      "Processing Participant: 391\n",
      "Participant 391:\n",
      " - Original audio length: 680.10 seconds\n",
      " - Cleaned audio length (no Ellie): 212.72 seconds\n",
      "\n",
      "Processing Participant: 392\n",
      "Participant 392:\n",
      " - Original audio length: 655.70 seconds\n",
      " - Cleaned audio length (no Ellie): 216.23 seconds\n",
      "\n",
      "Processing Participant: 393\n",
      "Participant 393:\n",
      " - Original audio length: 630.00 seconds\n",
      " - Cleaned audio length (no Ellie): 205.95 seconds\n",
      "\n",
      "Processing Participant: 395\n",
      "Participant 395:\n",
      " - Original audio length: 889.20 seconds\n",
      " - Cleaned audio length (no Ellie): 430.92 seconds\n",
      "\n",
      "Processing Participant: 396\n",
      "Participant 396:\n",
      " - Original audio length: 780.40 seconds\n",
      " - Cleaned audio length (no Ellie): 309.56 seconds\n",
      "\n",
      "Processing Participant: 397\n",
      "Participant 397:\n",
      " - Original audio length: 953.30 seconds\n",
      " - Cleaned audio length (no Ellie): 442.87 seconds\n",
      "\n",
      "Processing Participant: 399\n",
      "Participant 399:\n",
      " - Original audio length: 734.00 seconds\n",
      " - Cleaned audio length (no Ellie): 336.54 seconds\n",
      "\n",
      "Processing Participant: 400\n",
      "Participant 400:\n",
      " - Original audio length: 936.70 seconds\n",
      " - Cleaned audio length (no Ellie): 412.45 seconds\n",
      "\n",
      "Processing Participant: 401\n",
      "Participant 401:\n",
      " - Original audio length: 934.20 seconds\n",
      " - Cleaned audio length (no Ellie): 421.58 seconds\n",
      "\n",
      "Processing Participant: 402\n",
      "Participant 402:\n",
      " - Original audio length: 955.50 seconds\n",
      " - Cleaned audio length (no Ellie): 447.60 seconds\n",
      "\n",
      "Processing Participant: 403\n",
      "Participant 403:\n",
      " - Original audio length: 862.50 seconds\n",
      " - Cleaned audio length (no Ellie): 443.06 seconds\n",
      "\n",
      "Processing Participant: 404\n",
      "Participant 404:\n",
      " - Original audio length: 1130.60 seconds\n",
      " - Cleaned audio length (no Ellie): 480.09 seconds\n",
      "\n",
      "Processing Participant: 405\n",
      "Participant 405:\n",
      " - Original audio length: 1570.20 seconds\n",
      " - Cleaned audio length (no Ellie): 853.56 seconds\n",
      "\n",
      "Processing Participant: 406\n",
      "Participant 406:\n",
      " - Original audio length: 721.80 seconds\n",
      " - Cleaned audio length (no Ellie): 305.06 seconds\n",
      "\n",
      "Processing Participant: 407\n",
      "Participant 407:\n",
      " - Original audio length: 1252.40 seconds\n",
      " - Cleaned audio length (no Ellie): 825.16 seconds\n",
      "\n",
      "Processing Participant: 408\n",
      "Participant 408:\n",
      " - Original audio length: 715.90 seconds\n",
      " - Cleaned audio length (no Ellie): 321.33 seconds\n",
      "\n",
      "Processing Participant: 409\n",
      "Participant 409:\n",
      " - Original audio length: 1032.40 seconds\n",
      " - Cleaned audio length (no Ellie): 578.36 seconds\n",
      "\n",
      "Processing Participant: 410\n",
      "Participant 410:\n",
      " - Original audio length: 1065.00 seconds\n",
      " - Cleaned audio length (no Ellie): 551.04 seconds\n",
      "\n",
      "Processing Participant: 411\n",
      "Participant 411:\n",
      " - Original audio length: 1382.90 seconds\n",
      " - Cleaned audio length (no Ellie): 906.92 seconds\n",
      "\n",
      "Processing Participant: 412\n",
      "Participant 412:\n",
      " - Original audio length: 856.90 seconds\n",
      " - Cleaned audio length (no Ellie): 330.72 seconds\n",
      "\n",
      "Processing Participant: 413\n",
      "Participant 413:\n",
      " - Original audio length: 996.80 seconds\n",
      " - Cleaned audio length (no Ellie): 518.55 seconds\n",
      "\n",
      "Processing Participant: 414\n",
      "Participant 414:\n",
      " - Original audio length: 984.30 seconds\n",
      " - Cleaned audio length (no Ellie): 523.03 seconds\n",
      "\n",
      "Processing Participant: 415\n",
      "Participant 415:\n",
      " - Original audio length: 780.70 seconds\n",
      " - Cleaned audio length (no Ellie): 351.08 seconds\n",
      "\n",
      "Processing Participant: 416\n",
      "Participant 416:\n",
      " - Original audio length: 865.80 seconds\n",
      " - Cleaned audio length (no Ellie): 432.56 seconds\n",
      "\n",
      "Processing Participant: 417\n",
      "Participant 417:\n",
      " - Original audio length: 886.30 seconds\n",
      " - Cleaned audio length (no Ellie): 439.40 seconds\n",
      "\n",
      "Processing Participant: 418\n",
      "Participant 418:\n",
      " - Original audio length: 1089.20 seconds\n",
      " - Cleaned audio length (no Ellie): 587.04 seconds\n",
      "\n",
      "Processing Participant: 419\n",
      "Participant 419:\n",
      " - Original audio length: 906.30 seconds\n",
      " - Cleaned audio length (no Ellie): 561.11 seconds\n",
      "\n",
      "Processing Participant: 420\n",
      "Participant 420:\n",
      " - Original audio length: 1048.90 seconds\n",
      " - Cleaned audio length (no Ellie): 383.83 seconds\n",
      "\n",
      "Processing Participant: 421\n",
      "Participant 421:\n",
      " - Original audio length: 837.00 seconds\n",
      " - Cleaned audio length (no Ellie): 378.75 seconds\n",
      "\n",
      "Processing Participant: 422\n",
      "Participant 422:\n",
      " - Original audio length: 1334.60 seconds\n",
      " - Cleaned audio length (no Ellie): 750.47 seconds\n",
      "\n",
      "Processing Participant: 423\n",
      "Participant 423:\n",
      " - Original audio length: 995.90 seconds\n",
      " - Cleaned audio length (no Ellie): 433.09 seconds\n",
      "\n",
      "Processing Participant: 424\n",
      "Participant 424:\n",
      " - Original audio length: 1062.70 seconds\n",
      " - Cleaned audio length (no Ellie): 719.49 seconds\n",
      "\n",
      "Processing Participant: 425\n",
      "Participant 425:\n",
      " - Original audio length: 1154.80 seconds\n",
      " - Cleaned audio length (no Ellie): 613.49 seconds\n",
      "\n",
      "Processing Participant: 426\n",
      "Participant 426:\n",
      " - Original audio length: 856.80 seconds\n",
      " - Cleaned audio length (no Ellie): 340.63 seconds\n",
      "\n",
      "Processing Participant: 427\n",
      "Participant 427:\n",
      " - Original audio length: 871.80 seconds\n",
      " - Cleaned audio length (no Ellie): 322.40 seconds\n",
      "\n",
      "Processing Participant: 428\n",
      "Participant 428:\n",
      " - Original audio length: 704.10 seconds\n",
      " - Cleaned audio length (no Ellie): 249.44 seconds\n",
      "\n",
      "Processing Participant: 429\n",
      "Participant 429:\n",
      " - Original audio length: 957.50 seconds\n",
      " - Cleaned audio length (no Ellie): 410.86 seconds\n",
      "\n",
      "Processing Participant: 430\n",
      "Participant 430:\n",
      " - Original audio length: 908.80 seconds\n",
      " - Cleaned audio length (no Ellie): 400.71 seconds\n",
      "\n",
      "Processing Participant: 431\n",
      "Participant 431:\n",
      " - Original audio length: 833.80 seconds\n",
      " - Cleaned audio length (no Ellie): 350.30 seconds\n",
      "\n",
      "Processing Participant: 432\n",
      "Participant 432:\n",
      " - Original audio length: 935.90 seconds\n",
      " - Cleaned audio length (no Ellie): 385.88 seconds\n",
      "\n",
      "Processing Participant: 433\n",
      "Participant 433:\n",
      " - Original audio length: 801.90 seconds\n",
      " - Cleaned audio length (no Ellie): 296.15 seconds\n",
      "\n",
      "Processing Participant: 434\n",
      "Participant 434:\n",
      " - Original audio length: 1319.90 seconds\n",
      " - Cleaned audio length (no Ellie): 813.93 seconds\n",
      "\n",
      "Processing Participant: 435\n",
      "Participant 435:\n",
      " - Original audio length: 1185.00 seconds\n",
      " - Cleaned audio length (no Ellie): 503.44 seconds\n",
      "\n",
      "Processing Participant: 436\n",
      "Participant 436:\n",
      " - Original audio length: 687.90 seconds\n",
      " - Cleaned audio length (no Ellie): 329.39 seconds\n",
      "\n",
      "Processing Participant: 437\n",
      "Participant 437:\n",
      " - Original audio length: 849.60 seconds\n",
      " - Cleaned audio length (no Ellie): 440.99 seconds\n",
      "\n",
      "Processing Participant: 438\n",
      "Participant 438:\n",
      " - Original audio length: 1429.90 seconds\n",
      " - Cleaned audio length (no Ellie): 1035.08 seconds\n",
      "\n",
      "Processing Participant: 439\n",
      "Participant 439:\n",
      " - Original audio length: 1284.60 seconds\n",
      " - Cleaned audio length (no Ellie): 912.70 seconds\n",
      "\n",
      "Processing Participant: 440\n",
      "Participant 440:\n",
      " - Original audio length: 1414.10 seconds\n",
      " - Cleaned audio length (no Ellie): 643.98 seconds\n",
      "\n",
      "Processing Participant: 441\n",
      "Participant 441:\n",
      " - Original audio length: 971.30 seconds\n",
      " - Cleaned audio length (no Ellie): 284.91 seconds\n",
      "\n",
      "Processing Participant: 442\n",
      "Participant 442:\n",
      " - Original audio length: 950.00 seconds\n",
      " - Cleaned audio length (no Ellie): 466.71 seconds\n",
      "\n",
      "Processing Participant: 443\n",
      "Participant 443:\n",
      " - Original audio length: 701.30 seconds\n",
      " - Cleaned audio length (no Ellie): 201.90 seconds\n",
      "\n",
      "Processing Participant: 444\n",
      "Participant 444:\n",
      " - Original audio length: 1310.50 seconds\n",
      " - Cleaned audio length (no Ellie): 841.31 seconds\n",
      "\n",
      "Processing Participant: 445\n",
      "Participant 445:\n",
      " - Original audio length: 709.60 seconds\n",
      " - Cleaned audio length (no Ellie): 310.39 seconds\n",
      "\n",
      "Processing Participant: 446\n",
      "Participant 446:\n",
      " - Original audio length: 998.40 seconds\n",
      " - Cleaned audio length (no Ellie): 578.55 seconds\n",
      "\n",
      "Processing Participant: 447\n",
      "Participant 447:\n",
      " - Original audio length: 820.30 seconds\n",
      " - Cleaned audio length (no Ellie): 442.64 seconds\n",
      "\n",
      "Processing Participant: 448\n",
      "Participant 448:\n",
      " - Original audio length: 1213.00 seconds\n",
      " - Cleaned audio length (no Ellie): 795.01 seconds\n",
      "\n",
      "Processing Participant: 449\n",
      "Participant 449:\n",
      " - Original audio length: 1029.70 seconds\n",
      " - Cleaned audio length (no Ellie): 724.61 seconds\n",
      "\n",
      "Processing Participant: 450\n",
      "Participant 450:\n",
      " - Original audio length: 1275.20 seconds\n",
      " - Cleaned audio length (no Ellie): 723.60 seconds\n",
      "\n",
      "Processing Participant: 451\n",
      "Participant 451:\n",
      " - Original audio length: 1188.40 seconds\n",
      " - Cleaned audio length (no Ellie): 636.25 seconds\n",
      "\n",
      "Processing Participant: 452\n",
      "Participant 452:\n",
      " - Original audio length: 889.10 seconds\n",
      " - Cleaned audio length (no Ellie): 246.68 seconds\n",
      "\n",
      "Processing Participant: 453\n",
      "Participant 453:\n",
      " - Original audio length: 1032.20 seconds\n",
      " - Cleaned audio length (no Ellie): 457.25 seconds\n",
      "\n",
      "Processing Participant: 454\n",
      "Participant 454:\n",
      " - Original audio length: 804.10 seconds\n",
      " - Cleaned audio length (no Ellie): 208.07 seconds\n",
      "\n",
      "Processing Participant: 455\n",
      "Participant 455:\n",
      " - Original audio length: 750.40 seconds\n",
      " - Cleaned audio length (no Ellie): 384.55 seconds\n",
      "\n",
      "Processing Participant: 456\n",
      "Participant 456:\n",
      " - Original audio length: 882.70 seconds\n",
      " - Cleaned audio length (no Ellie): 466.74 seconds\n",
      "\n",
      "Processing Participant: 457\n",
      "Participant 457:\n",
      " - Original audio length: 962.30 seconds\n",
      " - Cleaned audio length (no Ellie): 460.43 seconds\n",
      "\n",
      "Processing Participant: 458\n",
      "Participant 458:\n",
      " - Original audio length: 949.70 seconds\n",
      " - Cleaned audio length (no Ellie): 547.65 seconds\n",
      "\n",
      "Processing Participant: 459\n",
      "Participant 459:\n",
      " - Original audio length: 975.10 seconds\n",
      " - Cleaned audio length (no Ellie): 350.42 seconds\n",
      "\n",
      "Processing Participant: 461\n",
      "Participant 461:\n",
      " - Original audio length: 981.50 seconds\n",
      " - Cleaned audio length (no Ellie): 295.82 seconds\n",
      "\n",
      "Processing Participant: 462\n",
      "Participant 462:\n",
      " - Original audio length: 965.10 seconds\n",
      " - Cleaned audio length (no Ellie): 583.17 seconds\n",
      "\n",
      "Processing Participant: 463\n",
      "Participant 463:\n",
      " - Original audio length: 834.70 seconds\n",
      " - Cleaned audio length (no Ellie): 349.68 seconds\n",
      "\n",
      "Processing Participant: 464\n",
      "Participant 464:\n",
      " - Original audio length: 980.30 seconds\n",
      " - Cleaned audio length (no Ellie): 512.88 seconds\n",
      "\n",
      "Processing Participant: 465\n",
      "Participant 465:\n",
      " - Original audio length: 1163.40 seconds\n",
      " - Cleaned audio length (no Ellie): 693.10 seconds\n",
      "\n",
      "Processing Participant: 466\n",
      "Participant 466:\n",
      " - Original audio length: 1566.50 seconds\n",
      " - Cleaned audio length (no Ellie): 910.94 seconds\n",
      "\n",
      "Processing Participant: 467\n",
      "Participant 467:\n",
      " - Original audio length: 1002.40 seconds\n",
      " - Cleaned audio length (no Ellie): 356.71 seconds\n",
      "\n",
      "Processing Participant: 468\n",
      "Participant 468:\n",
      " - Original audio length: 939.80 seconds\n",
      " - Cleaned audio length (no Ellie): 484.15 seconds\n",
      "\n",
      "Processing Participant: 469\n",
      "Participant 469:\n",
      " - Original audio length: 1126.60 seconds\n",
      " - Cleaned audio length (no Ellie): 629.90 seconds\n",
      "\n",
      "Processing Participant: 470\n",
      "Participant 470:\n",
      " - Original audio length: 955.40 seconds\n",
      " - Cleaned audio length (no Ellie): 493.64 seconds\n",
      "\n",
      "Processing Participant: 471\n",
      "Participant 471:\n",
      " - Original audio length: 995.30 seconds\n",
      " - Cleaned audio length (no Ellie): 591.39 seconds\n",
      "\n",
      "Processing Participant: 472\n",
      "Participant 472:\n",
      " - Original audio length: 903.00 seconds\n",
      " - Cleaned audio length (no Ellie): 391.27 seconds\n",
      "\n",
      "Processing Participant: 473\n",
      "Participant 473:\n",
      " - Original audio length: 533.30 seconds\n",
      " - Cleaned audio length (no Ellie): 94.23 seconds\n",
      "\n",
      "Processing Participant: 474\n",
      "Participant 474:\n",
      " - Original audio length: 927.40 seconds\n",
      " - Cleaned audio length (no Ellie): 459.58 seconds\n",
      "\n",
      "Processing Participant: 475\n",
      "Participant 475:\n",
      " - Original audio length: 587.20 seconds\n",
      " - Cleaned audio length (no Ellie): 204.06 seconds\n",
      "\n",
      "Processing Participant: 476\n",
      "Participant 476:\n",
      " - Original audio length: 608.80 seconds\n",
      " - Cleaned audio length (no Ellie): 195.56 seconds\n",
      "\n",
      "Processing Participant: 477\n",
      "Participant 477:\n",
      " - Original audio length: 1244.70 seconds\n",
      " - Cleaned audio length (no Ellie): 762.77 seconds\n",
      "\n",
      "Processing Participant: 478\n",
      "Participant 478:\n",
      " - Original audio length: 936.20 seconds\n",
      " - Cleaned audio length (no Ellie): 403.35 seconds\n",
      "\n",
      "Processing Participant: 479\n",
      "Participant 479:\n",
      " - Original audio length: 910.40 seconds\n",
      " - Cleaned audio length (no Ellie): 230.10 seconds\n",
      "\n",
      "Processing Participant: 480\n",
      "Participant 480:\n",
      " - Original audio length: 865.70 seconds\n",
      " - Cleaned audio length (no Ellie): 351.74 seconds\n",
      "\n",
      "Processing Participant: 481\n",
      "Participant 481:\n",
      " - Original audio length: 1116.40 seconds\n",
      " - Cleaned audio length (no Ellie): 599.38 seconds\n",
      "\n",
      "Processing Participant: 482\n",
      "Participant 482:\n",
      " - Original audio length: 1019.00 seconds\n",
      " - Cleaned audio length (no Ellie): 505.50 seconds\n",
      "\n",
      "Processing Participant: 483\n",
      "Participant 483:\n",
      " - Original audio length: 1577.00 seconds\n",
      " - Cleaned audio length (no Ellie): 828.50 seconds\n",
      "\n",
      "Processing Participant: 484\n",
      "Participant 484:\n",
      " - Original audio length: 995.50 seconds\n",
      " - Cleaned audio length (no Ellie): 549.49 seconds\n",
      "\n",
      "Processing Participant: 485\n",
      "Participant 485:\n",
      " - Original audio length: 602.70 seconds\n",
      " - Cleaned audio length (no Ellie): 196.10 seconds\n",
      "\n",
      "Processing Participant: 486\n",
      "Participant 486:\n",
      " - Original audio length: 682.30 seconds\n",
      " - Cleaned audio length (no Ellie): 261.81 seconds\n",
      "\n",
      "Processing Participant: 487\n",
      "Participant 487:\n",
      " - Original audio length: 1023.50 seconds\n",
      " - Cleaned audio length (no Ellie): 578.31 seconds\n",
      "\n",
      "Processing Participant: 488\n",
      "Participant 488:\n",
      " - Original audio length: 884.90 seconds\n",
      " - Cleaned audio length (no Ellie): 422.49 seconds\n",
      "\n",
      "Processing Participant: 489\n",
      "Participant 489:\n",
      " - Original audio length: 704.70 seconds\n",
      " - Cleaned audio length (no Ellie): 168.81 seconds\n",
      "\n",
      "Processing Participant: 490\n",
      "Participant 490:\n",
      " - Original audio length: 691.30 seconds\n",
      " - Cleaned audio length (no Ellie): 185.90 seconds\n",
      "\n",
      "Processing Participant: 491\n",
      "Participant 491:\n",
      " - Original audio length: 881.70 seconds\n",
      " - Cleaned audio length (no Ellie): 413.58 seconds\n",
      "\n",
      "Processing Participant: 492\n",
      "Participant 492:\n",
      " - Original audio length: 912.50 seconds\n",
      " - Cleaned audio length (no Ellie): 476.22 seconds\n"
     ]
    }
   ],
   "source": [
    "# ---- 2. Prepare lists for each DF ----\n",
    "logmel_rows     = []\n",
    "# ---- 3. Loop over participants ----\n",
    "for pid in participant_ids:\n",
    "    print(f\"\\nProcessing Participant: {pid}\")\n",
    "\n",
    "    # Load full + cleaned audio\n",
    "    y_full, y_clean, sr = load_audio_and_clean(pid)\n",
    "\n",
    "    # 1) MFCC Family\n",
    "    s_logmel = extract_logmel_family_features(y_clean, sr)\n",
    "    s_logmel[\"Participant_ID\"] = pid\n",
    "    logmel_rows.append(s_logmel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c6a0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path(r\"C:\\Users\\DELL\\Desktop\\Conversational-Health-Analytics-\")\n",
    "dataset_folder = root / \"Dataset\"\n",
    "\n",
    "DF_TRAIN = pd.read_csv(dataset_folder / \"train_split_Depression_AVEC2017.csv\")\n",
    "DF_DEV   = pd.read_csv(dataset_folder / \"dev_split_Depression_AVEC2017.csv\")\n",
    "DF_TEST  = pd.read_csv(dataset_folder / \"full_test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79c650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logmel_all = pd.DataFrame(logmel_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70580e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC+Labels shape: (189, 772)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logmel_1_mean</th>\n",
       "      <th>logmel_1_std</th>\n",
       "      <th>logmel_1_min</th>\n",
       "      <th>logmel_1_max</th>\n",
       "      <th>logmel_2_mean</th>\n",
       "      <th>logmel_2_std</th>\n",
       "      <th>logmel_2_min</th>\n",
       "      <th>logmel_2_max</th>\n",
       "      <th>logmel_3_mean</th>\n",
       "      <th>logmel_3_std</th>\n",
       "      <th>logmel_3_min</th>\n",
       "      <th>logmel_3_max</th>\n",
       "      <th>logmel_4_mean</th>\n",
       "      <th>logmel_4_std</th>\n",
       "      <th>logmel_4_min</th>\n",
       "      <th>logmel_4_max</th>\n",
       "      <th>logmel_5_mean</th>\n",
       "      <th>logmel_5_std</th>\n",
       "      <th>logmel_5_min</th>\n",
       "      <th>logmel_5_max</th>\n",
       "      <th>logmel_6_mean</th>\n",
       "      <th>logmel_6_std</th>\n",
       "      <th>logmel_6_min</th>\n",
       "      <th>logmel_6_max</th>\n",
       "      <th>logmel_7_mean</th>\n",
       "      <th>logmel_7_std</th>\n",
       "      <th>logmel_7_min</th>\n",
       "      <th>logmel_7_max</th>\n",
       "      <th>logmel_8_mean</th>\n",
       "      <th>logmel_8_std</th>\n",
       "      <th>logmel_8_min</th>\n",
       "      <th>logmel_8_max</th>\n",
       "      <th>logmel_9_mean</th>\n",
       "      <th>logmel_9_std</th>\n",
       "      <th>logmel_9_min</th>\n",
       "      <th>logmel_9_max</th>\n",
       "      <th>logmel_10_mean</th>\n",
       "      <th>logmel_10_std</th>\n",
       "      <th>logmel_10_min</th>\n",
       "      <th>logmel_10_max</th>\n",
       "      <th>logmel_11_mean</th>\n",
       "      <th>logmel_11_std</th>\n",
       "      <th>logmel_11_min</th>\n",
       "      <th>logmel_11_max</th>\n",
       "      <th>logmel_12_mean</th>\n",
       "      <th>logmel_12_std</th>\n",
       "      <th>logmel_12_min</th>\n",
       "      <th>logmel_12_max</th>\n",
       "      <th>logmel_13_mean</th>\n",
       "      <th>logmel_13_std</th>\n",
       "      <th>logmel_13_min</th>\n",
       "      <th>logmel_13_max</th>\n",
       "      <th>logmel_14_mean</th>\n",
       "      <th>logmel_14_std</th>\n",
       "      <th>logmel_14_min</th>\n",
       "      <th>logmel_14_max</th>\n",
       "      <th>logmel_15_mean</th>\n",
       "      <th>logmel_15_std</th>\n",
       "      <th>logmel_15_min</th>\n",
       "      <th>logmel_15_max</th>\n",
       "      <th>logmel_16_mean</th>\n",
       "      <th>logmel_16_std</th>\n",
       "      <th>logmel_16_min</th>\n",
       "      <th>logmel_16_max</th>\n",
       "      <th>logmel_17_mean</th>\n",
       "      <th>logmel_17_std</th>\n",
       "      <th>logmel_17_min</th>\n",
       "      <th>logmel_17_max</th>\n",
       "      <th>logmel_18_mean</th>\n",
       "      <th>logmel_18_std</th>\n",
       "      <th>logmel_18_min</th>\n",
       "      <th>logmel_18_max</th>\n",
       "      <th>logmel_19_mean</th>\n",
       "      <th>logmel_19_std</th>\n",
       "      <th>logmel_19_min</th>\n",
       "      <th>logmel_19_max</th>\n",
       "      <th>logmel_20_mean</th>\n",
       "      <th>logmel_20_std</th>\n",
       "      <th>logmel_20_min</th>\n",
       "      <th>logmel_20_max</th>\n",
       "      <th>logmel_21_mean</th>\n",
       "      <th>logmel_21_std</th>\n",
       "      <th>logmel_21_min</th>\n",
       "      <th>logmel_21_max</th>\n",
       "      <th>logmel_22_mean</th>\n",
       "      <th>logmel_22_std</th>\n",
       "      <th>logmel_22_min</th>\n",
       "      <th>logmel_22_max</th>\n",
       "      <th>logmel_23_mean</th>\n",
       "      <th>logmel_23_std</th>\n",
       "      <th>logmel_23_min</th>\n",
       "      <th>logmel_23_max</th>\n",
       "      <th>logmel_24_mean</th>\n",
       "      <th>logmel_24_std</th>\n",
       "      <th>logmel_24_min</th>\n",
       "      <th>logmel_24_max</th>\n",
       "      <th>logmel_25_mean</th>\n",
       "      <th>logmel_25_std</th>\n",
       "      <th>logmel_25_min</th>\n",
       "      <th>logmel_25_max</th>\n",
       "      <th>logmel_26_mean</th>\n",
       "      <th>logmel_26_std</th>\n",
       "      <th>logmel_26_min</th>\n",
       "      <th>logmel_26_max</th>\n",
       "      <th>logmel_27_mean</th>\n",
       "      <th>logmel_27_std</th>\n",
       "      <th>logmel_27_min</th>\n",
       "      <th>logmel_27_max</th>\n",
       "      <th>logmel_28_mean</th>\n",
       "      <th>logmel_28_std</th>\n",
       "      <th>logmel_28_min</th>\n",
       "      <th>logmel_28_max</th>\n",
       "      <th>logmel_29_mean</th>\n",
       "      <th>logmel_29_std</th>\n",
       "      <th>logmel_29_min</th>\n",
       "      <th>logmel_29_max</th>\n",
       "      <th>logmel_30_mean</th>\n",
       "      <th>logmel_30_std</th>\n",
       "      <th>logmel_30_min</th>\n",
       "      <th>logmel_30_max</th>\n",
       "      <th>logmel_31_mean</th>\n",
       "      <th>logmel_31_std</th>\n",
       "      <th>logmel_31_min</th>\n",
       "      <th>logmel_31_max</th>\n",
       "      <th>logmel_32_mean</th>\n",
       "      <th>logmel_32_std</th>\n",
       "      <th>logmel_32_min</th>\n",
       "      <th>logmel_32_max</th>\n",
       "      <th>logmel_33_mean</th>\n",
       "      <th>logmel_33_std</th>\n",
       "      <th>logmel_33_min</th>\n",
       "      <th>logmel_33_max</th>\n",
       "      <th>logmel_34_mean</th>\n",
       "      <th>logmel_34_std</th>\n",
       "      <th>logmel_34_min</th>\n",
       "      <th>logmel_34_max</th>\n",
       "      <th>logmel_35_mean</th>\n",
       "      <th>logmel_35_std</th>\n",
       "      <th>logmel_35_min</th>\n",
       "      <th>logmel_35_max</th>\n",
       "      <th>logmel_36_mean</th>\n",
       "      <th>logmel_36_std</th>\n",
       "      <th>logmel_36_min</th>\n",
       "      <th>logmel_36_max</th>\n",
       "      <th>logmel_37_mean</th>\n",
       "      <th>logmel_37_std</th>\n",
       "      <th>logmel_37_min</th>\n",
       "      <th>logmel_37_max</th>\n",
       "      <th>logmel_38_mean</th>\n",
       "      <th>logmel_38_std</th>\n",
       "      <th>logmel_38_min</th>\n",
       "      <th>logmel_38_max</th>\n",
       "      <th>logmel_39_mean</th>\n",
       "      <th>logmel_39_std</th>\n",
       "      <th>logmel_39_min</th>\n",
       "      <th>logmel_39_max</th>\n",
       "      <th>logmel_40_mean</th>\n",
       "      <th>logmel_40_std</th>\n",
       "      <th>logmel_40_min</th>\n",
       "      <th>logmel_40_max</th>\n",
       "      <th>logmel_41_mean</th>\n",
       "      <th>logmel_41_std</th>\n",
       "      <th>logmel_41_min</th>\n",
       "      <th>logmel_41_max</th>\n",
       "      <th>logmel_42_mean</th>\n",
       "      <th>logmel_42_std</th>\n",
       "      <th>logmel_42_min</th>\n",
       "      <th>logmel_42_max</th>\n",
       "      <th>logmel_43_mean</th>\n",
       "      <th>logmel_43_std</th>\n",
       "      <th>logmel_43_min</th>\n",
       "      <th>logmel_43_max</th>\n",
       "      <th>logmel_44_mean</th>\n",
       "      <th>logmel_44_std</th>\n",
       "      <th>logmel_44_min</th>\n",
       "      <th>logmel_44_max</th>\n",
       "      <th>logmel_45_mean</th>\n",
       "      <th>logmel_45_std</th>\n",
       "      <th>logmel_45_min</th>\n",
       "      <th>logmel_45_max</th>\n",
       "      <th>logmel_46_mean</th>\n",
       "      <th>logmel_46_std</th>\n",
       "      <th>logmel_46_min</th>\n",
       "      <th>logmel_46_max</th>\n",
       "      <th>logmel_47_mean</th>\n",
       "      <th>logmel_47_std</th>\n",
       "      <th>logmel_47_min</th>\n",
       "      <th>logmel_47_max</th>\n",
       "      <th>logmel_48_mean</th>\n",
       "      <th>logmel_48_std</th>\n",
       "      <th>logmel_48_min</th>\n",
       "      <th>logmel_48_max</th>\n",
       "      <th>logmel_49_mean</th>\n",
       "      <th>logmel_49_std</th>\n",
       "      <th>logmel_49_min</th>\n",
       "      <th>logmel_49_max</th>\n",
       "      <th>logmel_50_mean</th>\n",
       "      <th>logmel_50_std</th>\n",
       "      <th>logmel_50_min</th>\n",
       "      <th>logmel_50_max</th>\n",
       "      <th>logmel_51_mean</th>\n",
       "      <th>logmel_51_std</th>\n",
       "      <th>logmel_51_min</th>\n",
       "      <th>logmel_51_max</th>\n",
       "      <th>logmel_52_mean</th>\n",
       "      <th>logmel_52_std</th>\n",
       "      <th>logmel_52_min</th>\n",
       "      <th>logmel_52_max</th>\n",
       "      <th>logmel_53_mean</th>\n",
       "      <th>logmel_53_std</th>\n",
       "      <th>logmel_53_min</th>\n",
       "      <th>logmel_53_max</th>\n",
       "      <th>logmel_54_mean</th>\n",
       "      <th>logmel_54_std</th>\n",
       "      <th>logmel_54_min</th>\n",
       "      <th>logmel_54_max</th>\n",
       "      <th>logmel_55_mean</th>\n",
       "      <th>logmel_55_std</th>\n",
       "      <th>logmel_55_min</th>\n",
       "      <th>logmel_55_max</th>\n",
       "      <th>logmel_56_mean</th>\n",
       "      <th>logmel_56_std</th>\n",
       "      <th>logmel_56_min</th>\n",
       "      <th>logmel_56_max</th>\n",
       "      <th>logmel_57_mean</th>\n",
       "      <th>logmel_57_std</th>\n",
       "      <th>logmel_57_min</th>\n",
       "      <th>logmel_57_max</th>\n",
       "      <th>logmel_58_mean</th>\n",
       "      <th>logmel_58_std</th>\n",
       "      <th>logmel_58_min</th>\n",
       "      <th>logmel_58_max</th>\n",
       "      <th>logmel_59_mean</th>\n",
       "      <th>logmel_59_std</th>\n",
       "      <th>logmel_59_min</th>\n",
       "      <th>logmel_59_max</th>\n",
       "      <th>logmel_60_mean</th>\n",
       "      <th>logmel_60_std</th>\n",
       "      <th>logmel_60_min</th>\n",
       "      <th>logmel_60_max</th>\n",
       "      <th>logmel_61_mean</th>\n",
       "      <th>logmel_61_std</th>\n",
       "      <th>logmel_61_min</th>\n",
       "      <th>logmel_61_max</th>\n",
       "      <th>logmel_62_mean</th>\n",
       "      <th>logmel_62_std</th>\n",
       "      <th>logmel_62_min</th>\n",
       "      <th>logmel_62_max</th>\n",
       "      <th>logmel_63_mean</th>\n",
       "      <th>logmel_63_std</th>\n",
       "      <th>logmel_63_min</th>\n",
       "      <th>logmel_63_max</th>\n",
       "      <th>logmel_64_mean</th>\n",
       "      <th>logmel_64_std</th>\n",
       "      <th>logmel_64_min</th>\n",
       "      <th>logmel_64_max</th>\n",
       "      <th>logmel_delta_1_mean</th>\n",
       "      <th>logmel_delta_1_std</th>\n",
       "      <th>logmel_delta_1_min</th>\n",
       "      <th>logmel_delta_1_max</th>\n",
       "      <th>logmel_delta_2_mean</th>\n",
       "      <th>logmel_delta_2_std</th>\n",
       "      <th>logmel_delta_2_min</th>\n",
       "      <th>logmel_delta_2_max</th>\n",
       "      <th>logmel_delta_3_mean</th>\n",
       "      <th>logmel_delta_3_std</th>\n",
       "      <th>logmel_delta_3_min</th>\n",
       "      <th>logmel_delta_3_max</th>\n",
       "      <th>logmel_delta_4_mean</th>\n",
       "      <th>logmel_delta_4_std</th>\n",
       "      <th>logmel_delta_4_min</th>\n",
       "      <th>logmel_delta_4_max</th>\n",
       "      <th>logmel_delta_5_mean</th>\n",
       "      <th>logmel_delta_5_std</th>\n",
       "      <th>logmel_delta_5_min</th>\n",
       "      <th>logmel_delta_5_max</th>\n",
       "      <th>logmel_delta_6_mean</th>\n",
       "      <th>logmel_delta_6_std</th>\n",
       "      <th>logmel_delta_6_min</th>\n",
       "      <th>logmel_delta_6_max</th>\n",
       "      <th>logmel_delta_7_mean</th>\n",
       "      <th>logmel_delta_7_std</th>\n",
       "      <th>logmel_delta_7_min</th>\n",
       "      <th>logmel_delta_7_max</th>\n",
       "      <th>logmel_delta_8_mean</th>\n",
       "      <th>logmel_delta_8_std</th>\n",
       "      <th>logmel_delta_8_min</th>\n",
       "      <th>logmel_delta_8_max</th>\n",
       "      <th>logmel_delta_9_mean</th>\n",
       "      <th>logmel_delta_9_std</th>\n",
       "      <th>logmel_delta_9_min</th>\n",
       "      <th>logmel_delta_9_max</th>\n",
       "      <th>logmel_delta_10_mean</th>\n",
       "      <th>logmel_delta_10_std</th>\n",
       "      <th>logmel_delta_10_min</th>\n",
       "      <th>logmel_delta_10_max</th>\n",
       "      <th>logmel_delta_11_mean</th>\n",
       "      <th>logmel_delta_11_std</th>\n",
       "      <th>logmel_delta_11_min</th>\n",
       "      <th>logmel_delta_11_max</th>\n",
       "      <th>logmel_delta_12_mean</th>\n",
       "      <th>logmel_delta_12_std</th>\n",
       "      <th>logmel_delta_12_min</th>\n",
       "      <th>logmel_delta_12_max</th>\n",
       "      <th>logmel_delta_13_mean</th>\n",
       "      <th>logmel_delta_13_std</th>\n",
       "      <th>logmel_delta_13_min</th>\n",
       "      <th>logmel_delta_13_max</th>\n",
       "      <th>logmel_delta_14_mean</th>\n",
       "      <th>logmel_delta_14_std</th>\n",
       "      <th>logmel_delta_14_min</th>\n",
       "      <th>logmel_delta_14_max</th>\n",
       "      <th>logmel_delta_15_mean</th>\n",
       "      <th>logmel_delta_15_std</th>\n",
       "      <th>logmel_delta_15_min</th>\n",
       "      <th>logmel_delta_15_max</th>\n",
       "      <th>logmel_delta_16_mean</th>\n",
       "      <th>logmel_delta_16_std</th>\n",
       "      <th>logmel_delta_16_min</th>\n",
       "      <th>logmel_delta_16_max</th>\n",
       "      <th>logmel_delta_17_mean</th>\n",
       "      <th>logmel_delta_17_std</th>\n",
       "      <th>logmel_delta_17_min</th>\n",
       "      <th>logmel_delta_17_max</th>\n",
       "      <th>logmel_delta_18_mean</th>\n",
       "      <th>logmel_delta_18_std</th>\n",
       "      <th>logmel_delta_18_min</th>\n",
       "      <th>logmel_delta_18_max</th>\n",
       "      <th>logmel_delta_19_mean</th>\n",
       "      <th>logmel_delta_19_std</th>\n",
       "      <th>logmel_delta_19_min</th>\n",
       "      <th>logmel_delta_19_max</th>\n",
       "      <th>logmel_delta_20_mean</th>\n",
       "      <th>logmel_delta_20_std</th>\n",
       "      <th>logmel_delta_20_min</th>\n",
       "      <th>logmel_delta_20_max</th>\n",
       "      <th>logmel_delta_21_mean</th>\n",
       "      <th>logmel_delta_21_std</th>\n",
       "      <th>logmel_delta_21_min</th>\n",
       "      <th>logmel_delta_21_max</th>\n",
       "      <th>logmel_delta_22_mean</th>\n",
       "      <th>logmel_delta_22_std</th>\n",
       "      <th>logmel_delta_22_min</th>\n",
       "      <th>logmel_delta_22_max</th>\n",
       "      <th>logmel_delta_23_mean</th>\n",
       "      <th>logmel_delta_23_std</th>\n",
       "      <th>logmel_delta_23_min</th>\n",
       "      <th>logmel_delta_23_max</th>\n",
       "      <th>logmel_delta_24_mean</th>\n",
       "      <th>logmel_delta_24_std</th>\n",
       "      <th>logmel_delta_24_min</th>\n",
       "      <th>logmel_delta_24_max</th>\n",
       "      <th>logmel_delta_25_mean</th>\n",
       "      <th>logmel_delta_25_std</th>\n",
       "      <th>logmel_delta_25_min</th>\n",
       "      <th>logmel_delta_25_max</th>\n",
       "      <th>logmel_delta_26_mean</th>\n",
       "      <th>logmel_delta_26_std</th>\n",
       "      <th>logmel_delta_26_min</th>\n",
       "      <th>logmel_delta_26_max</th>\n",
       "      <th>logmel_delta_27_mean</th>\n",
       "      <th>logmel_delta_27_std</th>\n",
       "      <th>logmel_delta_27_min</th>\n",
       "      <th>logmel_delta_27_max</th>\n",
       "      <th>logmel_delta_28_mean</th>\n",
       "      <th>logmel_delta_28_std</th>\n",
       "      <th>logmel_delta_28_min</th>\n",
       "      <th>logmel_delta_28_max</th>\n",
       "      <th>logmel_delta_29_mean</th>\n",
       "      <th>logmel_delta_29_std</th>\n",
       "      <th>logmel_delta_29_min</th>\n",
       "      <th>logmel_delta_29_max</th>\n",
       "      <th>logmel_delta_30_mean</th>\n",
       "      <th>logmel_delta_30_std</th>\n",
       "      <th>logmel_delta_30_min</th>\n",
       "      <th>logmel_delta_30_max</th>\n",
       "      <th>logmel_delta_31_mean</th>\n",
       "      <th>logmel_delta_31_std</th>\n",
       "      <th>logmel_delta_31_min</th>\n",
       "      <th>logmel_delta_31_max</th>\n",
       "      <th>logmel_delta_32_mean</th>\n",
       "      <th>logmel_delta_32_std</th>\n",
       "      <th>logmel_delta_32_min</th>\n",
       "      <th>logmel_delta_32_max</th>\n",
       "      <th>logmel_delta_33_mean</th>\n",
       "      <th>logmel_delta_33_std</th>\n",
       "      <th>logmel_delta_33_min</th>\n",
       "      <th>logmel_delta_33_max</th>\n",
       "      <th>logmel_delta_34_mean</th>\n",
       "      <th>logmel_delta_34_std</th>\n",
       "      <th>logmel_delta_34_min</th>\n",
       "      <th>logmel_delta_34_max</th>\n",
       "      <th>logmel_delta_35_mean</th>\n",
       "      <th>logmel_delta_35_std</th>\n",
       "      <th>logmel_delta_35_min</th>\n",
       "      <th>logmel_delta_35_max</th>\n",
       "      <th>logmel_delta_36_mean</th>\n",
       "      <th>logmel_delta_36_std</th>\n",
       "      <th>logmel_delta_36_min</th>\n",
       "      <th>logmel_delta_36_max</th>\n",
       "      <th>logmel_delta_37_mean</th>\n",
       "      <th>logmel_delta_37_std</th>\n",
       "      <th>logmel_delta_37_min</th>\n",
       "      <th>logmel_delta_37_max</th>\n",
       "      <th>logmel_delta_38_mean</th>\n",
       "      <th>logmel_delta_38_std</th>\n",
       "      <th>logmel_delta_38_min</th>\n",
       "      <th>logmel_delta_38_max</th>\n",
       "      <th>logmel_delta_39_mean</th>\n",
       "      <th>logmel_delta_39_std</th>\n",
       "      <th>logmel_delta_39_min</th>\n",
       "      <th>logmel_delta_39_max</th>\n",
       "      <th>logmel_delta_40_mean</th>\n",
       "      <th>logmel_delta_40_std</th>\n",
       "      <th>logmel_delta_40_min</th>\n",
       "      <th>logmel_delta_40_max</th>\n",
       "      <th>logmel_delta_41_mean</th>\n",
       "      <th>logmel_delta_41_std</th>\n",
       "      <th>logmel_delta_41_min</th>\n",
       "      <th>logmel_delta_41_max</th>\n",
       "      <th>logmel_delta_42_mean</th>\n",
       "      <th>logmel_delta_42_std</th>\n",
       "      <th>logmel_delta_42_min</th>\n",
       "      <th>logmel_delta_42_max</th>\n",
       "      <th>logmel_delta_43_mean</th>\n",
       "      <th>logmel_delta_43_std</th>\n",
       "      <th>logmel_delta_43_min</th>\n",
       "      <th>logmel_delta_43_max</th>\n",
       "      <th>logmel_delta_44_mean</th>\n",
       "      <th>logmel_delta_44_std</th>\n",
       "      <th>logmel_delta_44_min</th>\n",
       "      <th>logmel_delta_44_max</th>\n",
       "      <th>logmel_delta_45_mean</th>\n",
       "      <th>logmel_delta_45_std</th>\n",
       "      <th>logmel_delta_45_min</th>\n",
       "      <th>logmel_delta_45_max</th>\n",
       "      <th>logmel_delta_46_mean</th>\n",
       "      <th>logmel_delta_46_std</th>\n",
       "      <th>logmel_delta_46_min</th>\n",
       "      <th>logmel_delta_46_max</th>\n",
       "      <th>logmel_delta_47_mean</th>\n",
       "      <th>logmel_delta_47_std</th>\n",
       "      <th>logmel_delta_47_min</th>\n",
       "      <th>logmel_delta_47_max</th>\n",
       "      <th>logmel_delta_48_mean</th>\n",
       "      <th>logmel_delta_48_std</th>\n",
       "      <th>logmel_delta_48_min</th>\n",
       "      <th>logmel_delta_48_max</th>\n",
       "      <th>logmel_delta_49_mean</th>\n",
       "      <th>logmel_delta_49_std</th>\n",
       "      <th>logmel_delta_49_min</th>\n",
       "      <th>logmel_delta_49_max</th>\n",
       "      <th>logmel_delta_50_mean</th>\n",
       "      <th>logmel_delta_50_std</th>\n",
       "      <th>logmel_delta_50_min</th>\n",
       "      <th>logmel_delta_50_max</th>\n",
       "      <th>logmel_delta_51_mean</th>\n",
       "      <th>logmel_delta_51_std</th>\n",
       "      <th>logmel_delta_51_min</th>\n",
       "      <th>logmel_delta_51_max</th>\n",
       "      <th>logmel_delta_52_mean</th>\n",
       "      <th>logmel_delta_52_std</th>\n",
       "      <th>logmel_delta_52_min</th>\n",
       "      <th>logmel_delta_52_max</th>\n",
       "      <th>logmel_delta_53_mean</th>\n",
       "      <th>logmel_delta_53_std</th>\n",
       "      <th>logmel_delta_53_min</th>\n",
       "      <th>logmel_delta_53_max</th>\n",
       "      <th>logmel_delta_54_mean</th>\n",
       "      <th>logmel_delta_54_std</th>\n",
       "      <th>logmel_delta_54_min</th>\n",
       "      <th>logmel_delta_54_max</th>\n",
       "      <th>logmel_delta_55_mean</th>\n",
       "      <th>logmel_delta_55_std</th>\n",
       "      <th>logmel_delta_55_min</th>\n",
       "      <th>logmel_delta_55_max</th>\n",
       "      <th>logmel_delta_56_mean</th>\n",
       "      <th>logmel_delta_56_std</th>\n",
       "      <th>logmel_delta_56_min</th>\n",
       "      <th>logmel_delta_56_max</th>\n",
       "      <th>logmel_delta_57_mean</th>\n",
       "      <th>logmel_delta_57_std</th>\n",
       "      <th>logmel_delta_57_min</th>\n",
       "      <th>logmel_delta_57_max</th>\n",
       "      <th>logmel_delta_58_mean</th>\n",
       "      <th>logmel_delta_58_std</th>\n",
       "      <th>logmel_delta_58_min</th>\n",
       "      <th>logmel_delta_58_max</th>\n",
       "      <th>logmel_delta_59_mean</th>\n",
       "      <th>logmel_delta_59_std</th>\n",
       "      <th>logmel_delta_59_min</th>\n",
       "      <th>logmel_delta_59_max</th>\n",
       "      <th>logmel_delta_60_mean</th>\n",
       "      <th>logmel_delta_60_std</th>\n",
       "      <th>logmel_delta_60_min</th>\n",
       "      <th>logmel_delta_60_max</th>\n",
       "      <th>logmel_delta_61_mean</th>\n",
       "      <th>logmel_delta_61_std</th>\n",
       "      <th>logmel_delta_61_min</th>\n",
       "      <th>logmel_delta_61_max</th>\n",
       "      <th>logmel_delta_62_mean</th>\n",
       "      <th>logmel_delta_62_std</th>\n",
       "      <th>logmel_delta_62_min</th>\n",
       "      <th>logmel_delta_62_max</th>\n",
       "      <th>logmel_delta_63_mean</th>\n",
       "      <th>logmel_delta_63_std</th>\n",
       "      <th>logmel_delta_63_min</th>\n",
       "      <th>logmel_delta_63_max</th>\n",
       "      <th>logmel_delta_64_mean</th>\n",
       "      <th>logmel_delta_64_std</th>\n",
       "      <th>logmel_delta_64_min</th>\n",
       "      <th>logmel_delta_64_max</th>\n",
       "      <th>logmel_delta2_1_mean</th>\n",
       "      <th>logmel_delta2_1_std</th>\n",
       "      <th>logmel_delta2_1_min</th>\n",
       "      <th>logmel_delta2_1_max</th>\n",
       "      <th>logmel_delta2_2_mean</th>\n",
       "      <th>logmel_delta2_2_std</th>\n",
       "      <th>logmel_delta2_2_min</th>\n",
       "      <th>logmel_delta2_2_max</th>\n",
       "      <th>logmel_delta2_3_mean</th>\n",
       "      <th>logmel_delta2_3_std</th>\n",
       "      <th>logmel_delta2_3_min</th>\n",
       "      <th>logmel_delta2_3_max</th>\n",
       "      <th>logmel_delta2_4_mean</th>\n",
       "      <th>logmel_delta2_4_std</th>\n",
       "      <th>logmel_delta2_4_min</th>\n",
       "      <th>logmel_delta2_4_max</th>\n",
       "      <th>logmel_delta2_5_mean</th>\n",
       "      <th>logmel_delta2_5_std</th>\n",
       "      <th>logmel_delta2_5_min</th>\n",
       "      <th>logmel_delta2_5_max</th>\n",
       "      <th>logmel_delta2_6_mean</th>\n",
       "      <th>logmel_delta2_6_std</th>\n",
       "      <th>logmel_delta2_6_min</th>\n",
       "      <th>logmel_delta2_6_max</th>\n",
       "      <th>logmel_delta2_7_mean</th>\n",
       "      <th>logmel_delta2_7_std</th>\n",
       "      <th>logmel_delta2_7_min</th>\n",
       "      <th>logmel_delta2_7_max</th>\n",
       "      <th>logmel_delta2_8_mean</th>\n",
       "      <th>logmel_delta2_8_std</th>\n",
       "      <th>logmel_delta2_8_min</th>\n",
       "      <th>logmel_delta2_8_max</th>\n",
       "      <th>logmel_delta2_9_mean</th>\n",
       "      <th>logmel_delta2_9_std</th>\n",
       "      <th>logmel_delta2_9_min</th>\n",
       "      <th>logmel_delta2_9_max</th>\n",
       "      <th>logmel_delta2_10_mean</th>\n",
       "      <th>logmel_delta2_10_std</th>\n",
       "      <th>logmel_delta2_10_min</th>\n",
       "      <th>logmel_delta2_10_max</th>\n",
       "      <th>logmel_delta2_11_mean</th>\n",
       "      <th>logmel_delta2_11_std</th>\n",
       "      <th>logmel_delta2_11_min</th>\n",
       "      <th>logmel_delta2_11_max</th>\n",
       "      <th>logmel_delta2_12_mean</th>\n",
       "      <th>logmel_delta2_12_std</th>\n",
       "      <th>logmel_delta2_12_min</th>\n",
       "      <th>logmel_delta2_12_max</th>\n",
       "      <th>logmel_delta2_13_mean</th>\n",
       "      <th>logmel_delta2_13_std</th>\n",
       "      <th>logmel_delta2_13_min</th>\n",
       "      <th>logmel_delta2_13_max</th>\n",
       "      <th>logmel_delta2_14_mean</th>\n",
       "      <th>logmel_delta2_14_std</th>\n",
       "      <th>logmel_delta2_14_min</th>\n",
       "      <th>logmel_delta2_14_max</th>\n",
       "      <th>logmel_delta2_15_mean</th>\n",
       "      <th>logmel_delta2_15_std</th>\n",
       "      <th>logmel_delta2_15_min</th>\n",
       "      <th>logmel_delta2_15_max</th>\n",
       "      <th>logmel_delta2_16_mean</th>\n",
       "      <th>logmel_delta2_16_std</th>\n",
       "      <th>logmel_delta2_16_min</th>\n",
       "      <th>logmel_delta2_16_max</th>\n",
       "      <th>logmel_delta2_17_mean</th>\n",
       "      <th>logmel_delta2_17_std</th>\n",
       "      <th>logmel_delta2_17_min</th>\n",
       "      <th>logmel_delta2_17_max</th>\n",
       "      <th>logmel_delta2_18_mean</th>\n",
       "      <th>logmel_delta2_18_std</th>\n",
       "      <th>logmel_delta2_18_min</th>\n",
       "      <th>logmel_delta2_18_max</th>\n",
       "      <th>logmel_delta2_19_mean</th>\n",
       "      <th>logmel_delta2_19_std</th>\n",
       "      <th>logmel_delta2_19_min</th>\n",
       "      <th>logmel_delta2_19_max</th>\n",
       "      <th>logmel_delta2_20_mean</th>\n",
       "      <th>logmel_delta2_20_std</th>\n",
       "      <th>logmel_delta2_20_min</th>\n",
       "      <th>logmel_delta2_20_max</th>\n",
       "      <th>logmel_delta2_21_mean</th>\n",
       "      <th>logmel_delta2_21_std</th>\n",
       "      <th>logmel_delta2_21_min</th>\n",
       "      <th>logmel_delta2_21_max</th>\n",
       "      <th>logmel_delta2_22_mean</th>\n",
       "      <th>logmel_delta2_22_std</th>\n",
       "      <th>logmel_delta2_22_min</th>\n",
       "      <th>logmel_delta2_22_max</th>\n",
       "      <th>logmel_delta2_23_mean</th>\n",
       "      <th>logmel_delta2_23_std</th>\n",
       "      <th>logmel_delta2_23_min</th>\n",
       "      <th>logmel_delta2_23_max</th>\n",
       "      <th>logmel_delta2_24_mean</th>\n",
       "      <th>logmel_delta2_24_std</th>\n",
       "      <th>logmel_delta2_24_min</th>\n",
       "      <th>logmel_delta2_24_max</th>\n",
       "      <th>logmel_delta2_25_mean</th>\n",
       "      <th>logmel_delta2_25_std</th>\n",
       "      <th>logmel_delta2_25_min</th>\n",
       "      <th>logmel_delta2_25_max</th>\n",
       "      <th>logmel_delta2_26_mean</th>\n",
       "      <th>logmel_delta2_26_std</th>\n",
       "      <th>logmel_delta2_26_min</th>\n",
       "      <th>logmel_delta2_26_max</th>\n",
       "      <th>logmel_delta2_27_mean</th>\n",
       "      <th>logmel_delta2_27_std</th>\n",
       "      <th>logmel_delta2_27_min</th>\n",
       "      <th>logmel_delta2_27_max</th>\n",
       "      <th>logmel_delta2_28_mean</th>\n",
       "      <th>logmel_delta2_28_std</th>\n",
       "      <th>logmel_delta2_28_min</th>\n",
       "      <th>logmel_delta2_28_max</th>\n",
       "      <th>logmel_delta2_29_mean</th>\n",
       "      <th>logmel_delta2_29_std</th>\n",
       "      <th>logmel_delta2_29_min</th>\n",
       "      <th>logmel_delta2_29_max</th>\n",
       "      <th>logmel_delta2_30_mean</th>\n",
       "      <th>logmel_delta2_30_std</th>\n",
       "      <th>logmel_delta2_30_min</th>\n",
       "      <th>logmel_delta2_30_max</th>\n",
       "      <th>logmel_delta2_31_mean</th>\n",
       "      <th>logmel_delta2_31_std</th>\n",
       "      <th>logmel_delta2_31_min</th>\n",
       "      <th>logmel_delta2_31_max</th>\n",
       "      <th>logmel_delta2_32_mean</th>\n",
       "      <th>logmel_delta2_32_std</th>\n",
       "      <th>logmel_delta2_32_min</th>\n",
       "      <th>logmel_delta2_32_max</th>\n",
       "      <th>logmel_delta2_33_mean</th>\n",
       "      <th>logmel_delta2_33_std</th>\n",
       "      <th>logmel_delta2_33_min</th>\n",
       "      <th>logmel_delta2_33_max</th>\n",
       "      <th>logmel_delta2_34_mean</th>\n",
       "      <th>logmel_delta2_34_std</th>\n",
       "      <th>logmel_delta2_34_min</th>\n",
       "      <th>logmel_delta2_34_max</th>\n",
       "      <th>logmel_delta2_35_mean</th>\n",
       "      <th>logmel_delta2_35_std</th>\n",
       "      <th>logmel_delta2_35_min</th>\n",
       "      <th>logmel_delta2_35_max</th>\n",
       "      <th>logmel_delta2_36_mean</th>\n",
       "      <th>logmel_delta2_36_std</th>\n",
       "      <th>logmel_delta2_36_min</th>\n",
       "      <th>logmel_delta2_36_max</th>\n",
       "      <th>logmel_delta2_37_mean</th>\n",
       "      <th>logmel_delta2_37_std</th>\n",
       "      <th>logmel_delta2_37_min</th>\n",
       "      <th>logmel_delta2_37_max</th>\n",
       "      <th>logmel_delta2_38_mean</th>\n",
       "      <th>logmel_delta2_38_std</th>\n",
       "      <th>logmel_delta2_38_min</th>\n",
       "      <th>logmel_delta2_38_max</th>\n",
       "      <th>logmel_delta2_39_mean</th>\n",
       "      <th>logmel_delta2_39_std</th>\n",
       "      <th>logmel_delta2_39_min</th>\n",
       "      <th>logmel_delta2_39_max</th>\n",
       "      <th>logmel_delta2_40_mean</th>\n",
       "      <th>logmel_delta2_40_std</th>\n",
       "      <th>logmel_delta2_40_min</th>\n",
       "      <th>logmel_delta2_40_max</th>\n",
       "      <th>logmel_delta2_41_mean</th>\n",
       "      <th>logmel_delta2_41_std</th>\n",
       "      <th>logmel_delta2_41_min</th>\n",
       "      <th>logmel_delta2_41_max</th>\n",
       "      <th>logmel_delta2_42_mean</th>\n",
       "      <th>logmel_delta2_42_std</th>\n",
       "      <th>logmel_delta2_42_min</th>\n",
       "      <th>logmel_delta2_42_max</th>\n",
       "      <th>logmel_delta2_43_mean</th>\n",
       "      <th>logmel_delta2_43_std</th>\n",
       "      <th>logmel_delta2_43_min</th>\n",
       "      <th>logmel_delta2_43_max</th>\n",
       "      <th>logmel_delta2_44_mean</th>\n",
       "      <th>logmel_delta2_44_std</th>\n",
       "      <th>logmel_delta2_44_min</th>\n",
       "      <th>logmel_delta2_44_max</th>\n",
       "      <th>logmel_delta2_45_mean</th>\n",
       "      <th>logmel_delta2_45_std</th>\n",
       "      <th>logmel_delta2_45_min</th>\n",
       "      <th>logmel_delta2_45_max</th>\n",
       "      <th>logmel_delta2_46_mean</th>\n",
       "      <th>logmel_delta2_46_std</th>\n",
       "      <th>logmel_delta2_46_min</th>\n",
       "      <th>logmel_delta2_46_max</th>\n",
       "      <th>logmel_delta2_47_mean</th>\n",
       "      <th>logmel_delta2_47_std</th>\n",
       "      <th>logmel_delta2_47_min</th>\n",
       "      <th>logmel_delta2_47_max</th>\n",
       "      <th>logmel_delta2_48_mean</th>\n",
       "      <th>logmel_delta2_48_std</th>\n",
       "      <th>logmel_delta2_48_min</th>\n",
       "      <th>logmel_delta2_48_max</th>\n",
       "      <th>logmel_delta2_49_mean</th>\n",
       "      <th>logmel_delta2_49_std</th>\n",
       "      <th>logmel_delta2_49_min</th>\n",
       "      <th>logmel_delta2_49_max</th>\n",
       "      <th>logmel_delta2_50_mean</th>\n",
       "      <th>logmel_delta2_50_std</th>\n",
       "      <th>logmel_delta2_50_min</th>\n",
       "      <th>logmel_delta2_50_max</th>\n",
       "      <th>logmel_delta2_51_mean</th>\n",
       "      <th>logmel_delta2_51_std</th>\n",
       "      <th>logmel_delta2_51_min</th>\n",
       "      <th>logmel_delta2_51_max</th>\n",
       "      <th>logmel_delta2_52_mean</th>\n",
       "      <th>logmel_delta2_52_std</th>\n",
       "      <th>logmel_delta2_52_min</th>\n",
       "      <th>logmel_delta2_52_max</th>\n",
       "      <th>logmel_delta2_53_mean</th>\n",
       "      <th>logmel_delta2_53_std</th>\n",
       "      <th>logmel_delta2_53_min</th>\n",
       "      <th>logmel_delta2_53_max</th>\n",
       "      <th>logmel_delta2_54_mean</th>\n",
       "      <th>logmel_delta2_54_std</th>\n",
       "      <th>logmel_delta2_54_min</th>\n",
       "      <th>logmel_delta2_54_max</th>\n",
       "      <th>logmel_delta2_55_mean</th>\n",
       "      <th>logmel_delta2_55_std</th>\n",
       "      <th>logmel_delta2_55_min</th>\n",
       "      <th>logmel_delta2_55_max</th>\n",
       "      <th>logmel_delta2_56_mean</th>\n",
       "      <th>logmel_delta2_56_std</th>\n",
       "      <th>logmel_delta2_56_min</th>\n",
       "      <th>logmel_delta2_56_max</th>\n",
       "      <th>logmel_delta2_57_mean</th>\n",
       "      <th>logmel_delta2_57_std</th>\n",
       "      <th>logmel_delta2_57_min</th>\n",
       "      <th>logmel_delta2_57_max</th>\n",
       "      <th>logmel_delta2_58_mean</th>\n",
       "      <th>logmel_delta2_58_std</th>\n",
       "      <th>logmel_delta2_58_min</th>\n",
       "      <th>logmel_delta2_58_max</th>\n",
       "      <th>logmel_delta2_59_mean</th>\n",
       "      <th>logmel_delta2_59_std</th>\n",
       "      <th>logmel_delta2_59_min</th>\n",
       "      <th>logmel_delta2_59_max</th>\n",
       "      <th>logmel_delta2_60_mean</th>\n",
       "      <th>logmel_delta2_60_std</th>\n",
       "      <th>logmel_delta2_60_min</th>\n",
       "      <th>logmel_delta2_60_max</th>\n",
       "      <th>logmel_delta2_61_mean</th>\n",
       "      <th>logmel_delta2_61_std</th>\n",
       "      <th>logmel_delta2_61_min</th>\n",
       "      <th>logmel_delta2_61_max</th>\n",
       "      <th>logmel_delta2_62_mean</th>\n",
       "      <th>logmel_delta2_62_std</th>\n",
       "      <th>logmel_delta2_62_min</th>\n",
       "      <th>logmel_delta2_62_max</th>\n",
       "      <th>logmel_delta2_63_mean</th>\n",
       "      <th>logmel_delta2_63_std</th>\n",
       "      <th>logmel_delta2_63_min</th>\n",
       "      <th>logmel_delta2_63_max</th>\n",
       "      <th>logmel_delta2_64_mean</th>\n",
       "      <th>logmel_delta2_64_std</th>\n",
       "      <th>logmel_delta2_64_min</th>\n",
       "      <th>logmel_delta2_64_max</th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "      <th>PHQ8_Binary</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39.851742</td>\n",
       "      <td>5.740917</td>\n",
       "      <td>-50.290749</td>\n",
       "      <td>-10.951934</td>\n",
       "      <td>-36.666473</td>\n",
       "      <td>9.424625</td>\n",
       "      <td>-59.953186</td>\n",
       "      <td>-1.421984</td>\n",
       "      <td>-32.704754</td>\n",
       "      <td>10.618219</td>\n",
       "      <td>-62.922821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.444298</td>\n",
       "      <td>11.591890</td>\n",
       "      <td>-58.935440</td>\n",
       "      <td>-8.010373</td>\n",
       "      <td>-36.046009</td>\n",
       "      <td>10.111912</td>\n",
       "      <td>-56.211853</td>\n",
       "      <td>-5.029753</td>\n",
       "      <td>-39.541901</td>\n",
       "      <td>10.223858</td>\n",
       "      <td>-58.508698</td>\n",
       "      <td>-10.306637</td>\n",
       "      <td>-42.335514</td>\n",
       "      <td>10.076996</td>\n",
       "      <td>-60.252258</td>\n",
       "      <td>-9.603920</td>\n",
       "      <td>-41.445229</td>\n",
       "      <td>10.693617</td>\n",
       "      <td>-63.525314</td>\n",
       "      <td>-5.730236</td>\n",
       "      <td>-43.900616</td>\n",
       "      <td>11.855015</td>\n",
       "      <td>-67.004128</td>\n",
       "      <td>-11.832230</td>\n",
       "      <td>-42.292408</td>\n",
       "      <td>11.916592</td>\n",
       "      <td>-66.646904</td>\n",
       "      <td>-9.608103</td>\n",
       "      <td>-41.670689</td>\n",
       "      <td>12.271562</td>\n",
       "      <td>-68.370148</td>\n",
       "      <td>-12.053400</td>\n",
       "      <td>-42.511345</td>\n",
       "      <td>12.572989</td>\n",
       "      <td>-66.612236</td>\n",
       "      <td>-10.799599</td>\n",
       "      <td>-42.740101</td>\n",
       "      <td>12.980083</td>\n",
       "      <td>-67.882423</td>\n",
       "      <td>-9.160012</td>\n",
       "      <td>-45.265316</td>\n",
       "      <td>12.594672</td>\n",
       "      <td>-67.811661</td>\n",
       "      <td>-7.733182</td>\n",
       "      <td>-47.281605</td>\n",
       "      <td>11.568984</td>\n",
       "      <td>-68.004677</td>\n",
       "      <td>-11.218313</td>\n",
       "      <td>-48.010006</td>\n",
       "      <td>12.180610</td>\n",
       "      <td>-71.816017</td>\n",
       "      <td>-11.783464</td>\n",
       "      <td>-47.378807</td>\n",
       "      <td>12.451192</td>\n",
       "      <td>-68.537880</td>\n",
       "      <td>-11.243020</td>\n",
       "      <td>-46.011837</td>\n",
       "      <td>11.511155</td>\n",
       "      <td>-67.631721</td>\n",
       "      <td>-9.824169</td>\n",
       "      <td>-49.009212</td>\n",
       "      <td>11.873863</td>\n",
       "      <td>-69.166443</td>\n",
       "      <td>-13.946668</td>\n",
       "      <td>-50.276794</td>\n",
       "      <td>11.378053</td>\n",
       "      <td>-69.881828</td>\n",
       "      <td>-12.796806</td>\n",
       "      <td>-50.927895</td>\n",
       "      <td>10.840370</td>\n",
       "      <td>-69.346687</td>\n",
       "      <td>-12.481324</td>\n",
       "      <td>-52.884293</td>\n",
       "      <td>12.025846</td>\n",
       "      <td>-72.168762</td>\n",
       "      <td>-14.247681</td>\n",
       "      <td>-53.218559</td>\n",
       "      <td>11.982041</td>\n",
       "      <td>-73.972351</td>\n",
       "      <td>-13.800469</td>\n",
       "      <td>-54.231770</td>\n",
       "      <td>11.837197</td>\n",
       "      <td>-71.576859</td>\n",
       "      <td>-12.470656</td>\n",
       "      <td>-53.495396</td>\n",
       "      <td>11.753271</td>\n",
       "      <td>-73.183128</td>\n",
       "      <td>-13.771776</td>\n",
       "      <td>-53.680553</td>\n",
       "      <td>12.224150</td>\n",
       "      <td>-73.298363</td>\n",
       "      <td>-15.113614</td>\n",
       "      <td>-52.546642</td>\n",
       "      <td>11.813158</td>\n",
       "      <td>-72.904457</td>\n",
       "      <td>-14.655323</td>\n",
       "      <td>-52.808094</td>\n",
       "      <td>11.954452</td>\n",
       "      <td>-72.943039</td>\n",
       "      <td>-13.835618</td>\n",
       "      <td>-52.311790</td>\n",
       "      <td>11.870535</td>\n",
       "      <td>-73.768715</td>\n",
       "      <td>-14.588394</td>\n",
       "      <td>-52.963558</td>\n",
       "      <td>12.075062</td>\n",
       "      <td>-74.416367</td>\n",
       "      <td>-15.850573</td>\n",
       "      <td>-52.874767</td>\n",
       "      <td>11.815126</td>\n",
       "      <td>-73.040245</td>\n",
       "      <td>-16.444122</td>\n",
       "      <td>-53.565666</td>\n",
       "      <td>11.943626</td>\n",
       "      <td>-74.042282</td>\n",
       "      <td>-15.904652</td>\n",
       "      <td>-54.374710</td>\n",
       "      <td>11.296093</td>\n",
       "      <td>-71.887871</td>\n",
       "      <td>-16.776970</td>\n",
       "      <td>-54.550739</td>\n",
       "      <td>10.918699</td>\n",
       "      <td>-71.444160</td>\n",
       "      <td>-15.308524</td>\n",
       "      <td>-54.984581</td>\n",
       "      <td>10.772046</td>\n",
       "      <td>-71.352737</td>\n",
       "      <td>-15.457122</td>\n",
       "      <td>-56.244480</td>\n",
       "      <td>10.918089</td>\n",
       "      <td>-73.015640</td>\n",
       "      <td>-15.980874</td>\n",
       "      <td>-56.773766</td>\n",
       "      <td>11.010494</td>\n",
       "      <td>-73.683762</td>\n",
       "      <td>-16.820917</td>\n",
       "      <td>-57.273552</td>\n",
       "      <td>11.115426</td>\n",
       "      <td>-74.542061</td>\n",
       "      <td>-16.137234</td>\n",
       "      <td>-57.509197</td>\n",
       "      <td>11.113318</td>\n",
       "      <td>-75.323387</td>\n",
       "      <td>-17.903858</td>\n",
       "      <td>-57.050003</td>\n",
       "      <td>10.618951</td>\n",
       "      <td>-71.593445</td>\n",
       "      <td>-17.023657</td>\n",
       "      <td>-57.510437</td>\n",
       "      <td>10.572404</td>\n",
       "      <td>-71.803375</td>\n",
       "      <td>-17.253759</td>\n",
       "      <td>-58.951881</td>\n",
       "      <td>10.849917</td>\n",
       "      <td>-73.921524</td>\n",
       "      <td>-18.085953</td>\n",
       "      <td>-60.176651</td>\n",
       "      <td>10.739304</td>\n",
       "      <td>-74.026939</td>\n",
       "      <td>-19.195347</td>\n",
       "      <td>-60.826412</td>\n",
       "      <td>10.755725</td>\n",
       "      <td>-75.944672</td>\n",
       "      <td>-18.625450</td>\n",
       "      <td>-61.175663</td>\n",
       "      <td>10.812799</td>\n",
       "      <td>-75.968025</td>\n",
       "      <td>-19.956989</td>\n",
       "      <td>-61.384243</td>\n",
       "      <td>10.738929</td>\n",
       "      <td>-76.493614</td>\n",
       "      <td>-20.275364</td>\n",
       "      <td>-60.993401</td>\n",
       "      <td>10.665506</td>\n",
       "      <td>-77.195732</td>\n",
       "      <td>-20.189339</td>\n",
       "      <td>-60.535217</td>\n",
       "      <td>10.655331</td>\n",
       "      <td>-75.906479</td>\n",
       "      <td>-19.903004</td>\n",
       "      <td>-60.520363</td>\n",
       "      <td>10.622469</td>\n",
       "      <td>-76.397980</td>\n",
       "      <td>-20.415352</td>\n",
       "      <td>-61.342403</td>\n",
       "      <td>10.526973</td>\n",
       "      <td>-78.149544</td>\n",
       "      <td>-21.180485</td>\n",
       "      <td>-62.204151</td>\n",
       "      <td>10.467043</td>\n",
       "      <td>-77.389656</td>\n",
       "      <td>-21.620869</td>\n",
       "      <td>-62.564285</td>\n",
       "      <td>10.434353</td>\n",
       "      <td>-76.813248</td>\n",
       "      <td>-21.745163</td>\n",
       "      <td>-62.878166</td>\n",
       "      <td>10.459710</td>\n",
       "      <td>-76.082756</td>\n",
       "      <td>-22.319384</td>\n",
       "      <td>-62.978508</td>\n",
       "      <td>10.357654</td>\n",
       "      <td>-76.456497</td>\n",
       "      <td>-22.547447</td>\n",
       "      <td>-63.112072</td>\n",
       "      <td>10.343971</td>\n",
       "      <td>-76.297241</td>\n",
       "      <td>-22.966291</td>\n",
       "      <td>-63.486366</td>\n",
       "      <td>10.304195</td>\n",
       "      <td>-75.965256</td>\n",
       "      <td>-23.189812</td>\n",
       "      <td>-63.596149</td>\n",
       "      <td>10.184913</td>\n",
       "      <td>-76.479034</td>\n",
       "      <td>-24.083778</td>\n",
       "      <td>-63.82444</td>\n",
       "      <td>10.082624</td>\n",
       "      <td>-76.345062</td>\n",
       "      <td>-25.050465</td>\n",
       "      <td>-64.186752</td>\n",
       "      <td>9.993088</td>\n",
       "      <td>-77.040321</td>\n",
       "      <td>-24.264339</td>\n",
       "      <td>-65.032982</td>\n",
       "      <td>9.917229</td>\n",
       "      <td>-77.983513</td>\n",
       "      <td>-26.151478</td>\n",
       "      <td>-66.297325</td>\n",
       "      <td>9.824694</td>\n",
       "      <td>-78.763115</td>\n",
       "      <td>-27.643932</td>\n",
       "      <td>-68.13102</td>\n",
       "      <td>9.741109</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-30.459169</td>\n",
       "      <td>-70.547966</td>\n",
       "      <td>9.589478</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-32.264328</td>\n",
       "      <td>-73.406082</td>\n",
       "      <td>9.107372</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-36.631458</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.562481</td>\n",
       "      <td>-3.408246</td>\n",
       "      <td>3.874160</td>\n",
       "      <td>-0.002138</td>\n",
       "      <td>1.157037</td>\n",
       "      <td>-7.427499</td>\n",
       "      <td>4.393394</td>\n",
       "      <td>-0.002196</td>\n",
       "      <td>1.563738</td>\n",
       "      <td>-7.614388</td>\n",
       "      <td>6.485934</td>\n",
       "      <td>-0.004703</td>\n",
       "      <td>1.774328</td>\n",
       "      <td>-5.270807</td>\n",
       "      <td>6.553293</td>\n",
       "      <td>-0.005857</td>\n",
       "      <td>1.485678</td>\n",
       "      <td>-6.564243</td>\n",
       "      <td>6.117229</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>1.479937</td>\n",
       "      <td>-6.133159</td>\n",
       "      <td>6.004710</td>\n",
       "      <td>-0.000574</td>\n",
       "      <td>1.438803</td>\n",
       "      <td>-6.227189</td>\n",
       "      <td>5.358456</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>1.573520</td>\n",
       "      <td>-6.421951</td>\n",
       "      <td>5.685359</td>\n",
       "      <td>-0.005834</td>\n",
       "      <td>1.789931</td>\n",
       "      <td>-6.477557</td>\n",
       "      <td>7.043877</td>\n",
       "      <td>-0.007305</td>\n",
       "      <td>1.885950</td>\n",
       "      <td>-7.837217</td>\n",
       "      <td>6.395647</td>\n",
       "      <td>-0.004754</td>\n",
       "      <td>1.993862</td>\n",
       "      <td>-7.865154</td>\n",
       "      <td>6.964901</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>2.117957</td>\n",
       "      <td>-7.358836</td>\n",
       "      <td>7.410278</td>\n",
       "      <td>-0.002284</td>\n",
       "      <td>2.179384</td>\n",
       "      <td>-7.329955</td>\n",
       "      <td>8.069315</td>\n",
       "      <td>-0.004289</td>\n",
       "      <td>2.040538</td>\n",
       "      <td>-7.026336</td>\n",
       "      <td>8.059722</td>\n",
       "      <td>-0.005131</td>\n",
       "      <td>1.773072</td>\n",
       "      <td>-6.830982</td>\n",
       "      <td>7.075618</td>\n",
       "      <td>-0.004875</td>\n",
       "      <td>1.877056</td>\n",
       "      <td>-7.175396</td>\n",
       "      <td>7.275594</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>2.057817</td>\n",
       "      <td>-6.860421</td>\n",
       "      <td>7.416581</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>1.807707</td>\n",
       "      <td>-6.915091</td>\n",
       "      <td>7.225881</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>1.813398</td>\n",
       "      <td>-6.688712</td>\n",
       "      <td>7.002263</td>\n",
       "      <td>-0.002742</td>\n",
       "      <td>1.645075</td>\n",
       "      <td>-6.821152</td>\n",
       "      <td>6.407463</td>\n",
       "      <td>-0.002437</td>\n",
       "      <td>1.434233</td>\n",
       "      <td>-6.015069</td>\n",
       "      <td>6.505145</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>1.662543</td>\n",
       "      <td>-6.999271</td>\n",
       "      <td>6.295094</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>1.638962</td>\n",
       "      <td>-7.154384</td>\n",
       "      <td>6.782696</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>1.588885</td>\n",
       "      <td>-6.266981</td>\n",
       "      <td>6.293672</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>1.601522</td>\n",
       "      <td>-6.473611</td>\n",
       "      <td>6.402759</td>\n",
       "      <td>-0.002838</td>\n",
       "      <td>1.656332</td>\n",
       "      <td>-6.594781</td>\n",
       "      <td>6.486707</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>1.613482</td>\n",
       "      <td>-6.88164</td>\n",
       "      <td>6.627349</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>1.730491</td>\n",
       "      <td>-6.631011</td>\n",
       "      <td>6.739870</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>1.703441</td>\n",
       "      <td>-6.295053</td>\n",
       "      <td>7.082738</td>\n",
       "      <td>-0.004345</td>\n",
       "      <td>1.780080</td>\n",
       "      <td>-6.835969</td>\n",
       "      <td>7.010891</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>1.744458</td>\n",
       "      <td>-7.451605</td>\n",
       "      <td>6.658376</td>\n",
       "      <td>-0.003556</td>\n",
       "      <td>1.762355</td>\n",
       "      <td>-7.571341</td>\n",
       "      <td>6.864086</td>\n",
       "      <td>-0.002290</td>\n",
       "      <td>1.570089</td>\n",
       "      <td>-7.577459</td>\n",
       "      <td>6.656305</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>1.477519</td>\n",
       "      <td>-7.149912</td>\n",
       "      <td>6.90031</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>1.368096</td>\n",
       "      <td>-7.237137</td>\n",
       "      <td>6.845982</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>1.308669</td>\n",
       "      <td>-7.479065</td>\n",
       "      <td>6.268087</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>1.283352</td>\n",
       "      <td>-7.625987</td>\n",
       "      <td>6.279490</td>\n",
       "      <td>-0.002286</td>\n",
       "      <td>1.285248</td>\n",
       "      <td>-7.541911</td>\n",
       "      <td>6.190585</td>\n",
       "      <td>-0.002239</td>\n",
       "      <td>1.295134</td>\n",
       "      <td>-7.116451</td>\n",
       "      <td>6.531188</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>1.247369</td>\n",
       "      <td>-6.744134</td>\n",
       "      <td>6.399222</td>\n",
       "      <td>-0.002165</td>\n",
       "      <td>1.205066</td>\n",
       "      <td>-7.381474</td>\n",
       "      <td>6.430018</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>1.163207</td>\n",
       "      <td>-7.706937</td>\n",
       "      <td>6.391137</td>\n",
       "      <td>-0.001866</td>\n",
       "      <td>1.025413</td>\n",
       "      <td>-7.720008</td>\n",
       "      <td>6.195965</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>0.960673</td>\n",
       "      <td>-7.996519</td>\n",
       "      <td>6.274160</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>0.950841</td>\n",
       "      <td>-7.780514</td>\n",
       "      <td>5.819147</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.944503</td>\n",
       "      <td>-7.459291</td>\n",
       "      <td>5.938414</td>\n",
       "      <td>-0.001852</td>\n",
       "      <td>1.017366</td>\n",
       "      <td>-7.343104</td>\n",
       "      <td>6.055673</td>\n",
       "      <td>-0.002281</td>\n",
       "      <td>1.091199</td>\n",
       "      <td>-7.407117</td>\n",
       "      <td>5.832691</td>\n",
       "      <td>-0.002916</td>\n",
       "      <td>1.084247</td>\n",
       "      <td>-7.566036</td>\n",
       "      <td>6.007954</td>\n",
       "      <td>-0.002862</td>\n",
       "      <td>0.959336</td>\n",
       "      <td>-7.554816</td>\n",
       "      <td>6.035970</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>0.867211</td>\n",
       "      <td>-7.191154</td>\n",
       "      <td>5.946761</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>0.833454</td>\n",
       "      <td>-7.250513</td>\n",
       "      <td>5.929493</td>\n",
       "      <td>-0.001645</td>\n",
       "      <td>0.804061</td>\n",
       "      <td>-7.320018</td>\n",
       "      <td>6.109330</td>\n",
       "      <td>-0.001797</td>\n",
       "      <td>0.769690</td>\n",
       "      <td>-7.407846</td>\n",
       "      <td>5.547441</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.72048</td>\n",
       "      <td>-7.564429</td>\n",
       "      <td>5.553703</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>0.687834</td>\n",
       "      <td>-7.141067</td>\n",
       "      <td>5.753775</td>\n",
       "      <td>-0.001488</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>-7.060959</td>\n",
       "      <td>5.318386</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>0.659297</td>\n",
       "      <td>-7.280230</td>\n",
       "      <td>5.303634</td>\n",
       "      <td>-0.001864</td>\n",
       "      <td>0.651912</td>\n",
       "      <td>-7.263845</td>\n",
       "      <td>5.314815</td>\n",
       "      <td>-0.001654</td>\n",
       "      <td>0.650760</td>\n",
       "      <td>-6.781481</td>\n",
       "      <td>5.343369</td>\n",
       "      <td>-0.001644</td>\n",
       "      <td>0.648088</td>\n",
       "      <td>-7.009334</td>\n",
       "      <td>5.261159</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>0.629735</td>\n",
       "      <td>-6.902781</td>\n",
       "      <td>5.289543</td>\n",
       "      <td>-0.002112</td>\n",
       "      <td>0.632005</td>\n",
       "      <td>-6.657485</td>\n",
       "      <td>5.103760</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>0.596797</td>\n",
       "      <td>-6.718698</td>\n",
       "      <td>4.89314</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>0.345677</td>\n",
       "      <td>-1.843542</td>\n",
       "      <td>1.729448</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.595834</td>\n",
       "      <td>-2.975336</td>\n",
       "      <td>3.231094</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.822058</td>\n",
       "      <td>-3.895775</td>\n",
       "      <td>4.395530</td>\n",
       "      <td>-0.002048</td>\n",
       "      <td>0.927267</td>\n",
       "      <td>-3.755056</td>\n",
       "      <td>4.226347</td>\n",
       "      <td>-0.002085</td>\n",
       "      <td>0.789995</td>\n",
       "      <td>-3.390566</td>\n",
       "      <td>3.323174</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>0.772569</td>\n",
       "      <td>-3.253763</td>\n",
       "      <td>2.809123</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>0.778983</td>\n",
       "      <td>-3.479960</td>\n",
       "      <td>4.298919</td>\n",
       "      <td>-0.000584</td>\n",
       "      <td>0.822063</td>\n",
       "      <td>-4.269476</td>\n",
       "      <td>4.351273</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>0.969448</td>\n",
       "      <td>-4.377288</td>\n",
       "      <td>3.603624</td>\n",
       "      <td>-0.002748</td>\n",
       "      <td>1.033088</td>\n",
       "      <td>-4.718294</td>\n",
       "      <td>4.196088</td>\n",
       "      <td>-0.002992</td>\n",
       "      <td>1.094983</td>\n",
       "      <td>-3.798604</td>\n",
       "      <td>5.761508</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>1.167877</td>\n",
       "      <td>-3.964405</td>\n",
       "      <td>6.079978</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>1.175475</td>\n",
       "      <td>-4.539234</td>\n",
       "      <td>4.157409</td>\n",
       "      <td>-0.002780</td>\n",
       "      <td>1.131080</td>\n",
       "      <td>-4.918217</td>\n",
       "      <td>4.169780</td>\n",
       "      <td>-0.003961</td>\n",
       "      <td>0.994498</td>\n",
       "      <td>-4.181981</td>\n",
       "      <td>5.647631</td>\n",
       "      <td>-0.004254</td>\n",
       "      <td>1.032044</td>\n",
       "      <td>-4.464016</td>\n",
       "      <td>5.314181</td>\n",
       "      <td>-0.003117</td>\n",
       "      <td>1.153215</td>\n",
       "      <td>-4.551128</td>\n",
       "      <td>4.369111</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.021063</td>\n",
       "      <td>-4.360654</td>\n",
       "      <td>4.504696</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>1.038282</td>\n",
       "      <td>-4.271760</td>\n",
       "      <td>4.529875</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>0.912826</td>\n",
       "      <td>-4.141519</td>\n",
       "      <td>4.504786</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>0.772611</td>\n",
       "      <td>-3.732660</td>\n",
       "      <td>3.843079</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>0.924066</td>\n",
       "      <td>-4.083868</td>\n",
       "      <td>4.409594</td>\n",
       "      <td>-0.001645</td>\n",
       "      <td>0.922713</td>\n",
       "      <td>-3.821781</td>\n",
       "      <td>5.324937</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>0.860745</td>\n",
       "      <td>-3.768911</td>\n",
       "      <td>4.391576</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>0.876277</td>\n",
       "      <td>-4.218463</td>\n",
       "      <td>3.854547</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>0.937947</td>\n",
       "      <td>-4.044465</td>\n",
       "      <td>4.788952</td>\n",
       "      <td>-0.001060</td>\n",
       "      <td>0.907104</td>\n",
       "      <td>-4.367910</td>\n",
       "      <td>4.761883</td>\n",
       "      <td>-0.001932</td>\n",
       "      <td>0.956815</td>\n",
       "      <td>-4.308661</td>\n",
       "      <td>3.945053</td>\n",
       "      <td>-0.003133</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>-4.470064</td>\n",
       "      <td>3.904717</td>\n",
       "      <td>-0.003992</td>\n",
       "      <td>1.015091</td>\n",
       "      <td>-4.156464</td>\n",
       "      <td>3.759477</td>\n",
       "      <td>-0.002545</td>\n",
       "      <td>1.012325</td>\n",
       "      <td>-4.333559</td>\n",
       "      <td>4.074770</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>1.040694</td>\n",
       "      <td>-4.491760</td>\n",
       "      <td>4.460404</td>\n",
       "      <td>-0.001324</td>\n",
       "      <td>0.907613</td>\n",
       "      <td>-4.267463</td>\n",
       "      <td>3.624063</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>0.856946</td>\n",
       "      <td>-3.860828</td>\n",
       "      <td>3.675834</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.773285</td>\n",
       "      <td>-3.399029</td>\n",
       "      <td>3.413612</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.723855</td>\n",
       "      <td>-3.404227</td>\n",
       "      <td>3.679519</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>-3.054933</td>\n",
       "      <td>3.524524</td>\n",
       "      <td>-0.000522</td>\n",
       "      <td>0.730972</td>\n",
       "      <td>-3.188881</td>\n",
       "      <td>3.893355</td>\n",
       "      <td>-0.000462</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>-3.336474</td>\n",
       "      <td>4.051969</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>0.681175</td>\n",
       "      <td>-3.604669</td>\n",
       "      <td>3.904557</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>0.660269</td>\n",
       "      <td>-3.564255</td>\n",
       "      <td>3.935660</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.614451</td>\n",
       "      <td>-3.490843</td>\n",
       "      <td>3.397852</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.535764</td>\n",
       "      <td>-3.087711</td>\n",
       "      <td>3.517388</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>-3.435765</td>\n",
       "      <td>3.615880</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.494188</td>\n",
       "      <td>-3.432452</td>\n",
       "      <td>3.305724</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>0.495186</td>\n",
       "      <td>-3.028486</td>\n",
       "      <td>3.050538</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>0.532017</td>\n",
       "      <td>-3.028147</td>\n",
       "      <td>3.187119</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>0.584926</td>\n",
       "      <td>-3.227058</td>\n",
       "      <td>3.181402</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>0.592864</td>\n",
       "      <td>-3.323748</td>\n",
       "      <td>3.677542</td>\n",
       "      <td>-0.000607</td>\n",
       "      <td>0.510747</td>\n",
       "      <td>-3.053588</td>\n",
       "      <td>3.885958</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.458996</td>\n",
       "      <td>-3.340174</td>\n",
       "      <td>3.436489</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0.431766</td>\n",
       "      <td>-3.310402</td>\n",
       "      <td>2.767556</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.406353</td>\n",
       "      <td>-3.22843</td>\n",
       "      <td>2.753009</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.387721</td>\n",
       "      <td>-3.225262</td>\n",
       "      <td>2.993035</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>0.355671</td>\n",
       "      <td>-3.018779</td>\n",
       "      <td>3.070250</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>0.335354</td>\n",
       "      <td>-2.694158</td>\n",
       "      <td>2.694717</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>0.321524</td>\n",
       "      <td>-2.855458</td>\n",
       "      <td>2.891176</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>-3.021807</td>\n",
       "      <td>2.883310</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.306826</td>\n",
       "      <td>-2.962321</td>\n",
       "      <td>2.778399</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.303709</td>\n",
       "      <td>-2.503587</td>\n",
       "      <td>2.453456</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.306797</td>\n",
       "      <td>-2.745233</td>\n",
       "      <td>2.475453</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.299928</td>\n",
       "      <td>-2.774734</td>\n",
       "      <td>2.475754</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.306427</td>\n",
       "      <td>-2.576145</td>\n",
       "      <td>2.543875</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.286238</td>\n",
       "      <td>-2.665952</td>\n",
       "      <td>2.558672</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-34.786011</td>\n",
       "      <td>3.358032</td>\n",
       "      <td>-44.879646</td>\n",
       "      <td>-23.219515</td>\n",
       "      <td>-29.060829</td>\n",
       "      <td>10.515779</td>\n",
       "      <td>-53.240997</td>\n",
       "      <td>-14.231997</td>\n",
       "      <td>-32.236298</td>\n",
       "      <td>9.939849</td>\n",
       "      <td>-58.014923</td>\n",
       "      <td>-7.619808</td>\n",
       "      <td>-30.143028</td>\n",
       "      <td>11.013476</td>\n",
       "      <td>-59.824051</td>\n",
       "      <td>-5.542061</td>\n",
       "      <td>-32.030411</td>\n",
       "      <td>10.867658</td>\n",
       "      <td>-56.220779</td>\n",
       "      <td>-5.682781</td>\n",
       "      <td>-36.031937</td>\n",
       "      <td>10.141639</td>\n",
       "      <td>-57.505447</td>\n",
       "      <td>-5.210167</td>\n",
       "      <td>-37.368904</td>\n",
       "      <td>10.451889</td>\n",
       "      <td>-60.692589</td>\n",
       "      <td>-6.297174</td>\n",
       "      <td>-37.039143</td>\n",
       "      <td>10.711411</td>\n",
       "      <td>-62.189766</td>\n",
       "      <td>-6.307545</td>\n",
       "      <td>-37.597626</td>\n",
       "      <td>11.782638</td>\n",
       "      <td>-63.909447</td>\n",
       "      <td>-4.699326</td>\n",
       "      <td>-37.692524</td>\n",
       "      <td>12.777701</td>\n",
       "      <td>-66.315414</td>\n",
       "      <td>-0.675177</td>\n",
       "      <td>-37.929832</td>\n",
       "      <td>12.641417</td>\n",
       "      <td>-66.395905</td>\n",
       "      <td>-5.825067</td>\n",
       "      <td>-38.256271</td>\n",
       "      <td>12.925496</td>\n",
       "      <td>-65.244629</td>\n",
       "      <td>-3.566361</td>\n",
       "      <td>-37.969402</td>\n",
       "      <td>13.204153</td>\n",
       "      <td>-65.996590</td>\n",
       "      <td>-3.508892</td>\n",
       "      <td>-39.766624</td>\n",
       "      <td>13.379935</td>\n",
       "      <td>-66.539505</td>\n",
       "      <td>-3.100595</td>\n",
       "      <td>-40.931011</td>\n",
       "      <td>13.479660</td>\n",
       "      <td>-68.710220</td>\n",
       "      <td>-2.193323</td>\n",
       "      <td>-41.629654</td>\n",
       "      <td>13.781569</td>\n",
       "      <td>-68.089371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-42.090237</td>\n",
       "      <td>13.090995</td>\n",
       "      <td>-68.711235</td>\n",
       "      <td>-0.828356</td>\n",
       "      <td>-43.468948</td>\n",
       "      <td>11.691388</td>\n",
       "      <td>-65.727646</td>\n",
       "      <td>-3.700083</td>\n",
       "      <td>-45.156689</td>\n",
       "      <td>11.324534</td>\n",
       "      <td>-66.018082</td>\n",
       "      <td>-3.624866</td>\n",
       "      <td>-46.497578</td>\n",
       "      <td>11.385719</td>\n",
       "      <td>-67.354744</td>\n",
       "      <td>-6.117212</td>\n",
       "      <td>-47.572041</td>\n",
       "      <td>11.342668</td>\n",
       "      <td>-70.620949</td>\n",
       "      <td>-7.512813</td>\n",
       "      <td>-49.335587</td>\n",
       "      <td>11.387427</td>\n",
       "      <td>-70.608612</td>\n",
       "      <td>-12.044534</td>\n",
       "      <td>-49.333294</td>\n",
       "      <td>11.282046</td>\n",
       "      <td>-70.263908</td>\n",
       "      <td>-12.796953</td>\n",
       "      <td>-49.398602</td>\n",
       "      <td>12.154994</td>\n",
       "      <td>-70.495506</td>\n",
       "      <td>-12.835116</td>\n",
       "      <td>-48.366116</td>\n",
       "      <td>12.351986</td>\n",
       "      <td>-70.989159</td>\n",
       "      <td>-9.560171</td>\n",
       "      <td>-48.936340</td>\n",
       "      <td>12.332754</td>\n",
       "      <td>-70.712029</td>\n",
       "      <td>-9.880013</td>\n",
       "      <td>-49.056435</td>\n",
       "      <td>12.477395</td>\n",
       "      <td>-73.122635</td>\n",
       "      <td>-10.610985</td>\n",
       "      <td>-49.910172</td>\n",
       "      <td>12.301474</td>\n",
       "      <td>-73.008713</td>\n",
       "      <td>-14.392643</td>\n",
       "      <td>-50.314922</td>\n",
       "      <td>11.809654</td>\n",
       "      <td>-71.761665</td>\n",
       "      <td>-14.649114</td>\n",
       "      <td>-51.125488</td>\n",
       "      <td>11.640377</td>\n",
       "      <td>-70.723656</td>\n",
       "      <td>-13.618870</td>\n",
       "      <td>-51.515751</td>\n",
       "      <td>11.153984</td>\n",
       "      <td>-72.092598</td>\n",
       "      <td>-17.473976</td>\n",
       "      <td>-51.772354</td>\n",
       "      <td>11.038113</td>\n",
       "      <td>-72.343536</td>\n",
       "      <td>-16.458107</td>\n",
       "      <td>-51.399204</td>\n",
       "      <td>10.185336</td>\n",
       "      <td>-70.009857</td>\n",
       "      <td>-15.131104</td>\n",
       "      <td>-51.755730</td>\n",
       "      <td>9.359445</td>\n",
       "      <td>-67.789101</td>\n",
       "      <td>-17.118204</td>\n",
       "      <td>-52.509068</td>\n",
       "      <td>9.556059</td>\n",
       "      <td>-70.676666</td>\n",
       "      <td>-16.595606</td>\n",
       "      <td>-53.855598</td>\n",
       "      <td>10.069683</td>\n",
       "      <td>-71.238205</td>\n",
       "      <td>-17.776957</td>\n",
       "      <td>-54.560001</td>\n",
       "      <td>10.134842</td>\n",
       "      <td>-71.749725</td>\n",
       "      <td>-20.108440</td>\n",
       "      <td>-55.250168</td>\n",
       "      <td>9.829446</td>\n",
       "      <td>-73.015129</td>\n",
       "      <td>-20.772850</td>\n",
       "      <td>-55.239037</td>\n",
       "      <td>9.026427</td>\n",
       "      <td>-70.633072</td>\n",
       "      <td>-21.527912</td>\n",
       "      <td>-55.028103</td>\n",
       "      <td>8.123954</td>\n",
       "      <td>-67.954964</td>\n",
       "      <td>-25.719372</td>\n",
       "      <td>-55.313007</td>\n",
       "      <td>8.616389</td>\n",
       "      <td>-69.742401</td>\n",
       "      <td>-24.426548</td>\n",
       "      <td>-56.088478</td>\n",
       "      <td>9.774688</td>\n",
       "      <td>-72.257614</td>\n",
       "      <td>-23.926105</td>\n",
       "      <td>-56.851929</td>\n",
       "      <td>9.395409</td>\n",
       "      <td>-72.176926</td>\n",
       "      <td>-21.414106</td>\n",
       "      <td>-58.241673</td>\n",
       "      <td>8.696650</td>\n",
       "      <td>-72.668411</td>\n",
       "      <td>-24.123726</td>\n",
       "      <td>-59.603909</td>\n",
       "      <td>8.208038</td>\n",
       "      <td>-73.148247</td>\n",
       "      <td>-30.235405</td>\n",
       "      <td>-60.435101</td>\n",
       "      <td>7.899898</td>\n",
       "      <td>-73.828934</td>\n",
       "      <td>-30.819963</td>\n",
       "      <td>-61.111877</td>\n",
       "      <td>8.243114</td>\n",
       "      <td>-74.451881</td>\n",
       "      <td>-25.614748</td>\n",
       "      <td>-61.265808</td>\n",
       "      <td>8.455508</td>\n",
       "      <td>-74.329124</td>\n",
       "      <td>-29.842350</td>\n",
       "      <td>-61.883801</td>\n",
       "      <td>8.366471</td>\n",
       "      <td>-74.622589</td>\n",
       "      <td>-30.562502</td>\n",
       "      <td>-62.607018</td>\n",
       "      <td>8.094605</td>\n",
       "      <td>-74.396042</td>\n",
       "      <td>-28.083597</td>\n",
       "      <td>-62.897217</td>\n",
       "      <td>8.021015</td>\n",
       "      <td>-74.431267</td>\n",
       "      <td>-30.542015</td>\n",
       "      <td>-63.521706</td>\n",
       "      <td>7.652587</td>\n",
       "      <td>-74.534409</td>\n",
       "      <td>-36.178806</td>\n",
       "      <td>-64.279633</td>\n",
       "      <td>6.722586</td>\n",
       "      <td>-73.844406</td>\n",
       "      <td>-35.815147</td>\n",
       "      <td>-65.958603</td>\n",
       "      <td>6.139832</td>\n",
       "      <td>-75.076149</td>\n",
       "      <td>-34.297066</td>\n",
       "      <td>-67.651169</td>\n",
       "      <td>5.122226</td>\n",
       "      <td>-75.780716</td>\n",
       "      <td>-34.722275</td>\n",
       "      <td>-67.525017</td>\n",
       "      <td>5.003294</td>\n",
       "      <td>-74.979637</td>\n",
       "      <td>-37.456642</td>\n",
       "      <td>-67.591476</td>\n",
       "      <td>5.315038</td>\n",
       "      <td>-74.065735</td>\n",
       "      <td>-36.723312</td>\n",
       "      <td>-67.53672</td>\n",
       "      <td>6.115058</td>\n",
       "      <td>-74.879196</td>\n",
       "      <td>-35.283356</td>\n",
       "      <td>-67.601959</td>\n",
       "      <td>6.731968</td>\n",
       "      <td>-74.538620</td>\n",
       "      <td>-33.450523</td>\n",
       "      <td>-68.407349</td>\n",
       "      <td>7.770634</td>\n",
       "      <td>-75.533417</td>\n",
       "      <td>-32.078804</td>\n",
       "      <td>-68.802116</td>\n",
       "      <td>8.560555</td>\n",
       "      <td>-77.044060</td>\n",
       "      <td>-30.555410</td>\n",
       "      <td>-69.85675</td>\n",
       "      <td>8.831872</td>\n",
       "      <td>-78.790161</td>\n",
       "      <td>-31.024920</td>\n",
       "      <td>-71.458382</td>\n",
       "      <td>8.791592</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-32.326187</td>\n",
       "      <td>-74.190773</td>\n",
       "      <td>8.507262</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-35.673420</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.547863</td>\n",
       "      <td>-2.556505</td>\n",
       "      <td>1.832141</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>1.756980</td>\n",
       "      <td>-4.814270</td>\n",
       "      <td>5.003709</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>1.660940</td>\n",
       "      <td>-5.925524</td>\n",
       "      <td>5.781195</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>1.862585</td>\n",
       "      <td>-6.024328</td>\n",
       "      <td>6.029046</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>1.793467</td>\n",
       "      <td>-5.278584</td>\n",
       "      <td>6.392132</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>1.704347</td>\n",
       "      <td>-5.363217</td>\n",
       "      <td>6.345536</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>1.774413</td>\n",
       "      <td>-5.572687</td>\n",
       "      <td>6.051150</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>1.855842</td>\n",
       "      <td>-5.847002</td>\n",
       "      <td>6.267033</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>2.049184</td>\n",
       "      <td>-6.466393</td>\n",
       "      <td>6.834742</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>2.209919</td>\n",
       "      <td>-6.793139</td>\n",
       "      <td>7.700038</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>2.213601</td>\n",
       "      <td>-6.573767</td>\n",
       "      <td>7.592107</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>2.291636</td>\n",
       "      <td>-6.831878</td>\n",
       "      <td>7.579700</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>2.374723</td>\n",
       "      <td>-6.616634</td>\n",
       "      <td>7.406949</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>2.428038</td>\n",
       "      <td>-7.055273</td>\n",
       "      <td>8.396403</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>2.444839</td>\n",
       "      <td>-7.388039</td>\n",
       "      <td>8.320820</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>2.507377</td>\n",
       "      <td>-7.034614</td>\n",
       "      <td>8.305781</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>2.375421</td>\n",
       "      <td>-7.246790</td>\n",
       "      <td>7.786440</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>2.129525</td>\n",
       "      <td>-6.758570</td>\n",
       "      <td>7.278070</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>2.089232</td>\n",
       "      <td>-7.142992</td>\n",
       "      <td>7.870632</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>2.070817</td>\n",
       "      <td>-6.892043</td>\n",
       "      <td>6.910765</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>2.083852</td>\n",
       "      <td>-6.622849</td>\n",
       "      <td>7.011225</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>2.097660</td>\n",
       "      <td>-6.675929</td>\n",
       "      <td>7.551085</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>2.074203</td>\n",
       "      <td>-6.550871</td>\n",
       "      <td>7.372426</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>2.221152</td>\n",
       "      <td>-6.615071</td>\n",
       "      <td>7.274904</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>2.237890</td>\n",
       "      <td>-6.537192</td>\n",
       "      <td>7.803130</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>2.220926</td>\n",
       "      <td>-6.222318</td>\n",
       "      <td>7.482855</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>2.241750</td>\n",
       "      <td>-6.73070</td>\n",
       "      <td>7.288789</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>2.240006</td>\n",
       "      <td>-6.955960</td>\n",
       "      <td>7.603156</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>2.178485</td>\n",
       "      <td>-6.886145</td>\n",
       "      <td>7.335704</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>2.150915</td>\n",
       "      <td>-6.337079</td>\n",
       "      <td>7.314126</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>2.070173</td>\n",
       "      <td>-6.049308</td>\n",
       "      <td>7.040512</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>2.028838</td>\n",
       "      <td>-6.318143</td>\n",
       "      <td>6.908805</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>1.858191</td>\n",
       "      <td>-6.044658</td>\n",
       "      <td>6.170248</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1.703333</td>\n",
       "      <td>-5.638628</td>\n",
       "      <td>6.22979</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>1.726096</td>\n",
       "      <td>-5.745324</td>\n",
       "      <td>6.755592</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.821396</td>\n",
       "      <td>-5.911152</td>\n",
       "      <td>6.842749</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>1.840721</td>\n",
       "      <td>-6.364254</td>\n",
       "      <td>6.596788</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1.782385</td>\n",
       "      <td>-5.714539</td>\n",
       "      <td>6.363852</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>1.636923</td>\n",
       "      <td>-5.455584</td>\n",
       "      <td>5.899785</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.473573</td>\n",
       "      <td>-5.415421</td>\n",
       "      <td>5.104062</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>1.555818</td>\n",
       "      <td>-5.692486</td>\n",
       "      <td>5.770504</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>1.761601</td>\n",
       "      <td>-5.939577</td>\n",
       "      <td>5.763610</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>1.697675</td>\n",
       "      <td>-5.665002</td>\n",
       "      <td>6.085232</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.570385</td>\n",
       "      <td>-5.482865</td>\n",
       "      <td>5.937726</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.480760</td>\n",
       "      <td>-5.228698</td>\n",
       "      <td>5.579383</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.428916</td>\n",
       "      <td>-5.150427</td>\n",
       "      <td>5.403829</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>1.492057</td>\n",
       "      <td>-5.156378</td>\n",
       "      <td>6.056252</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.538289</td>\n",
       "      <td>-5.237777</td>\n",
       "      <td>5.711278</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>1.527723</td>\n",
       "      <td>-5.368091</td>\n",
       "      <td>5.434238</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>1.494664</td>\n",
       "      <td>-5.218350</td>\n",
       "      <td>5.515513</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>1.489729</td>\n",
       "      <td>-5.075670</td>\n",
       "      <td>5.318966</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>1.415119</td>\n",
       "      <td>-4.657671</td>\n",
       "      <td>4.828682</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.260744</td>\n",
       "      <td>-4.418991</td>\n",
       "      <td>5.145064</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1.199044</td>\n",
       "      <td>-4.577263</td>\n",
       "      <td>5.329707</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1.01628</td>\n",
       "      <td>-4.557378</td>\n",
       "      <td>5.827478</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.996999</td>\n",
       "      <td>-4.803331</td>\n",
       "      <td>5.101470</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>1.062774</td>\n",
       "      <td>-5.125795</td>\n",
       "      <td>5.091107</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.232479</td>\n",
       "      <td>-5.266501</td>\n",
       "      <td>5.797585</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.367156</td>\n",
       "      <td>-5.708364</td>\n",
       "      <td>5.893638</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1.579173</td>\n",
       "      <td>-5.972969</td>\n",
       "      <td>6.483659</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>1.734211</td>\n",
       "      <td>-6.216993</td>\n",
       "      <td>6.186902</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1.774907</td>\n",
       "      <td>-6.139166</td>\n",
       "      <td>6.597427</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.740914</td>\n",
       "      <td>-5.999963</td>\n",
       "      <td>6.633176</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.693182</td>\n",
       "      <td>-6.466531</td>\n",
       "      <td>6.65544</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.394958</td>\n",
       "      <td>-1.432690</td>\n",
       "      <td>1.381540</td>\n",
       "      <td>-0.001039</td>\n",
       "      <td>1.060117</td>\n",
       "      <td>-3.584485</td>\n",
       "      <td>3.756902</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>-3.941930</td>\n",
       "      <td>3.818823</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>1.091842</td>\n",
       "      <td>-3.746035</td>\n",
       "      <td>3.870853</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>1.064669</td>\n",
       "      <td>-3.711049</td>\n",
       "      <td>3.971898</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>1.029840</td>\n",
       "      <td>-4.092535</td>\n",
       "      <td>3.676883</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>1.088073</td>\n",
       "      <td>-4.017005</td>\n",
       "      <td>4.318094</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>1.133479</td>\n",
       "      <td>-3.951298</td>\n",
       "      <td>4.004588</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>1.237488</td>\n",
       "      <td>-4.329955</td>\n",
       "      <td>4.369985</td>\n",
       "      <td>-0.001063</td>\n",
       "      <td>1.344791</td>\n",
       "      <td>-4.641900</td>\n",
       "      <td>5.033251</td>\n",
       "      <td>-0.001177</td>\n",
       "      <td>1.337909</td>\n",
       "      <td>-4.537592</td>\n",
       "      <td>4.647406</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>1.375670</td>\n",
       "      <td>-4.517756</td>\n",
       "      <td>5.162681</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>1.417925</td>\n",
       "      <td>-4.592708</td>\n",
       "      <td>5.099078</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>1.465734</td>\n",
       "      <td>-5.555953</td>\n",
       "      <td>5.111919</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>1.469957</td>\n",
       "      <td>-5.216434</td>\n",
       "      <td>4.723258</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>1.503461</td>\n",
       "      <td>-5.188988</td>\n",
       "      <td>4.803594</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>1.439228</td>\n",
       "      <td>-4.948042</td>\n",
       "      <td>4.742201</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>1.305017</td>\n",
       "      <td>-5.015997</td>\n",
       "      <td>4.531786</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>1.274912</td>\n",
       "      <td>-5.279198</td>\n",
       "      <td>4.069356</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>1.273132</td>\n",
       "      <td>-4.597051</td>\n",
       "      <td>4.375212</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>1.275513</td>\n",
       "      <td>-4.972398</td>\n",
       "      <td>4.261891</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>1.259231</td>\n",
       "      <td>-4.963903</td>\n",
       "      <td>4.662827</td>\n",
       "      <td>-0.001137</td>\n",
       "      <td>1.263639</td>\n",
       "      <td>-4.759346</td>\n",
       "      <td>4.290592</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>1.333262</td>\n",
       "      <td>-4.457909</td>\n",
       "      <td>4.381674</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>1.355035</td>\n",
       "      <td>-4.814380</td>\n",
       "      <td>4.427106</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>1.330216</td>\n",
       "      <td>-4.412353</td>\n",
       "      <td>4.642101</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>1.343100</td>\n",
       "      <td>-4.833606</td>\n",
       "      <td>4.633005</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>1.362715</td>\n",
       "      <td>-4.869596</td>\n",
       "      <td>4.560936</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>1.341451</td>\n",
       "      <td>-4.695038</td>\n",
       "      <td>4.386358</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>1.344900</td>\n",
       "      <td>-5.022954</td>\n",
       "      <td>4.836495</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>1.306571</td>\n",
       "      <td>-5.194457</td>\n",
       "      <td>4.529933</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>1.282336</td>\n",
       "      <td>-4.823397</td>\n",
       "      <td>4.260787</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>1.188221</td>\n",
       "      <td>-4.423777</td>\n",
       "      <td>4.050364</td>\n",
       "      <td>-0.000449</td>\n",
       "      <td>1.111436</td>\n",
       "      <td>-4.166761</td>\n",
       "      <td>3.774100</td>\n",
       "      <td>-0.000246</td>\n",
       "      <td>1.124503</td>\n",
       "      <td>-4.290976</td>\n",
       "      <td>3.802511</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>1.170747</td>\n",
       "      <td>-4.417428</td>\n",
       "      <td>4.094736</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>1.155017</td>\n",
       "      <td>-4.846234</td>\n",
       "      <td>4.354733</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>1.104621</td>\n",
       "      <td>-4.446986</td>\n",
       "      <td>3.871280</td>\n",
       "      <td>-0.000508</td>\n",
       "      <td>1.017771</td>\n",
       "      <td>-4.038434</td>\n",
       "      <td>3.801999</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.929988</td>\n",
       "      <td>-3.851680</td>\n",
       "      <td>3.456408</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>1.004248</td>\n",
       "      <td>-4.459260</td>\n",
       "      <td>3.916385</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>1.127811</td>\n",
       "      <td>-4.570722</td>\n",
       "      <td>4.010119</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>1.082036</td>\n",
       "      <td>-4.233340</td>\n",
       "      <td>3.701340</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>-4.119242</td>\n",
       "      <td>3.638494</td>\n",
       "      <td>-0.000398</td>\n",
       "      <td>0.945697</td>\n",
       "      <td>-3.904773</td>\n",
       "      <td>3.602951</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.913312</td>\n",
       "      <td>-3.486021</td>\n",
       "      <td>3.554817</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>0.946981</td>\n",
       "      <td>-3.894907</td>\n",
       "      <td>3.592723</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>0.977045</td>\n",
       "      <td>-3.858791</td>\n",
       "      <td>3.592449</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.958078</td>\n",
       "      <td>-3.820132</td>\n",
       "      <td>3.575255</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>0.908841</td>\n",
       "      <td>-3.790657</td>\n",
       "      <td>3.245145</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>0.900029</td>\n",
       "      <td>-3.534322</td>\n",
       "      <td>3.377987</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.862609</td>\n",
       "      <td>-3.603699</td>\n",
       "      <td>3.156713</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.773314</td>\n",
       "      <td>-3.36165</td>\n",
       "      <td>3.109010</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.730576</td>\n",
       "      <td>-3.753596</td>\n",
       "      <td>3.315866</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.621822</td>\n",
       "      <td>-3.724786</td>\n",
       "      <td>3.102611</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>-3.478741</td>\n",
       "      <td>2.882083</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0.656715</td>\n",
       "      <td>-3.544268</td>\n",
       "      <td>2.965258</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.766560</td>\n",
       "      <td>-3.985547</td>\n",
       "      <td>3.011336</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.855687</td>\n",
       "      <td>-4.212993</td>\n",
       "      <td>3.461694</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.981123</td>\n",
       "      <td>-4.566537</td>\n",
       "      <td>3.839639</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.069480</td>\n",
       "      <td>-4.733699</td>\n",
       "      <td>3.998524</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>-4.561327</td>\n",
       "      <td>4.156236</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>1.073933</td>\n",
       "      <td>-4.847902</td>\n",
       "      <td>4.199106</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.054937</td>\n",
       "      <td>-4.998971</td>\n",
       "      <td>4.148556</td>\n",
       "      <td>301.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logmel_1_mean  logmel_1_std  logmel_1_min  logmel_1_max  logmel_2_mean  logmel_2_std  logmel_2_min  logmel_2_max  logmel_3_mean  logmel_3_std  logmel_3_min  logmel_3_max  logmel_4_mean  logmel_4_std  logmel_4_min  logmel_4_max  logmel_5_mean  logmel_5_std  logmel_5_min  logmel_5_max  logmel_6_mean  logmel_6_std  logmel_6_min  logmel_6_max  logmel_7_mean  logmel_7_std  logmel_7_min  logmel_7_max  logmel_8_mean  logmel_8_std  logmel_8_min  logmel_8_max  logmel_9_mean  logmel_9_std  logmel_9_min  logmel_9_max  logmel_10_mean  logmel_10_std  logmel_10_min  logmel_10_max  logmel_11_mean  logmel_11_std  logmel_11_min  logmel_11_max  logmel_12_mean  logmel_12_std  logmel_12_min  logmel_12_max  logmel_13_mean  logmel_13_std  logmel_13_min  logmel_13_max  logmel_14_mean  logmel_14_std  logmel_14_min  logmel_14_max  logmel_15_mean  logmel_15_std  logmel_15_min  logmel_15_max  logmel_16_mean  logmel_16_std  logmel_16_min  logmel_16_max  logmel_17_mean  logmel_17_std  logmel_17_min  logmel_17_max  logmel_18_mean  logmel_18_std  logmel_18_min  logmel_18_max  logmel_19_mean  logmel_19_std  logmel_19_min  logmel_19_max  logmel_20_mean  logmel_20_std  logmel_20_min  logmel_20_max  logmel_21_mean  logmel_21_std  logmel_21_min  logmel_21_max  logmel_22_mean  logmel_22_std  logmel_22_min  logmel_22_max  logmel_23_mean  logmel_23_std  logmel_23_min  logmel_23_max  logmel_24_mean  logmel_24_std  logmel_24_min  logmel_24_max  logmel_25_mean  logmel_25_std  logmel_25_min  logmel_25_max  logmel_26_mean  logmel_26_std  logmel_26_min  logmel_26_max  logmel_27_mean  logmel_27_std  logmel_27_min  logmel_27_max  logmel_28_mean  logmel_28_std  logmel_28_min  logmel_28_max  logmel_29_mean  logmel_29_std  logmel_29_min  logmel_29_max  logmel_30_mean  logmel_30_std  logmel_30_min  logmel_30_max  logmel_31_mean  logmel_31_std  logmel_31_min  logmel_31_max  logmel_32_mean  logmel_32_std  logmel_32_min  logmel_32_max  logmel_33_mean  logmel_33_std  logmel_33_min  logmel_33_max  logmel_34_mean  \\\n",
       "0     -39.851742      5.740917    -50.290749    -10.951934     -36.666473      9.424625    -59.953186     -1.421984     -32.704754     10.618219    -62.922821      0.000000     -38.444298     11.591890    -58.935440     -8.010373     -36.046009     10.111912    -56.211853     -5.029753     -39.541901     10.223858    -58.508698    -10.306637     -42.335514     10.076996    -60.252258     -9.603920     -41.445229     10.693617    -63.525314     -5.730236     -43.900616     11.855015    -67.004128    -11.832230      -42.292408      11.916592     -66.646904      -9.608103      -41.670689      12.271562     -68.370148     -12.053400      -42.511345      12.572989     -66.612236     -10.799599      -42.740101      12.980083     -67.882423      -9.160012      -45.265316      12.594672     -67.811661      -7.733182      -47.281605      11.568984     -68.004677     -11.218313      -48.010006      12.180610     -71.816017     -11.783464      -47.378807      12.451192     -68.537880     -11.243020      -46.011837      11.511155     -67.631721      -9.824169      -49.009212      11.873863     -69.166443     -13.946668      -50.276794      11.378053     -69.881828     -12.796806      -50.927895      10.840370     -69.346687     -12.481324      -52.884293      12.025846     -72.168762     -14.247681      -53.218559      11.982041     -73.972351     -13.800469      -54.231770      11.837197     -71.576859     -12.470656      -53.495396      11.753271     -73.183128     -13.771776      -53.680553      12.224150     -73.298363     -15.113614      -52.546642      11.813158     -72.904457     -14.655323      -52.808094      11.954452     -72.943039     -13.835618      -52.311790      11.870535     -73.768715     -14.588394      -52.963558      12.075062     -74.416367     -15.850573      -52.874767      11.815126     -73.040245     -16.444122      -53.565666      11.943626     -74.042282     -15.904652      -54.374710      11.296093     -71.887871     -16.776970      -54.550739   \n",
       "1     -34.786011      3.358032    -44.879646    -23.219515     -29.060829     10.515779    -53.240997    -14.231997     -32.236298      9.939849    -58.014923     -7.619808     -30.143028     11.013476    -59.824051     -5.542061     -32.030411     10.867658    -56.220779     -5.682781     -36.031937     10.141639    -57.505447     -5.210167     -37.368904     10.451889    -60.692589     -6.297174     -37.039143     10.711411    -62.189766     -6.307545     -37.597626     11.782638    -63.909447     -4.699326      -37.692524      12.777701     -66.315414      -0.675177      -37.929832      12.641417     -66.395905      -5.825067      -38.256271      12.925496     -65.244629      -3.566361      -37.969402      13.204153     -65.996590      -3.508892      -39.766624      13.379935     -66.539505      -3.100595      -40.931011      13.479660     -68.710220      -2.193323      -41.629654      13.781569     -68.089371       0.000000      -42.090237      13.090995     -68.711235      -0.828356      -43.468948      11.691388     -65.727646      -3.700083      -45.156689      11.324534     -66.018082      -3.624866      -46.497578      11.385719     -67.354744      -6.117212      -47.572041      11.342668     -70.620949      -7.512813      -49.335587      11.387427     -70.608612     -12.044534      -49.333294      11.282046     -70.263908     -12.796953      -49.398602      12.154994     -70.495506     -12.835116      -48.366116      12.351986     -70.989159      -9.560171      -48.936340      12.332754     -70.712029      -9.880013      -49.056435      12.477395     -73.122635     -10.610985      -49.910172      12.301474     -73.008713     -14.392643      -50.314922      11.809654     -71.761665     -14.649114      -51.125488      11.640377     -70.723656     -13.618870      -51.515751      11.153984     -72.092598     -17.473976      -51.772354      11.038113     -72.343536     -16.458107      -51.399204      10.185336     -70.009857     -15.131104      -51.755730   \n",
       "\n",
       "   logmel_34_std  logmel_34_min  logmel_34_max  logmel_35_mean  logmel_35_std  logmel_35_min  logmel_35_max  logmel_36_mean  logmel_36_std  logmel_36_min  logmel_36_max  logmel_37_mean  logmel_37_std  logmel_37_min  logmel_37_max  logmel_38_mean  logmel_38_std  logmel_38_min  logmel_38_max  logmel_39_mean  logmel_39_std  logmel_39_min  logmel_39_max  logmel_40_mean  logmel_40_std  logmel_40_min  logmel_40_max  logmel_41_mean  logmel_41_std  logmel_41_min  logmel_41_max  logmel_42_mean  logmel_42_std  logmel_42_min  logmel_42_max  logmel_43_mean  logmel_43_std  logmel_43_min  logmel_43_max  logmel_44_mean  logmel_44_std  logmel_44_min  logmel_44_max  logmel_45_mean  logmel_45_std  logmel_45_min  logmel_45_max  logmel_46_mean  logmel_46_std  logmel_46_min  logmel_46_max  logmel_47_mean  logmel_47_std  logmel_47_min  logmel_47_max  logmel_48_mean  logmel_48_std  logmel_48_min  logmel_48_max  logmel_49_mean  logmel_49_std  logmel_49_min  logmel_49_max  logmel_50_mean  logmel_50_std  logmel_50_min  logmel_50_max  logmel_51_mean  logmel_51_std  logmel_51_min  logmel_51_max  logmel_52_mean  logmel_52_std  logmel_52_min  logmel_52_max  logmel_53_mean  logmel_53_std  logmel_53_min  logmel_53_max  logmel_54_mean  logmel_54_std  logmel_54_min  logmel_54_max  logmel_55_mean  logmel_55_std  logmel_55_min  logmel_55_max  logmel_56_mean  logmel_56_std  logmel_56_min  logmel_56_max  logmel_57_mean  logmel_57_std  logmel_57_min  logmel_57_max  logmel_58_mean  logmel_58_std  logmel_58_min  logmel_58_max  logmel_59_mean  logmel_59_std  logmel_59_min  logmel_59_max  logmel_60_mean  logmel_60_std  logmel_60_min  logmel_60_max  logmel_61_mean  logmel_61_std  logmel_61_min  logmel_61_max  logmel_62_mean  logmel_62_std  logmel_62_min  logmel_62_max  logmel_63_mean  logmel_63_std  logmel_63_min  logmel_63_max  logmel_64_mean  logmel_64_std  logmel_64_min  logmel_64_max  logmel_delta_1_mean  logmel_delta_1_std  logmel_delta_1_min  logmel_delta_1_max  logmel_delta_2_mean  \\\n",
       "0      10.918699     -71.444160     -15.308524      -54.984581      10.772046     -71.352737     -15.457122      -56.244480      10.918089     -73.015640     -15.980874      -56.773766      11.010494     -73.683762     -16.820917      -57.273552      11.115426     -74.542061     -16.137234      -57.509197      11.113318     -75.323387     -17.903858      -57.050003      10.618951     -71.593445     -17.023657      -57.510437      10.572404     -71.803375     -17.253759      -58.951881      10.849917     -73.921524     -18.085953      -60.176651      10.739304     -74.026939     -19.195347      -60.826412      10.755725     -75.944672     -18.625450      -61.175663      10.812799     -75.968025     -19.956989      -61.384243      10.738929     -76.493614     -20.275364      -60.993401      10.665506     -77.195732     -20.189339      -60.535217      10.655331     -75.906479     -19.903004      -60.520363      10.622469     -76.397980     -20.415352      -61.342403      10.526973     -78.149544     -21.180485      -62.204151      10.467043     -77.389656     -21.620869      -62.564285      10.434353     -76.813248     -21.745163      -62.878166      10.459710     -76.082756     -22.319384      -62.978508      10.357654     -76.456497     -22.547447      -63.112072      10.343971     -76.297241     -22.966291      -63.486366      10.304195     -75.965256     -23.189812      -63.596149      10.184913     -76.479034     -24.083778       -63.82444      10.082624     -76.345062     -25.050465      -64.186752       9.993088     -77.040321     -24.264339      -65.032982       9.917229     -77.983513     -26.151478      -66.297325       9.824694     -78.763115     -27.643932       -68.13102       9.741109     -80.000000     -30.459169      -70.547966       9.589478          -80.0     -32.264328      -73.406082       9.107372          -80.0     -36.631458             0.000655            0.562481           -3.408246            3.874160            -0.002138   \n",
       "1       9.359445     -67.789101     -17.118204      -52.509068       9.556059     -70.676666     -16.595606      -53.855598      10.069683     -71.238205     -17.776957      -54.560001      10.134842     -71.749725     -20.108440      -55.250168       9.829446     -73.015129     -20.772850      -55.239037       9.026427     -70.633072     -21.527912      -55.028103       8.123954     -67.954964     -25.719372      -55.313007       8.616389     -69.742401     -24.426548      -56.088478       9.774688     -72.257614     -23.926105      -56.851929       9.395409     -72.176926     -21.414106      -58.241673       8.696650     -72.668411     -24.123726      -59.603909       8.208038     -73.148247     -30.235405      -60.435101       7.899898     -73.828934     -30.819963      -61.111877       8.243114     -74.451881     -25.614748      -61.265808       8.455508     -74.329124     -29.842350      -61.883801       8.366471     -74.622589     -30.562502      -62.607018       8.094605     -74.396042     -28.083597      -62.897217       8.021015     -74.431267     -30.542015      -63.521706       7.652587     -74.534409     -36.178806      -64.279633       6.722586     -73.844406     -35.815147      -65.958603       6.139832     -75.076149     -34.297066      -67.651169       5.122226     -75.780716     -34.722275      -67.525017       5.003294     -74.979637     -37.456642      -67.591476       5.315038     -74.065735     -36.723312       -67.53672       6.115058     -74.879196     -35.283356      -67.601959       6.731968     -74.538620     -33.450523      -68.407349       7.770634     -75.533417     -32.078804      -68.802116       8.560555     -77.044060     -30.555410       -69.85675       8.831872     -78.790161     -31.024920      -71.458382       8.791592          -80.0     -32.326187      -74.190773       8.507262          -80.0     -35.673420            -0.000228            0.547863           -2.556505            1.832141            -0.000029   \n",
       "\n",
       "   logmel_delta_2_std  logmel_delta_2_min  logmel_delta_2_max  logmel_delta_3_mean  logmel_delta_3_std  logmel_delta_3_min  logmel_delta_3_max  logmel_delta_4_mean  logmel_delta_4_std  logmel_delta_4_min  logmel_delta_4_max  logmel_delta_5_mean  logmel_delta_5_std  logmel_delta_5_min  logmel_delta_5_max  logmel_delta_6_mean  logmel_delta_6_std  logmel_delta_6_min  logmel_delta_6_max  logmel_delta_7_mean  logmel_delta_7_std  logmel_delta_7_min  logmel_delta_7_max  logmel_delta_8_mean  logmel_delta_8_std  logmel_delta_8_min  logmel_delta_8_max  logmel_delta_9_mean  logmel_delta_9_std  logmel_delta_9_min  logmel_delta_9_max  logmel_delta_10_mean  logmel_delta_10_std  logmel_delta_10_min  logmel_delta_10_max  logmel_delta_11_mean  logmel_delta_11_std  logmel_delta_11_min  logmel_delta_11_max  logmel_delta_12_mean  logmel_delta_12_std  logmel_delta_12_min  logmel_delta_12_max  logmel_delta_13_mean  logmel_delta_13_std  logmel_delta_13_min  logmel_delta_13_max  logmel_delta_14_mean  logmel_delta_14_std  logmel_delta_14_min  logmel_delta_14_max  logmel_delta_15_mean  logmel_delta_15_std  logmel_delta_15_min  logmel_delta_15_max  logmel_delta_16_mean  logmel_delta_16_std  logmel_delta_16_min  logmel_delta_16_max  logmel_delta_17_mean  logmel_delta_17_std  logmel_delta_17_min  logmel_delta_17_max  logmel_delta_18_mean  logmel_delta_18_std  logmel_delta_18_min  logmel_delta_18_max  logmel_delta_19_mean  logmel_delta_19_std  logmel_delta_19_min  logmel_delta_19_max  logmel_delta_20_mean  logmel_delta_20_std  logmel_delta_20_min  logmel_delta_20_max  logmel_delta_21_mean  logmel_delta_21_std  logmel_delta_21_min  logmel_delta_21_max  logmel_delta_22_mean  logmel_delta_22_std  logmel_delta_22_min  logmel_delta_22_max  logmel_delta_23_mean  logmel_delta_23_std  logmel_delta_23_min  logmel_delta_23_max  logmel_delta_24_mean  logmel_delta_24_std  logmel_delta_24_min  logmel_delta_24_max  logmel_delta_25_mean  logmel_delta_25_std  logmel_delta_25_min  logmel_delta_25_max  \\\n",
       "0            1.157037           -7.427499            4.393394            -0.002196            1.563738           -7.614388            6.485934            -0.004703            1.774328           -5.270807            6.553293            -0.005857            1.485678           -6.564243            6.117229            -0.003163            1.479937           -6.133159            6.004710            -0.000574            1.438803           -6.227189            5.358456            -0.001174            1.573520           -6.421951            5.685359            -0.005834            1.789931           -6.477557            7.043877             -0.007305             1.885950            -7.837217             6.395647             -0.004754             1.993862            -7.865154             6.964901             -0.001900             2.117957            -7.358836             7.410278             -0.002284             2.179384            -7.329955             8.069315             -0.004289             2.040538            -7.026336             8.059722             -0.005131             1.773072            -6.830982             7.075618             -0.004875             1.877056            -7.175396             7.275594             -0.001989             2.057817            -6.860421             7.416581             -0.001125             1.807707            -6.915091             7.225881             -0.002079             1.813398            -6.688712             7.002263             -0.002742             1.645075            -6.821152             6.407463             -0.002437             1.434233            -6.015069             6.505145             -0.002017             1.662543            -6.999271             6.295094             -0.001723             1.638962            -7.154384             6.782696             -0.001144             1.588885            -6.266981             6.293672             -0.001879             1.601522            -6.473611             6.402759   \n",
       "1            1.756980           -4.814270            5.003709            -0.000415            1.660940           -5.925524            5.781195            -0.000512            1.862585           -6.024328            6.029046            -0.000302            1.793467           -5.278584            6.392132            -0.000070            1.704347           -5.363217            6.345536            -0.000084            1.774413           -5.572687            6.051150            -0.000395            1.855842           -5.847002            6.267033            -0.000236            2.049184           -6.466393            6.834742             -0.000694             2.209919            -6.793139             7.700038             -0.000594             2.213601            -6.573767             7.592107             -0.000374             2.291636            -6.831878             7.579700             -0.000381             2.374723            -6.616634             7.406949             -0.000229             2.428038            -7.055273             8.396403              0.000373             2.444839            -7.388039             8.320820              0.000959             2.507377            -7.034614             8.305781              0.000795             2.375421            -7.246790             7.786440              0.000932             2.129525            -6.758570             7.278070              0.000469             2.089232            -7.142992             7.870632              0.000207             2.070817            -6.892043             6.910765             -0.000405             2.083852            -6.622849             7.011225             -0.000345             2.097660            -6.675929             7.551085             -0.000474             2.074203            -6.550871             7.372426             -0.000357             2.221152            -6.615071             7.274904             -0.000229             2.237890            -6.537192             7.803130   \n",
       "\n",
       "   logmel_delta_26_mean  logmel_delta_26_std  logmel_delta_26_min  logmel_delta_26_max  logmel_delta_27_mean  logmel_delta_27_std  logmel_delta_27_min  logmel_delta_27_max  logmel_delta_28_mean  logmel_delta_28_std  logmel_delta_28_min  logmel_delta_28_max  logmel_delta_29_mean  logmel_delta_29_std  logmel_delta_29_min  logmel_delta_29_max  logmel_delta_30_mean  logmel_delta_30_std  logmel_delta_30_min  logmel_delta_30_max  logmel_delta_31_mean  logmel_delta_31_std  logmel_delta_31_min  logmel_delta_31_max  logmel_delta_32_mean  logmel_delta_32_std  logmel_delta_32_min  logmel_delta_32_max  logmel_delta_33_mean  logmel_delta_33_std  logmel_delta_33_min  logmel_delta_33_max  logmel_delta_34_mean  logmel_delta_34_std  logmel_delta_34_min  logmel_delta_34_max  logmel_delta_35_mean  logmel_delta_35_std  logmel_delta_35_min  logmel_delta_35_max  logmel_delta_36_mean  logmel_delta_36_std  logmel_delta_36_min  logmel_delta_36_max  logmel_delta_37_mean  logmel_delta_37_std  logmel_delta_37_min  logmel_delta_37_max  logmel_delta_38_mean  logmel_delta_38_std  logmel_delta_38_min  logmel_delta_38_max  logmel_delta_39_mean  logmel_delta_39_std  logmel_delta_39_min  logmel_delta_39_max  logmel_delta_40_mean  logmel_delta_40_std  logmel_delta_40_min  logmel_delta_40_max  logmel_delta_41_mean  logmel_delta_41_std  logmel_delta_41_min  logmel_delta_41_max  logmel_delta_42_mean  logmel_delta_42_std  logmel_delta_42_min  logmel_delta_42_max  logmel_delta_43_mean  logmel_delta_43_std  logmel_delta_43_min  logmel_delta_43_max  logmel_delta_44_mean  logmel_delta_44_std  logmel_delta_44_min  logmel_delta_44_max  logmel_delta_45_mean  logmel_delta_45_std  logmel_delta_45_min  logmel_delta_45_max  logmel_delta_46_mean  logmel_delta_46_std  logmel_delta_46_min  logmel_delta_46_max  logmel_delta_47_mean  logmel_delta_47_std  logmel_delta_47_min  logmel_delta_47_max  logmel_delta_48_mean  logmel_delta_48_std  logmel_delta_48_min  logmel_delta_48_max  logmel_delta_49_mean  \\\n",
       "0             -0.002838             1.656332            -6.594781             6.486707             -0.002557             1.613482             -6.88164             6.627349             -0.003058             1.730491            -6.631011             6.739870             -0.003688             1.703441            -6.295053             7.082738             -0.004345             1.780080            -6.835969             7.010891             -0.004270             1.744458            -7.451605             6.658376             -0.003556             1.762355            -7.571341             6.864086             -0.002290             1.570089            -7.577459             6.656305             -0.000622             1.477519            -7.149912              6.90031             -0.000888             1.368096            -7.237137             6.845982             -0.000873             1.308669            -7.479065             6.268087             -0.001115             1.283352            -7.625987             6.279490             -0.002286             1.285248            -7.541911             6.190585             -0.002239             1.295134            -7.116451             6.531188             -0.002559             1.247369            -6.744134             6.399222             -0.002165             1.205066            -7.381474             6.430018             -0.001336             1.163207            -7.706937             6.391137             -0.001866             1.025413            -7.720008             6.195965             -0.001647             0.960673            -7.996519             6.274160             -0.001929             0.950841            -7.780514             5.819147             -0.001602             0.944503            -7.459291             5.938414             -0.001852             1.017366            -7.343104             6.055673             -0.002281             1.091199            -7.407117             5.832691             -0.002916   \n",
       "1             -0.000048             2.220926            -6.222318             7.482855              0.000405             2.241750             -6.73070             7.288789              0.000639             2.240006            -6.955960             7.603156              0.000928             2.178485            -6.886145             7.335704              0.000854             2.150915            -6.337079             7.314126              0.000625             2.070173            -6.049308             7.040512              0.000866             2.028838            -6.318143             6.908805              0.000426             1.858191            -6.044658             6.170248              0.000265             1.703333            -5.638628              6.22979              0.000479             1.726096            -5.745324             6.755592              0.000054             1.821396            -5.911152             6.842749             -0.000093             1.840721            -6.364254             6.596788              0.000115             1.782385            -5.714539             6.363852              0.000147             1.636923            -5.455584             5.899785              0.000125             1.473573            -5.415421             5.104062             -0.000116             1.555818            -5.692486             5.770504              0.000358             1.761601            -5.939577             5.763610              0.000558             1.697675            -5.665002             6.085232              0.000325             1.570385            -5.482865             5.937726              0.000253             1.480760            -5.228698             5.579383              0.000185             1.428916            -5.150427             5.403829              0.000481             1.492057            -5.156378             6.056252              0.000475             1.538289            -5.237777             5.711278              0.000176   \n",
       "\n",
       "   logmel_delta_49_std  logmel_delta_49_min  logmel_delta_49_max  logmel_delta_50_mean  logmel_delta_50_std  logmel_delta_50_min  logmel_delta_50_max  logmel_delta_51_mean  logmel_delta_51_std  logmel_delta_51_min  logmel_delta_51_max  logmel_delta_52_mean  logmel_delta_52_std  logmel_delta_52_min  logmel_delta_52_max  logmel_delta_53_mean  logmel_delta_53_std  logmel_delta_53_min  logmel_delta_53_max  logmel_delta_54_mean  logmel_delta_54_std  logmel_delta_54_min  logmel_delta_54_max  logmel_delta_55_mean  logmel_delta_55_std  logmel_delta_55_min  logmel_delta_55_max  logmel_delta_56_mean  logmel_delta_56_std  logmel_delta_56_min  logmel_delta_56_max  logmel_delta_57_mean  logmel_delta_57_std  logmel_delta_57_min  logmel_delta_57_max  logmel_delta_58_mean  logmel_delta_58_std  logmel_delta_58_min  logmel_delta_58_max  logmel_delta_59_mean  logmel_delta_59_std  logmel_delta_59_min  logmel_delta_59_max  logmel_delta_60_mean  logmel_delta_60_std  logmel_delta_60_min  logmel_delta_60_max  logmel_delta_61_mean  logmel_delta_61_std  logmel_delta_61_min  logmel_delta_61_max  logmel_delta_62_mean  logmel_delta_62_std  logmel_delta_62_min  logmel_delta_62_max  logmel_delta_63_mean  logmel_delta_63_std  logmel_delta_63_min  logmel_delta_63_max  logmel_delta_64_mean  logmel_delta_64_std  logmel_delta_64_min  logmel_delta_64_max  logmel_delta2_1_mean  logmel_delta2_1_std  logmel_delta2_1_min  logmel_delta2_1_max  logmel_delta2_2_mean  logmel_delta2_2_std  logmel_delta2_2_min  logmel_delta2_2_max  logmel_delta2_3_mean  logmel_delta2_3_std  logmel_delta2_3_min  logmel_delta2_3_max  logmel_delta2_4_mean  logmel_delta2_4_std  logmel_delta2_4_min  logmel_delta2_4_max  logmel_delta2_5_mean  logmel_delta2_5_std  logmel_delta2_5_min  logmel_delta2_5_max  logmel_delta2_6_mean  logmel_delta2_6_std  logmel_delta2_6_min  logmel_delta2_6_max  logmel_delta2_7_mean  logmel_delta2_7_std  logmel_delta2_7_min  logmel_delta2_7_max  logmel_delta2_8_mean  logmel_delta2_8_std  \\\n",
       "0             1.084247            -7.566036             6.007954             -0.002862             0.959336            -7.554816             6.035970             -0.002173             0.867211            -7.191154             5.946761             -0.002546             0.833454            -7.250513             5.929493             -0.001645             0.804061            -7.320018             6.109330             -0.001797             0.769690            -7.407846             5.547441             -0.001684              0.72048            -7.564429             5.553703             -0.001845             0.687834            -7.141067             5.753775             -0.001488             0.661736            -7.060959             5.318386             -0.001804             0.659297            -7.280230             5.303634             -0.001864             0.651912            -7.263845             5.314815             -0.001654             0.650760            -6.781481             5.343369             -0.001644             0.648088            -7.009334             5.261159             -0.001806             0.629735            -6.902781             5.289543             -0.002112             0.632005            -6.657485             5.103760             -0.001284             0.596797            -6.718698              4.89314             -0.000110             0.345677            -1.843542             1.729448              0.000704             0.595834            -2.975336             3.231094              0.000254             0.822058            -3.895775             4.395530             -0.002048             0.927267            -3.755056             4.226347             -0.002085             0.789995            -3.390566             3.323174             -0.002107             0.772569            -3.253763             2.809123             -0.000481             0.778983            -3.479960             4.298919             -0.000584             0.822063   \n",
       "1             1.527723            -5.368091             5.434238             -0.000081             1.494664            -5.218350             5.515513             -0.000067             1.489729            -5.075670             5.318966             -0.000098             1.415119            -4.657671             4.828682              0.000144             1.260744            -4.418991             5.145064              0.000072             1.199044            -4.577263             5.329707              0.000205              1.01628            -4.557378             5.827478              0.000214             0.996999            -4.803331             5.101470              0.000081             1.062774            -5.125795             5.091107              0.000255             1.232479            -5.266501             5.797585              0.000161             1.367156            -5.708364             5.893638              0.000148             1.579173            -5.972969             6.483659              0.000215             1.734211            -6.216993             6.186902              0.000072             1.774907            -6.139166             6.597427              0.000078             1.740914            -5.999963             6.633176              0.000056             1.693182            -6.466531              6.65544             -0.000101             0.394958            -1.432690             1.381540             -0.001039             1.060117            -3.584485             3.756902             -0.000968             0.999497            -3.941930             3.818823             -0.000661             1.091842            -3.746035             3.870853             -0.000788             1.064669            -3.711049             3.971898             -0.000782             1.029840            -4.092535             3.676883             -0.000673             1.088073            -4.017005             4.318094             -0.000486             1.133479   \n",
       "\n",
       "   logmel_delta2_8_min  logmel_delta2_8_max  logmel_delta2_9_mean  logmel_delta2_9_std  logmel_delta2_9_min  logmel_delta2_9_max  logmel_delta2_10_mean  logmel_delta2_10_std  logmel_delta2_10_min  logmel_delta2_10_max  logmel_delta2_11_mean  logmel_delta2_11_std  logmel_delta2_11_min  logmel_delta2_11_max  logmel_delta2_12_mean  logmel_delta2_12_std  logmel_delta2_12_min  logmel_delta2_12_max  logmel_delta2_13_mean  logmel_delta2_13_std  logmel_delta2_13_min  logmel_delta2_13_max  logmel_delta2_14_mean  logmel_delta2_14_std  logmel_delta2_14_min  logmel_delta2_14_max  logmel_delta2_15_mean  logmel_delta2_15_std  logmel_delta2_15_min  logmel_delta2_15_max  logmel_delta2_16_mean  logmel_delta2_16_std  logmel_delta2_16_min  logmel_delta2_16_max  logmel_delta2_17_mean  logmel_delta2_17_std  logmel_delta2_17_min  logmel_delta2_17_max  logmel_delta2_18_mean  logmel_delta2_18_std  logmel_delta2_18_min  logmel_delta2_18_max  logmel_delta2_19_mean  logmel_delta2_19_std  logmel_delta2_19_min  logmel_delta2_19_max  logmel_delta2_20_mean  logmel_delta2_20_std  logmel_delta2_20_min  logmel_delta2_20_max  logmel_delta2_21_mean  logmel_delta2_21_std  logmel_delta2_21_min  logmel_delta2_21_max  logmel_delta2_22_mean  logmel_delta2_22_std  logmel_delta2_22_min  logmel_delta2_22_max  logmel_delta2_23_mean  logmel_delta2_23_std  logmel_delta2_23_min  logmel_delta2_23_max  logmel_delta2_24_mean  logmel_delta2_24_std  logmel_delta2_24_min  logmel_delta2_24_max  logmel_delta2_25_mean  logmel_delta2_25_std  logmel_delta2_25_min  logmel_delta2_25_max  logmel_delta2_26_mean  logmel_delta2_26_std  logmel_delta2_26_min  logmel_delta2_26_max  logmel_delta2_27_mean  logmel_delta2_27_std  logmel_delta2_27_min  logmel_delta2_27_max  logmel_delta2_28_mean  logmel_delta2_28_std  logmel_delta2_28_min  logmel_delta2_28_max  logmel_delta2_29_mean  logmel_delta2_29_std  logmel_delta2_29_min  logmel_delta2_29_max  logmel_delta2_30_mean  logmel_delta2_30_std  logmel_delta2_30_min  logmel_delta2_30_max  \\\n",
       "0            -4.269476             4.351273             -0.002123             0.969448            -4.377288             3.603624              -0.002748              1.033088             -4.718294              4.196088              -0.002992              1.094983             -3.798604              5.761508              -0.001739              1.167877             -3.964405              6.079978              -0.001491              1.175475             -4.539234              4.157409              -0.002780              1.131080             -4.918217              4.169780              -0.003961              0.994498             -4.181981              5.647631              -0.004254              1.032044             -4.464016              5.314181              -0.003117              1.153215             -4.551128              4.369111              -0.001953              1.021063             -4.360654              4.504696              -0.002210              1.038282             -4.271760              4.529875              -0.001608              0.912826             -4.141519              4.504786              -0.001514              0.772611             -3.732660              3.843079              -0.001881              0.924066             -4.083868              4.409594              -0.001645              0.922713             -3.821781              5.324937              -0.002001              0.860745             -3.768911              4.391576              -0.001882              0.876277             -4.218463              3.854547              -0.002384              0.937947             -4.044465              4.788952              -0.001060              0.907104             -4.367910              4.761883              -0.001932              0.956815             -4.308661              3.945053              -0.003133              0.998583             -4.470064              3.904717              -0.003992              1.015091             -4.156464              3.759477   \n",
       "1            -3.951298             4.004588             -0.000795             1.237488            -4.329955             4.369985              -0.001063              1.344791             -4.641900              5.033251              -0.001177              1.337909             -4.537592              4.647406              -0.001463              1.375670             -4.517756              5.162681              -0.001249              1.417925             -4.592708              5.099078              -0.001391              1.465734             -5.555953              5.111919              -0.001372              1.469957             -5.216434              4.723258              -0.001719              1.503461             -5.188988              4.803594              -0.001087              1.439228             -4.948042              4.742201              -0.001065              1.305017             -5.015997              4.531786              -0.000803              1.274912             -5.279198              4.069356              -0.000989              1.273132             -4.597051              4.375212              -0.001401              1.275513             -4.972398              4.261891              -0.001327              1.259231             -4.963903              4.662827              -0.001137              1.263639             -4.759346              4.290592              -0.001171              1.333262             -4.457909              4.381674              -0.001236              1.355035             -4.814380              4.427106              -0.001234              1.330216             -4.412353              4.642101              -0.001293              1.343100             -4.833606              4.633005              -0.001422              1.362715             -4.869596              4.560936              -0.000907              1.341451             -4.695038              4.386358              -0.000891              1.344900             -5.022954              4.836495   \n",
       "\n",
       "   logmel_delta2_31_mean  logmel_delta2_31_std  logmel_delta2_31_min  logmel_delta2_31_max  logmel_delta2_32_mean  logmel_delta2_32_std  logmel_delta2_32_min  logmel_delta2_32_max  logmel_delta2_33_mean  logmel_delta2_33_std  logmel_delta2_33_min  logmel_delta2_33_max  logmel_delta2_34_mean  logmel_delta2_34_std  logmel_delta2_34_min  logmel_delta2_34_max  logmel_delta2_35_mean  logmel_delta2_35_std  logmel_delta2_35_min  logmel_delta2_35_max  logmel_delta2_36_mean  logmel_delta2_36_std  logmel_delta2_36_min  logmel_delta2_36_max  logmel_delta2_37_mean  logmel_delta2_37_std  logmel_delta2_37_min  logmel_delta2_37_max  logmel_delta2_38_mean  logmel_delta2_38_std  logmel_delta2_38_min  logmel_delta2_38_max  logmel_delta2_39_mean  logmel_delta2_39_std  logmel_delta2_39_min  logmel_delta2_39_max  logmel_delta2_40_mean  logmel_delta2_40_std  logmel_delta2_40_min  logmel_delta2_40_max  logmel_delta2_41_mean  logmel_delta2_41_std  logmel_delta2_41_min  logmel_delta2_41_max  logmel_delta2_42_mean  logmel_delta2_42_std  logmel_delta2_42_min  logmel_delta2_42_max  logmel_delta2_43_mean  logmel_delta2_43_std  logmel_delta2_43_min  logmel_delta2_43_max  logmel_delta2_44_mean  logmel_delta2_44_std  logmel_delta2_44_min  logmel_delta2_44_max  logmel_delta2_45_mean  logmel_delta2_45_std  logmel_delta2_45_min  logmel_delta2_45_max  logmel_delta2_46_mean  logmel_delta2_46_std  logmel_delta2_46_min  logmel_delta2_46_max  logmel_delta2_47_mean  logmel_delta2_47_std  logmel_delta2_47_min  logmel_delta2_47_max  logmel_delta2_48_mean  logmel_delta2_48_std  logmel_delta2_48_min  logmel_delta2_48_max  logmel_delta2_49_mean  logmel_delta2_49_std  logmel_delta2_49_min  logmel_delta2_49_max  logmel_delta2_50_mean  logmel_delta2_50_std  logmel_delta2_50_min  logmel_delta2_50_max  logmel_delta2_51_mean  logmel_delta2_51_std  logmel_delta2_51_min  logmel_delta2_51_max  logmel_delta2_52_mean  logmel_delta2_52_std  logmel_delta2_52_min  logmel_delta2_52_max  logmel_delta2_53_mean  \\\n",
       "0              -0.002545              1.012325             -4.333559              4.074770              -0.002060              1.040694             -4.491760              4.460404              -0.001324              0.907613             -4.267463              3.624063              -0.000582              0.856946             -3.860828              3.675834              -0.000415              0.773285             -3.399029              3.413612              -0.000649              0.723855             -3.404227              3.679519              -0.000875              0.720833             -3.054933              3.524524              -0.000522              0.730972             -3.188881              3.893355              -0.000462              0.726457             -3.336474              4.051969              -0.001070              0.681175             -3.604669              3.904557              -0.001592              0.660269             -3.564255              3.935660              -0.001400              0.614451             -3.490843              3.397852              -0.001059              0.535764             -3.087711              3.517388              -0.000478              0.500531             -3.435765              3.615880              -0.000594              0.494188             -3.432452              3.305724              -0.000622              0.495186             -3.028486              3.050538              -0.000729              0.532017             -3.028147              3.187119              -0.001136              0.584926             -3.227058              3.181402              -0.001997              0.592864             -3.323748              3.677542              -0.000607              0.510747             -3.053588              3.885958               0.000052              0.458996             -3.340174              3.436489              -0.000264              0.431766             -3.310402              2.767556              -0.000199   \n",
       "1              -0.000859              1.306571             -5.194457              4.529933              -0.000546              1.282336             -4.823397              4.260787              -0.000466              1.188221             -4.423777              4.050364              -0.000449              1.111436             -4.166761              3.774100              -0.000246              1.124503             -4.290976              3.802511              -0.000422              1.170747             -4.417428              4.094736              -0.000450              1.155017             -4.846234              4.354733              -0.000350              1.104621             -4.446986              3.871280              -0.000508              1.017771             -4.038434              3.801999              -0.000416              0.929988             -3.851680              3.456408              -0.000446              1.004248             -4.459260              3.916385              -0.000335              1.127811             -4.570722              4.010119              -0.000458              1.082036             -4.233340              3.701340              -0.000453              0.996795             -4.119242              3.638494              -0.000398              0.945697             -3.904773              3.602951              -0.000390              0.913312             -3.486021              3.554817              -0.000308              0.946981             -3.894907              3.592723              -0.000169              0.977045             -3.858791              3.592449              -0.000228              0.958078             -3.820132              3.575255              -0.000391              0.908841             -3.790657              3.245145              -0.000322              0.900029             -3.534322              3.377987              -0.000125              0.862609             -3.603699              3.156713              -0.000167   \n",
       "\n",
       "   logmel_delta2_53_std  logmel_delta2_53_min  logmel_delta2_53_max  logmel_delta2_54_mean  logmel_delta2_54_std  logmel_delta2_54_min  logmel_delta2_54_max  logmel_delta2_55_mean  logmel_delta2_55_std  logmel_delta2_55_min  logmel_delta2_55_max  logmel_delta2_56_mean  logmel_delta2_56_std  logmel_delta2_56_min  logmel_delta2_56_max  logmel_delta2_57_mean  logmel_delta2_57_std  logmel_delta2_57_min  logmel_delta2_57_max  logmel_delta2_58_mean  logmel_delta2_58_std  logmel_delta2_58_min  logmel_delta2_58_max  logmel_delta2_59_mean  logmel_delta2_59_std  logmel_delta2_59_min  logmel_delta2_59_max  logmel_delta2_60_mean  logmel_delta2_60_std  logmel_delta2_60_min  logmel_delta2_60_max  logmel_delta2_61_mean  logmel_delta2_61_std  logmel_delta2_61_min  logmel_delta2_61_max  logmel_delta2_62_mean  logmel_delta2_62_std  logmel_delta2_62_min  logmel_delta2_62_max  logmel_delta2_63_mean  logmel_delta2_63_std  logmel_delta2_63_min  logmel_delta2_63_max  logmel_delta2_64_mean  logmel_delta2_64_std  logmel_delta2_64_min  logmel_delta2_64_max  Participant_ID  PHQ8_Score  PHQ8_Binary  Gender  \n",
       "0              0.406353              -3.22843              2.753009               0.000252              0.387721             -3.225262              2.993035              -0.000246              0.355671             -3.018779              3.070250              -0.000276              0.335354             -2.694158              2.694717              -0.000164              0.321524             -2.855458              2.891176              -0.000346              0.319489             -3.021807              2.883310               0.000052              0.306826             -2.962321              2.778399               0.000010              0.303709             -2.503587              2.453456               0.000122              0.306797             -2.745233              2.475453              -0.000183              0.299928             -2.774734              2.475754               0.000095              0.306427             -2.576145              2.543875               0.000019              0.286238             -2.665952              2.558672           300.0           2            0       1  \n",
       "1              0.773314              -3.36165              3.109010              -0.000141              0.730576             -3.753596              3.315866              -0.000248              0.621822             -3.724786              3.102611              -0.000242              0.610294             -3.478741              2.882083              -0.000105              0.656715             -3.544268              2.965258               0.000024              0.766560             -3.985547              3.011336               0.000085              0.855687             -4.212993              3.461694               0.000059              0.981123             -4.566537              3.839639               0.000041              1.069480             -4.733699              3.998524              -0.000012              1.094735             -4.561327              4.156236              -0.000030              1.073933             -4.847902              4.199106               0.000008              1.054937             -4.998971              4.148556           301.0           3            0       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only needed label columns\n",
    "label_cols = [\"Participant_ID\", \"PHQ8_Score\", \"PHQ8_Binary\", \"Gender\"]\n",
    "\n",
    "df_train_lbl = DF_TRAIN[label_cols]\n",
    "df_dev_lbl   = DF_DEV[label_cols]\n",
    "df_test_lbl  = DF_TEST[label_cols]\n",
    "\n",
    "df_labels = (\n",
    "    pd.concat([df_train_lbl, df_dev_lbl, df_test_lbl], axis=0)\n",
    "      .drop_duplicates(subset=\"Participant_ID\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Merge MFCC features with labels\n",
    "logmel_with_labels = df_logmel_all.merge(df_labels, on=\"Participant_ID\", how=\"inner\")\n",
    "print(\"MFCC+Labels shape:\", logmel_with_labels.shape)\n",
    "logmel_with_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fcaea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (107, 772) Val: (35, 772) Test: (47, 772)\n"
     ]
    }
   ],
   "source": [
    "train_ids = DF_TRAIN[\"Participant_ID\"].unique()\n",
    "dev_ids   = DF_DEV[\"Participant_ID\"].unique()\n",
    "test_ids  = DF_TEST[\"Participant_ID\"].unique()\n",
    "\n",
    "train_df = logmel_with_labels[logmel_with_labels[\"Participant_ID\"].isin(train_ids)]\n",
    "val_df   = logmel_with_labels[logmel_with_labels[\"Participant_ID\"].isin(dev_ids)]\n",
    "test_df  = logmel_with_labels[logmel_with_labels[\"Participant_ID\"].isin(test_ids)]\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5194cd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MFCC features: 768\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = [\"Participant_ID\", \"PHQ8_Score\", \"PHQ8_Binary\", \"Gender\"]\n",
    "\n",
    "feature_cols = [c for c in logmel_with_labels.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"PHQ8_Score\"]\n",
    "\n",
    "X_val   = val_df[feature_cols]\n",
    "y_val   = val_df[\"PHQ8_Score\"]\n",
    "\n",
    "X_test  = test_df[feature_cols]\n",
    "y_test  = test_df[\"PHQ8_Score\"]\n",
    "\n",
    "print(\"Number of MFCC features:\", len(feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8650eb",
   "metadata": {},
   "source": [
    "### Use Random Forest to Find the Most Important Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3adbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "rf_for_fs = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    random_state=28,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_for_fs.fit(X_train, y_train)\n",
    "\n",
    "importances = rf_for_fs.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "394d9060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Logmel features (names):\n",
      "logmel_43_std\n",
      "logmel_delta2_5_min\n",
      "logmel_delta_50_max\n",
      "logmel_delta_27_std\n",
      "logmel_delta_18_min\n",
      "logmel_delta2_63_mean\n",
      "logmel_delta2_26_std\n",
      "logmel_7_mean\n",
      "logmel_delta2_17_min\n",
      "logmel_delta_39_min\n",
      "logmel_delta_43_std\n",
      "logmel_delta_4_std\n",
      "logmel_delta_51_max\n",
      "logmel_delta_23_mean\n",
      "logmel_delta_49_max\n",
      "logmel_delta2_2_min\n",
      "logmel_delta2_25_max\n",
      "logmel_delta_52_mean\n",
      "logmel_42_std\n",
      "logmel_delta_45_max\n",
      "logmel_1_mean\n",
      "logmel_delta2_49_std\n",
      "logmel_delta_51_mean\n",
      "logmel_delta_52_max\n",
      "logmel_delta_27_min\n",
      "logmel_delta_26_std\n",
      "logmel_delta2_1_min\n",
      "logmel_51_max\n",
      "logmel_delta_60_mean\n",
      "logmel_delta2_27_std\n",
      "logmel_delta_24_std\n",
      "logmel_delta_22_mean\n",
      "logmel_delta2_4_std\n",
      "logmel_delta2_7_min\n",
      "logmel_delta2_11_max\n",
      "logmel_delta_11_mean\n",
      "logmel_delta_45_mean\n",
      "logmel_52_max\n",
      "logmel_2_mean\n",
      "logmel_delta2_3_min\n"
     ]
    }
   ],
   "source": [
    "top_k = 40  # or 50, or 30 â€” your choice\n",
    "\n",
    "idx_sorted = np.argsort(importances)[::-1]  # descending\n",
    "top_idx = idx_sorted[:top_k]\n",
    "\n",
    "top_features = [feature_cols[i] for i in top_idx]\n",
    "\n",
    "print(\"Top Logmel features (names):\")\n",
    "for f in top_features:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37a507",
   "metadata": {},
   "source": [
    "### Build reduced MFCC DataFrames using only selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bed495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced train shape: (107, 40)\n",
      "Reduced val shape: (35, 40)\n",
      "Reduced test shape: (47, 40)\n"
     ]
    }
   ],
   "source": [
    "# Reduced feature matrices\n",
    "X_train_red = X_train[top_features].copy()\n",
    "X_val_red   = X_val[top_features].copy()\n",
    "X_test_red  = X_test[top_features].copy()\n",
    "\n",
    "print(\"Reduced train shape:\", X_train_red.shape)\n",
    "print(\"Reduced val shape:\", X_val_red.shape)\n",
    "print(\"Reduced test shape:\", X_test_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a38215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reduced MFCC feature set at: C:\\Users\\DELL\\Desktop\\Conversational-Health-Analytics-\\data\\LIBROSA_LOGMEL_TOP40.csv\n"
     ]
    }
   ],
   "source": [
    "data_folder = root / \"data\"\n",
    "\n",
    "logmel_reduced_all = logmel_with_labels[[\"Participant_ID\", \"PHQ8_Score\"] + top_features]\n",
    "logmel_reduced_all.to_csv(data_folder / \"LIBROSA_LOGMEL_TOP40.csv\", index=False)\n",
    "\n",
    "print(\"Saved reduced MFCC feature set at:\", data_folder / \"LIBROSA_LOGMEL_TOP40.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5338b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>PHQ8_Score</th>\n",
       "      <th>logmel_43_std</th>\n",
       "      <th>logmel_delta2_5_min</th>\n",
       "      <th>logmel_delta_50_max</th>\n",
       "      <th>logmel_delta_27_std</th>\n",
       "      <th>logmel_delta_18_min</th>\n",
       "      <th>logmel_delta2_63_mean</th>\n",
       "      <th>logmel_delta2_26_std</th>\n",
       "      <th>logmel_7_mean</th>\n",
       "      <th>logmel_delta2_17_min</th>\n",
       "      <th>logmel_delta_39_min</th>\n",
       "      <th>logmel_delta_43_std</th>\n",
       "      <th>logmel_delta_4_std</th>\n",
       "      <th>logmel_delta_51_max</th>\n",
       "      <th>logmel_delta_23_mean</th>\n",
       "      <th>logmel_delta_49_max</th>\n",
       "      <th>logmel_delta2_2_min</th>\n",
       "      <th>logmel_delta2_25_max</th>\n",
       "      <th>logmel_delta_52_mean</th>\n",
       "      <th>logmel_42_std</th>\n",
       "      <th>logmel_delta_45_max</th>\n",
       "      <th>logmel_1_mean</th>\n",
       "      <th>logmel_delta2_49_std</th>\n",
       "      <th>logmel_delta_51_mean</th>\n",
       "      <th>logmel_delta_52_max</th>\n",
       "      <th>logmel_delta_27_min</th>\n",
       "      <th>logmel_delta_26_std</th>\n",
       "      <th>logmel_delta2_1_min</th>\n",
       "      <th>logmel_51_max</th>\n",
       "      <th>logmel_delta_60_mean</th>\n",
       "      <th>logmel_delta2_27_std</th>\n",
       "      <th>logmel_delta_24_std</th>\n",
       "      <th>logmel_delta_22_mean</th>\n",
       "      <th>logmel_delta2_4_std</th>\n",
       "      <th>logmel_delta2_7_min</th>\n",
       "      <th>logmel_delta2_11_max</th>\n",
       "      <th>logmel_delta_11_mean</th>\n",
       "      <th>logmel_delta_45_mean</th>\n",
       "      <th>logmel_52_max</th>\n",
       "      <th>logmel_2_mean</th>\n",
       "      <th>logmel_delta2_3_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.739304</td>\n",
       "      <td>-3.390566</td>\n",
       "      <td>6.035970</td>\n",
       "      <td>1.613482</td>\n",
       "      <td>-6.915091</td>\n",
       "      <td>9.477621e-05</td>\n",
       "      <td>0.937947</td>\n",
       "      <td>-42.335514</td>\n",
       "      <td>-4.551128</td>\n",
       "      <td>-7.116451</td>\n",
       "      <td>1.025413</td>\n",
       "      <td>1.774328</td>\n",
       "      <td>5.946761</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>6.007954</td>\n",
       "      <td>-2.975336</td>\n",
       "      <td>3.854547</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>10.849917</td>\n",
       "      <td>5.819147</td>\n",
       "      <td>-39.851742</td>\n",
       "      <td>0.592864</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>5.929493</td>\n",
       "      <td>-6.881640</td>\n",
       "      <td>1.656332</td>\n",
       "      <td>-1.843542</td>\n",
       "      <td>-21.620869</td>\n",
       "      <td>-0.001654</td>\n",
       "      <td>0.907104</td>\n",
       "      <td>1.588885</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>0.927267</td>\n",
       "      <td>-3.479960</td>\n",
       "      <td>5.761508</td>\n",
       "      <td>-0.004754</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>-21.745163</td>\n",
       "      <td>-36.666473</td>\n",
       "      <td>-3.895775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.395409</td>\n",
       "      <td>-3.711049</td>\n",
       "      <td>5.515513</td>\n",
       "      <td>2.241750</td>\n",
       "      <td>-6.758570</td>\n",
       "      <td>-2.955596e-05</td>\n",
       "      <td>1.330216</td>\n",
       "      <td>-37.368904</td>\n",
       "      <td>-4.948042</td>\n",
       "      <td>-5.455584</td>\n",
       "      <td>1.697675</td>\n",
       "      <td>1.862585</td>\n",
       "      <td>5.318966</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>5.434238</td>\n",
       "      <td>-3.584485</td>\n",
       "      <td>4.427106</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>9.774688</td>\n",
       "      <td>5.579383</td>\n",
       "      <td>-34.786011</td>\n",
       "      <td>0.958078</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>4.828682</td>\n",
       "      <td>-6.730700</td>\n",
       "      <td>2.220926</td>\n",
       "      <td>-1.432690</td>\n",
       "      <td>-30.542015</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1.343100</td>\n",
       "      <td>2.221152</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>1.091842</td>\n",
       "      <td>-4.017005</td>\n",
       "      <td>4.647406</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>-36.178806</td>\n",
       "      <td>-29.060829</td>\n",
       "      <td>-3.941930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.783973</td>\n",
       "      <td>-3.374838</td>\n",
       "      <td>4.380237</td>\n",
       "      <td>1.681334</td>\n",
       "      <td>-5.304066</td>\n",
       "      <td>-7.131106e-04</td>\n",
       "      <td>1.019084</td>\n",
       "      <td>-32.149399</td>\n",
       "      <td>-3.263655</td>\n",
       "      <td>-4.337917</td>\n",
       "      <td>1.031796</td>\n",
       "      <td>1.442157</td>\n",
       "      <td>4.331590</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>4.877388</td>\n",
       "      <td>-2.740170</td>\n",
       "      <td>3.888376</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>6.057352</td>\n",
       "      <td>4.227523</td>\n",
       "      <td>-26.297705</td>\n",
       "      <td>0.635646</td>\n",
       "      <td>-0.001046</td>\n",
       "      <td>4.160639</td>\n",
       "      <td>-5.123510</td>\n",
       "      <td>1.686172</td>\n",
       "      <td>-1.945076</td>\n",
       "      <td>-33.668652</td>\n",
       "      <td>-0.000683</td>\n",
       "      <td>1.037769</td>\n",
       "      <td>1.753835</td>\n",
       "      <td>-0.004311</td>\n",
       "      <td>0.878476</td>\n",
       "      <td>-3.209999</td>\n",
       "      <td>3.398974</td>\n",
       "      <td>-0.002828</td>\n",
       "      <td>-0.001782</td>\n",
       "      <td>-34.625015</td>\n",
       "      <td>-20.675009</td>\n",
       "      <td>-3.446138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.490192</td>\n",
       "      <td>-3.621092</td>\n",
       "      <td>5.452006</td>\n",
       "      <td>2.105390</td>\n",
       "      <td>-7.104780</td>\n",
       "      <td>2.284568e-04</td>\n",
       "      <td>1.305185</td>\n",
       "      <td>-39.742962</td>\n",
       "      <td>-4.837091</td>\n",
       "      <td>-6.417822</td>\n",
       "      <td>1.554623</td>\n",
       "      <td>1.787458</td>\n",
       "      <td>5.292192</td>\n",
       "      <td>-0.001742</td>\n",
       "      <td>5.712991</td>\n",
       "      <td>-2.230157</td>\n",
       "      <td>4.562909</td>\n",
       "      <td>-0.000424</td>\n",
       "      <td>8.184835</td>\n",
       "      <td>6.293627</td>\n",
       "      <td>-37.777328</td>\n",
       "      <td>0.779309</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>5.600675</td>\n",
       "      <td>-7.099382</td>\n",
       "      <td>2.164683</td>\n",
       "      <td>-2.539845</td>\n",
       "      <td>-32.798985</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>1.288230</td>\n",
       "      <td>2.169303</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>0.972501</td>\n",
       "      <td>-3.872371</td>\n",
       "      <td>4.577280</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>-32.301853</td>\n",
       "      <td>-44.292381</td>\n",
       "      <td>-3.121050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7.878151</td>\n",
       "      <td>-3.339752</td>\n",
       "      <td>4.832123</td>\n",
       "      <td>1.909255</td>\n",
       "      <td>-7.139767</td>\n",
       "      <td>2.419532e-10</td>\n",
       "      <td>1.134411</td>\n",
       "      <td>-47.634342</td>\n",
       "      <td>-5.684505</td>\n",
       "      <td>-5.698740</td>\n",
       "      <td>1.347867</td>\n",
       "      <td>1.569708</td>\n",
       "      <td>4.635792</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>6.025497</td>\n",
       "      <td>-3.549773</td>\n",
       "      <td>4.249362</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>7.976190</td>\n",
       "      <td>5.967069</td>\n",
       "      <td>-41.200623</td>\n",
       "      <td>0.699520</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>4.726497</td>\n",
       "      <td>-6.308327</td>\n",
       "      <td>1.950240</td>\n",
       "      <td>-3.170179</td>\n",
       "      <td>-40.946724</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>1.104353</td>\n",
       "      <td>1.936945</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.846326</td>\n",
       "      <td>-4.459381</td>\n",
       "      <td>3.868308</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>-42.157715</td>\n",
       "      <td>-47.938351</td>\n",
       "      <td>-3.846102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant_ID  PHQ8_Score  logmel_43_std  logmel_delta2_5_min  logmel_delta_50_max  logmel_delta_27_std  logmel_delta_18_min  logmel_delta2_63_mean  logmel_delta2_26_std  logmel_7_mean  logmel_delta2_17_min  logmel_delta_39_min  logmel_delta_43_std  logmel_delta_4_std  logmel_delta_51_max  logmel_delta_23_mean  logmel_delta_49_max  logmel_delta2_2_min  logmel_delta2_25_max  logmel_delta_52_mean  logmel_42_std  logmel_delta_45_max  logmel_1_mean  logmel_delta2_49_std  logmel_delta_51_mean  logmel_delta_52_max  logmel_delta_27_min  logmel_delta_26_std  logmel_delta2_1_min  logmel_51_max  logmel_delta_60_mean  logmel_delta2_27_std  logmel_delta_24_std  logmel_delta_22_mean  logmel_delta2_4_std  logmel_delta2_7_min  logmel_delta2_11_max  logmel_delta_11_mean  logmel_delta_45_mean  logmel_52_max  logmel_2_mean  logmel_delta2_3_min\n",
       "0           300.0           2      10.739304            -3.390566             6.035970             1.613482            -6.915091           9.477621e-05              0.937947     -42.335514             -4.551128            -7.116451             1.025413            1.774328             5.946761             -0.001723             6.007954            -2.975336              3.854547             -0.002546      10.849917             5.819147     -39.851742              0.592864             -0.002173             5.929493            -6.881640             1.656332            -1.843542     -21.620869             -0.001654              0.907104             1.588885             -0.002017             0.927267            -3.479960              5.761508             -0.004754             -0.001929     -21.745163     -36.666473            -3.895775\n",
       "1           301.0           3       9.395409            -3.711049             5.515513             2.241750            -6.758570          -2.955596e-05              1.330216     -37.368904             -4.948042            -5.455584             1.697675            1.862585             5.318966             -0.000474             5.434238            -3.584485              4.427106             -0.000098       9.774688             5.579383     -34.786011              0.958078             -0.000067             4.828682            -6.730700             2.220926            -1.432690     -30.542015              0.000148              1.343100             2.221152             -0.000345             1.091842            -4.017005              4.647406             -0.000594              0.000253     -36.178806     -29.060829            -3.941930\n",
       "2           302.0           4       5.783973            -3.374838             4.380237             1.681334            -5.304066          -7.131106e-04              1.019084     -32.149399             -3.263655            -4.337917             1.031796            1.442157             4.331590             -0.003016             4.877388            -2.740170              3.888376             -0.001019       6.057352             4.227523     -26.297705              0.635646             -0.001046             4.160639            -5.123510             1.686172            -1.945076     -33.668652             -0.000683              1.037769             1.753835             -0.004311             0.878476            -3.209999              3.398974             -0.002828             -0.001782     -34.625015     -20.675009            -3.446138\n",
       "3           303.0           0       8.490192            -3.621092             5.452006             2.105390            -7.104780           2.284568e-04              1.305185     -39.742962             -4.837091            -6.417822             1.554623            1.787458             5.292192             -0.001742             5.712991            -2.230157              4.562909             -0.000424       8.184835             6.293627     -37.777328              0.779309             -0.000493             5.600675            -7.099382             2.164683            -2.539845     -32.798985             -0.000130              1.288230             2.169303             -0.001437             0.972501            -3.872371              4.577280             -0.001383             -0.000674     -32.301853     -44.292381            -3.121050\n",
       "4           304.0           6       7.878151            -3.339752             4.832123             1.909255            -7.139767           2.419532e-10              1.134411     -47.634342             -5.684505            -5.698740             1.347867            1.569708             4.635792              0.000206             6.025497            -3.549773              4.249362              0.000207       7.976190             5.967069     -41.200623              0.699520              0.000530             4.726497            -6.308327             1.950240            -3.170179     -40.946724              0.000392              1.104353             1.936945              0.000470             0.846326            -4.459381              3.868308              0.000127              0.000380     -42.157715     -47.938351            -3.846102"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(r\"C:\\Users\\DELL\\Desktop\\Conversational-Health-Analytics-\\data\")\n",
    "\n",
    "df_logmel_all = pd.read_csv(data_path / \"LIBROSA_LOGMEL_TOP40.csv\")\n",
    "print(df_logmel_all.shape)\n",
    "df_logmel_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc546738",
   "metadata": {},
   "source": [
    "### Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58096155",
   "metadata": {},
   "source": [
    "### Handle Missing, Infinite, and Constant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad479fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed constant features: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace inf with NaN\n",
    "X_train_red.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_val_red.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test_red.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN with column mean\n",
    "X_train_red = X_train_red.fillna(X_train_red.mean())\n",
    "X_val_red   = X_val_red.fillna(X_train_red.mean())\n",
    "X_test_red  = X_test_red.fillna(X_train_red.mean())\n",
    "\n",
    "# Remove constant columns\n",
    "constant_cols = X_train_red.columns[X_train_red.nunique() == 1]\n",
    "print(\"Removed constant features:\", constant_cols.tolist())\n",
    "\n",
    "X_train_red.drop(columns=constant_cols, inplace=True)\n",
    "X_val_red.drop(columns=constant_cols, inplace=True)\n",
    "X_test_red.drop(columns=constant_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b0050",
   "metadata": {},
   "source": [
    "### Outlier Detection & Removal (MFCC ranges vary widely).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44a1a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = X_train_red.quantile(0.25)\n",
    "Q3 = X_train_red.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Keep only non-outliers\n",
    "mask = ~((X_train_red < (Q1 - 1.5 * IQR)) | (X_train_red > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "X_train_red = X_train_red[mask]\n",
    "y_train = y_train[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa535f5",
   "metadata": {},
   "source": [
    "### Feature Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "073e4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_red)\n",
    "X_val_scaled   = scaler.transform(X_val_red)\n",
    "X_test_scaled  = scaler.transform(X_test_red)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7e300",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Three Best Regression Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a70e2f",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e70a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X, y, name=\"Model\"):\n",
    "    preds = model.predict(X)\n",
    "    mae  = mean_absolute_error(y, preds)\n",
    "    mse  = mean_squared_error(y, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2   = r2_score(y, preds)\n",
    "\n",
    "    print(f\"\\n{name} Validation Performance\")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"MSE :\", mse)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"RÂ²  :\", r2)\n",
    "\n",
    "    return [mae, mse, rmse, r2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa7cc8f",
   "metadata": {},
   "source": [
    "### Train XGBoost (Best Model for AVEC-type datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "70a74fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Validation Performance\n",
      "---------------------------------------\n",
      "MAE : 6.062353610992432\n",
      "MSE : 59.09469223022461\n",
      "RMSE: 7.687307215808707\n",
      "RÂ²  : -0.4007546901702881\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    random_state=28\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "xgb_results = evaluate_model(xgb, X_val_scaled, y_val, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e330b6",
   "metadata": {},
   "source": [
    "### Train LightGBM (Fast and Excellent for MFCC features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96e3fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 28, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 5.607143\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "\n",
      "LightGBM Validation Performance\n",
      "---------------------------------------\n",
      "MAE : 5.474489795918368\n",
      "MSE : 45.505357142857136\n",
      "RMSE: 6.745765867776403\n",
      "RÂ²  : -0.07863898026315774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgb = LGBMRegressor(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=50,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=28\n",
    ")\n",
    "\n",
    "lgb.fit(X_train_scaled, y_train)\n",
    "lgb_results = evaluate_model(lgb, X_val_scaled, y_val, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7a244",
   "metadata": {},
   "source": [
    "### Train Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06f03775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Validation Performance\n",
      "---------------------------------------\n",
      "MAE : 5.8020476190476185\n",
      "MSE : 49.94087738095238\n",
      "RMSE: 7.066885974809016\n",
      "RÂ²  : -0.18377660200593415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=600,\n",
    "    random_state=28\n",
    ")\n",
    "\n",
    "rf.fit(X_train_red, y_train)    # no scaling needed\n",
    "rf_results = evaluate_model(rf, X_val_red, y_val, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45654bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
