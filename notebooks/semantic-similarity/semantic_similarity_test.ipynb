{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae5e092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujjwalpoudel/Documents/insane_projects/Conversational-Health-Analytics-/.newvenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d2f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies \"janitorial\" cleaning to the text.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # 1. Lowercase\n",
    "    \n",
    "    # 2. Remove [laughter], [sighs], etc.\n",
    "    text = re.sub(r'\\[.*?\\]', '', text) \n",
    "    \n",
    "    # 3. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # 4. Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # 5. Collapse whitespace (newlines, tabs, multiple spaces)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # 6. Remove leading/trailing whitespace\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce41364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Reading and processing train.jsonl...\n",
      "Processing complete.\n",
      "Found 76 documents for Class 0 (Score < 10).\n",
      "Found 30 documents for Class 1 (Score >= 10).\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load your Embedding Model ---\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# --- 2. Process the .jsonl File ---\n",
    "texts_class_0 = []\n",
    "texts_class_1 = []\n",
    "\n",
    "print(\"Reading and processing train.jsonl...\")\n",
    "\n",
    "try:\n",
    "    with open('/Volumes/MACBACKUP/data/json/lines/train.jsonl', 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Check for 'labels' key\n",
    "            if 'labels' not in data:\n",
    "                continue\n",
    "            \n",
    "            # Get the list of individual scores\n",
    "            individual_scores = data['labels']\n",
    "            \n",
    "            # Check if it's a non-empty list\n",
    "            if not isinstance(individual_scores, list) or not individual_scores:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # 1. Sum the list to get the final score\n",
    "                # (This also checks if all items are numbers)\n",
    "                score_value = sum(individual_scores)\n",
    "            except TypeError:\n",
    "                # This catches cases like [0, 1, \"N/A\"]\n",
    "                continue \n",
    "            # --- END OF FIX ---\n",
    "            \n",
    "            # --- APPLY CLEANING ---\n",
    "            full_conversation_text = \" \".join(data['turns'])\n",
    "            full_conversation_text = clean_text(full_conversation_text)\n",
    "            \n",
    "            # --- END OF CLEANING ---\n",
    "\n",
    "            # 3. Apply your PHQ8 rule (>= 10 is clearer)\n",
    "            if score_value >= 10:\n",
    "                texts_class_1.append(full_conversation_text)\n",
    "            else:\n",
    "                texts_class_0.append(full_conversation_text)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at '/Volumes/MACBACKUP/data/json/lines/train.jsonl'\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Check if we found any data ---\n",
    "print(f\"Processing complete.\")\n",
    "print(f\"Found {len(texts_class_0)} documents for Class 0 (Score < 10).\")\n",
    "print(f\"Found {len(texts_class_1)} documents for Class 1 (Score >= 10).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9612db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for Class 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:01<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for Class 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging embeddings to create prototypes...\n",
      "Saving model to /Volumes/MACBACKUP/embeddings...\n",
      "Saving prototype vectors...\n",
      "\n",
      "Setup complete. Model and prototypes are saved.\n"
     ]
    }
   ],
   "source": [
    "if len(texts_class_0) == 0 or len(texts_class_1) == 0:\n",
    "    print(\"\\n--- !! WARNING !! ---\")\n",
    "    print(\"One or both classes have 0 documents.\")\n",
    "    print(\"Please check your 'train.jsonl' file and the PHQ8 scores.\")\n",
    "    print(\"------------------------\")\n",
    "    exit()\n",
    "\n",
    "# --- 4. Generate Embeddings for all found texts ---\n",
    "print(\"Generating embeddings for Class 0...\")\n",
    "embeddings_class_0 = model.encode(texts_class_0, show_progress_bar=True)\n",
    "\n",
    "print(\"Generating embeddings for Class 1...\")\n",
    "embeddings_class_1 = model.encode(texts_class_1, show_progress_bar=True)\n",
    "\n",
    "# --- 5. Create the Prototype (Centroid) ---\n",
    "print(\"Averaging embeddings to create prototypes...\")\n",
    "emb_0 = np.mean(embeddings_class_0, axis=0)\n",
    "emb_1 = np.mean(embeddings_class_1, axis=0)\n",
    "\n",
    "# --- 6. Save Everything for Production ---\n",
    "model_save_path = '/Volumes/MACBACKUP/embeddings'\n",
    "print(f\"Saving model to {model_save_path}...\")\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(\"Saving prototype vectors...\")\n",
    "np.save('prototype_emb_0.npy', emb_0)\n",
    "np.save('prototype_emb_1.npy', emb_1)\n",
    "\n",
    "print(\"\\nSetup complete. Model and prototypes are saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
